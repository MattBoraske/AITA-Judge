{"overall_metrics": {"total_conflicts": 9855, "top_doc_true_class_match_accuracy": 0.7734145104008118, "top_doc_predicted_class_match_accuracy": 0.8457635717909691, "all_docs_true_class_match_accuracy": 0.7753018772197064, "all_docs_predicted_class_match_accuracy": 0.8007914764079297}, "per_class_metrics": {"NTA": {"num_conflicts": 8107, "top_doc_true_class_match_accuracy": 0.9093376094732947, "top_doc_predicted_class_match_accuracy": 0.9056371037375108, "all_docs_true_class_match_accuracy": 0.9120759837178086, "all_docs_predicted_class_match_accuracy": 0.8689280868385555}, "YTA": {"num_conflicts": 1111, "top_doc_true_class_match_accuracy": 0.18901890189018902, "top_doc_predicted_class_match_accuracy": 0.48334833483348333, "all_docs_true_class_match_accuracy": 0.1922592259225916, "all_docs_predicted_class_match_accuracy": 0.41602160216021417}, "NAH": {"num_conflicts": 378, "top_doc_true_class_match_accuracy": 0.07407407407407407, "top_doc_predicted_class_match_accuracy": 0.7275132275132276, "all_docs_true_class_match_accuracy": 0.0677248677248676, "all_docs_predicted_class_match_accuracy": 0.6116402116402118}, "ESH": {"num_conflicts": 259, "top_doc_true_class_match_accuracy": 0.04633204633204633, "top_doc_predicted_class_match_accuracy": 0.6988416988416989, "all_docs_true_class_match_accuracy": 0.027799227799227815, "all_docs_predicted_class_match_accuracy": 0.5945945945945948}}}