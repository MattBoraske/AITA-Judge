{"overall_metrics": {"total_conflicts": 9809, "top_doc_true_class_match_accuracy": 0.7736772351921705, "top_doc_predicted_class_match_accuracy": 0.8373942297889693, "all_docs_true_class_match_accuracy": 0.7751452747477017, "all_docs_predicted_class_match_accuracy": 0.7595881333469362}, "per_class_metrics": {"NTA": {"num_conflicts": 8066, "top_doc_true_class_match_accuracy": 0.9099925613687082, "top_doc_predicted_class_match_accuracy": 0.882593602777089, "all_docs_true_class_match_accuracy": 0.9122241507562945, "all_docs_predicted_class_match_accuracy": 0.8123977188197503}, "YTA": {"num_conflicts": 1107, "top_doc_true_class_match_accuracy": 0.1878952122854562, "top_doc_predicted_class_match_accuracy": 0.5555555555555556, "all_docs_true_class_match_accuracy": 0.19168925022583488, "all_docs_predicted_class_match_accuracy": 0.4639566395663943}, "NAH": {"num_conflicts": 376, "top_doc_true_class_match_accuracy": 0.07712765957446809, "top_doc_predicted_class_match_accuracy": 0.8164893617021277, "all_docs_true_class_match_accuracy": 0.06861702127659564, "all_docs_predicted_class_match_accuracy": 0.6569148936170216}, "ESH": {"num_conflicts": 260, "top_doc_true_class_match_accuracy": 0.046153846153846156, "top_doc_predicted_class_match_accuracy": 0.6653846153846154, "all_docs_true_class_match_accuracy": 0.028461538461538476, "all_docs_predicted_class_match_accuracy": 0.5284615384615385}}}