2025-01-02 02:22:04,162 - __main__ - INFO - Starting AITA Agent evaluation script
2025-01-02 02:22:04,164 - __main__ - INFO - Setting up telemetry
2025-01-02 02:22:04,231 - __main__ - INFO - Telemetry setup completed successfully
2025-01-02 02:22:04,232 - __main__ - INFO - Starting evaluation process
2025-01-02 02:22:04,232 - __main__ - INFO - Initializing Evaluation Utility
2025-01-02 02:22:04,232 - src.agent.evaluation.eval_util - INFO - Initialized Evaluation_Utility
2025-01-02 02:22:04,232 - __main__ - INFO - Initializing AITA Agent workflow
2025-01-02 02:22:04,232 - __main__ - INFO - Loading dataset from MattBoraske/reddit-AITA-submissions-and-comments-multiclass
2025-01-02 02:22:06,017 - __main__ - INFO - Dataset size after filtering: 9867
2025-01-02 02:22:06,017 - __main__ - INFO - Creating balanced test set with 250 samples per class
2025-01-02 02:22:06,018 - src.agent.evaluation.eval_util - INFO - Creating balanced test set with 250 samples per class
2025-01-02 02:22:06,097 - src.agent.evaluation.eval_util - INFO - Successfully created balanced test set with 1000 samples
2025-01-02 02:22:06,098 - __main__ - INFO - Final test set size: 1000
2025-01-02 02:22:06,098 - __main__ - INFO - Starting response collection
2025-01-02 02:22:06,099 - src.agent.evaluation.eval_util - INFO - Starting response collection for 1000 samples
2025-01-02 02:22:06,106 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:22:06,106 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:22:06,119 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:22:07,111 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:22:09,500 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:22:11,646 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:22:14,399 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:22:16,329 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:22:18,866 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:22:21,470 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:22:22,273 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:22:24,834 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:22:24,836 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:22:24,836 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:22:25,354 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:22:26,659 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:22:27,799 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:22:31,939 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:22:34,317 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:22:37,118 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:22:39,902 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:22:40,557 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:22:44,843 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:22:44,845 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:22:44,845 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:22:45,415 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:22:46,817 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:22:47,872 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:22:49,546 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:22:52,988 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:22:56,299 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:22:58,213 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:22:58,929 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:23:00,725 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:23:00,726 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:23:00,726 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:23:01,389 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:23:05,282 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:23:06,184 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:23:08,382 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:23:10,743 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:23:13,983 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:23:16,707 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:23:17,477 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:23:20,637 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:23:20,638 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:23:20,639 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:23:21,153 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:23:22,277 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:23:23,203 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:23:24,942 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:23:27,091 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:23:31,801 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:23:34,428 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:23:35,242 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:23:37,324 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:23:37,324 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:23:37,325 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:23:37,845 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:23:39,527 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:23:40,554 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:23:42,646 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:23:45,453 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:23:47,765 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:23:49,295 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:23:49,924 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:23:52,237 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:23:52,238 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:23:52,239 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:23:52,693 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:23:54,330 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:23:55,149 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:23:56,518 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:23:58,420 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:24:04,055 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:24:08,041 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:24:08,705 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:24:12,082 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:24:12,084 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:24:12,084 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:24:12,750 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:24:14,493 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:24:15,348 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:24:17,717 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:24:19,927 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:24:22,180 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:24:24,293 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:24:25,354 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:24:29,791 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:24:29,794 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:24:29,794 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:24:30,376 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:24:31,778 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:24:32,729 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:24:35,236 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:24:41,331 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:24:44,254 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:24:46,599 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:24:47,306 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:24:49,649 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:24:49,650 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:24:49,650 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:24:50,078 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:24:51,671 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:24:52,660 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:24:55,100 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:25:00,886 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:25:04,132 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:25:07,522 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:25:09,290 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:25:11,626 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:25:11,628 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:25:11,628 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:25:12,364 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:25:13,871 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:25:14,717 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:25:16,156 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:25:18,069 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:25:20,961 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:25:23,109 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:25:23,723 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:25:25,826 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:25:25,827 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:25:25,827 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:25:26,289 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:25:27,924 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:25:28,750 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:25:30,665 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:25:33,865 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:25:37,443 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:25:40,875 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:25:41,765 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:25:45,148 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:25:45,150 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:25:45,151 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:25:45,640 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:25:46,766 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:25:47,587 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:25:49,452 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:25:51,312 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:25:53,528 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:25:55,805 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:25:56,484 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:25:58,464 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:25:58,465 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:25:58,465 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:25:58,790 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:25:59,910 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:26:00,707 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:26:04,355 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:26:09,399 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:26:12,673 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:26:15,664 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:26:16,361 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:26:18,838 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:26:18,840 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:26:18,840 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:26:19,332 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:26:21,377 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:26:22,305 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:26:23,940 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:26:26,295 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:26:28,342 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:26:31,371 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:26:32,130 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:26:34,962 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:26:34,963 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:26:34,963 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:26:35,659 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:26:37,035 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:26:37,971 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:26:40,810 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:26:42,987 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:26:49,323 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:26:52,054 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:26:52,818 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:26:54,397 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:26:54,399 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:26:54,399 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:26:54,972 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:26:56,036 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:26:56,914 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:27:00,804 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:27:03,792 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:27:08,417 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:27:11,813 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:27:12,456 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:27:14,758 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:27:14,759 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:27:14,759 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:27:15,240 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:27:16,284 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:27:17,084 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:27:19,133 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:27:20,772 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:27:22,409 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:27:24,275 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:27:24,971 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:27:28,888 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:27:28,895 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:27:28,895 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:27:29,415 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:27:30,814 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:27:31,834 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:27:33,070 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:27:34,800 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:27:36,337 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:27:37,748 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:27:38,375 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:27:40,362 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:27:40,362 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:27:40,363 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:27:40,777 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:27:42,028 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:27:42,746 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:27:44,423 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:27:46,985 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:27:48,593 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:27:50,393 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:27:51,080 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:27:53,200 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:27:53,201 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:27:53,201 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:27:53,646 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:27:54,791 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:27:55,694 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:27:58,028 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:28:03,158 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:28:05,831 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:28:08,300 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:28:08,885 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:28:13,409 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:28:13,412 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:28:13,412 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:28:13,819 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:28:14,950 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:28:15,694 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:28:17,401 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:28:20,151 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:28:23,339 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:28:25,535 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:28:26,130 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:28:28,620 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:28:28,621 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:28:28,621 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:28:29,181 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:28:30,601 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:28:31,400 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:28:33,785 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:28:35,423 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:28:37,472 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:28:39,677 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:28:40,440 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:28:42,459 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:28:42,460 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:28:42,460 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:28:43,001 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:28:44,143 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:28:45,150 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:28:47,033 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:28:49,962 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:28:52,273 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:28:54,377 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:28:55,030 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:28:57,176 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:28:57,177 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:28:57,178 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:28:57,707 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:28:58,927 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:28:59,797 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:29:33,223 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:29:37,042 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:29:39,835 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:29:41,811 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:29:42,700 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:29:44,422 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:29:44,423 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:29:44,423 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:29:45,336 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:29:46,593 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:29:47,472 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:29:49,460 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:29:55,447 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:29:58,243 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:30:00,608 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:30:04,003 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:30:06,675 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:30:06,677 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:30:06,677 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:30:06,926 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:30:08,940 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:30:10,186 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:30:12,027 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:30:14,226 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:30:16,491 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:30:19,084 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:30:19,874 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:30:22,259 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:30:22,260 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:30:22,260 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:30:23,057 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:30:24,926 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:30:25,740 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:30:27,350 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:30:29,494 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:30:32,340 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:30:36,175 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:30:37,145 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:30:41,564 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:30:41,566 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:30:41,566 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:30:41,995 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:30:43,424 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:30:44,223 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:30:45,989 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:30:48,198 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:30:50,997 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:30:53,867 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:30:54,535 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:30:58,242 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:30:58,244 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:30:58,244 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:30:58,788 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:31:00,020 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:31:00,834 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:31:04,930 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:31:08,004 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:31:10,049 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:31:12,887 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:31:13,888 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:31:45,145 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:31:45,146 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:31:45,146 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:31:45,562 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:31:47,033 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:31:47,989 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:31:49,758 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:31:51,934 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:31:54,594 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:31:57,088 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:31:57,770 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:32:00,818 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:32:00,819 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:32:00,819 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:32:01,350 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:32:03,902 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:32:04,786 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:32:08,770 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:32:11,482 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:32:14,359 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:32:16,783 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:32:19,662 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:32:22,654 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:32:22,657 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:32:22,657 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:32:23,064 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:32:24,223 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:32:25,116 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:32:26,339 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:32:28,794 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:48:15,182 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 02:49:14,327 - openai._base_client - INFO - Retrying request to /chat/completions in 0.438054 seconds
2025-01-02 02:49:15,156 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:49:15,165 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='05727df9-a556-4068-981f-800715e81a86'
2025-01-02 02:49:15,173 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='d571becc-dd82-4d2a-ab2a-00cc226d3abf'
2025-01-02 02:49:15,174 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='fc357e13-aeb8-4438-9190-b684e70c9cb6'
2025-01-02 02:49:15,202 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='558f40d7-f19f-49e4-a0e9-02709e3520d2'
2025-01-02 02:49:15,203 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='7d68a479-9861-4a20-9fc0-504c8f32af6a'
2025-01-02 02:49:15,221 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='e592e9d1-e6c1-4a40-99db-f7839acdfdc4'
2025-01-02 02:49:15,222 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='5e3051fd-598a-43ae-b748-9a248f6a5ab8'
2025-01-02 02:49:15,240 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='e8f139e7-08eb-49d0-a3ae-6df669b57f31'
2025-01-02 02:49:15,242 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='fa35a9d3-db64-4954-ba3b-d84194182015'
2025-01-02 02:49:15,263 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='74ed6c70-aa92-4684-a04d-dda7a3b41cd0'
2025-01-02 02:49:15,265 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='027c5fac-abb7-4032-8ba9-cbf0ead86e43'
2025-01-02 02:49:15,285 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='85567efc-df3f-44e2-b5a1-de46660cde96'
2025-01-02 02:49:15,286 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='2a87db08-a2c6-40fa-81e7-bc0f397193aa'
2025-01-02 02:49:15,343 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='ea528c97-64d6-4a41-8e71-7c2a74c6796a'
2025-01-02 02:49:15,345 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='b220439b-f046-4bee-bd41-cf1f8c7672d4'
2025-01-02 02:49:15,347 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='621d41c1-976d-4e4a-98f3-0d6633fd0cf4'
2025-01-02 02:49:15,349 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='b4aa8462-7fc7-484c-854c-68ff87a93786'
2025-01-02 02:49:15,390 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='5aac189d-87b7-4ef7-9204-8c108149ddab'
2025-01-02 02:49:15,390 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='115d3e85-cd31-4eb0-879e-62f0edb571e0'
2025-01-02 02:49:15,409 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='3180650e-551b-480b-80df-542a577e3409'
2025-01-02 02:49:15,409 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='6aef3b72-e7fa-4bc6-9ab9-c793c325a9b0'
2025-01-02 02:49:15,433 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='cbd37c40-c417-4504-8c0e-aac8b479ed5d'
2025-01-02 02:49:15,434 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='e156d876-f5cb-4176-920a-fba35b30225b'
2025-01-02 02:49:15,454 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='d8357013-b5ce-4d7c-87d3-a158cc5cb921'
2025-01-02 02:49:15,455 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='6f34c7f0-cba0-4e82-b4dc-df3d846277a3'
2025-01-02 02:49:15,481 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='05f1c54f-6384-454e-bab5-5e127014f417'
2025-01-02 02:49:15,482 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='c7f145ca-496b-49ad-83d0-9b824b122a94'
2025-01-02 02:49:15,502 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='6007393e-6f8d-41d0-88a1-ecf0a2b82490'
2025-01-02 02:49:15,503 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='9641c890-0733-4b8c-823a-1b31e72faea8'
2025-01-02 02:49:15,551 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='7b38e2a8-7474-416f-addf-0b83eca095e1'
2025-01-02 02:49:15,552 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='dcee90d3-639c-4418-aab4-0ec7cda089b2'
2025-01-02 02:49:15,560 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='116fc3b0-67c6-4dcb-a9bd-a021923bb48e'
2025-01-02 02:49:15,561 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='57b05004-f8c5-4a66-bf57-c1f3b9e8d12a'
2025-01-02 02:49:15,583 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='45d7bd1f-0381-43e9-9ae7-3a2da8d04571'
2025-01-02 02:49:15,585 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='8501f08d-68d4-4167-9c7a-be19fe548038'
2025-01-02 02:49:15,605 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='e6d49c3c-1948-4474-9a29-acd923acdfe4'
2025-01-02 02:49:15,607 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='76090bd8-993d-4570-96ff-7dc429b0bc31'
2025-01-02 02:49:15,628 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='daab47bc-1a90-4f3a-97b6-75c6e107a218'
2025-01-02 02:49:15,630 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='abb1a136-027f-45b7-a677-adcdd69346c8'
2025-01-02 02:49:15,673 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='edb6c262-8203-4027-8728-f7e7ed29f503'
2025-01-02 02:49:15,675 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='3548b22a-2d3f-4c65-ac2c-cb11cd7b4533'
2025-01-02 02:49:15,677 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='1af58073-11dc-4b12-b7d5-640b461aa018'
2025-01-02 02:49:15,678 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='19caa567-4624-4401-b76d-f60138f727b0'
2025-01-02 02:49:15,706 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='e1c18493-268c-46ec-9bac-daa509e73c33'
2025-01-02 02:49:15,708 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='4384e10c-a1ac-4ea2-8013-5e1547a2bd3d'
2025-01-02 02:49:15,734 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='d249f6ae-e4f4-4756-a199-1e232b5a3505'
2025-01-02 02:49:15,735 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='659c30a8-d7ec-400f-911f-e80369b88fe6'
2025-01-02 02:49:15,752 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='4242428d-55ab-4d4f-88bc-235487a56b38'
2025-01-02 02:49:15,753 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='d573a8d8-fa2f-441c-964f-71a17f8d45ef'
2025-01-02 02:49:15,780 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='b9ee4f0e-29a6-41f0-801e-d4a9c247b023'
2025-01-02 02:49:15,781 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='5edcbc84-d53f-446d-82f5-98ad18ffadcd'
2025-01-02 02:49:15,808 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='81eed1a2-0ae4-4c37-82b5-774c79de4acc'
2025-01-02 02:49:15,810 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='f00c0be6-ef90-49f8-bb4d-f6a1998d3450'
2025-01-02 02:49:15,828 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='832f8465-ba1a-43b6-aa7e-2fd14bc586fe'
2025-01-02 02:49:15,829 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='921fe0a5-6a49-4128-869a-214c5786cc8a'
2025-01-02 02:49:15,869 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='8e873814-38be-42e9-bb0e-4e4a69fb0c24'
2025-01-02 02:49:15,871 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='aef34a28-c225-411e-abb1-cdba6f8d721d'
2025-01-02 02:49:15,874 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='eb84a077-40ed-4814-acbb-510edb0460e4'
2025-01-02 02:49:15,875 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='90dfa38e-2a05-432d-b2a6-9c37cf7dcddf'
2025-01-02 02:49:15,897 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='45dd4800-8a5e-4713-8189-7765f433755a'
2025-01-02 02:49:15,898 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='f73be995-dcde-40bc-aee1-9fbefb24dc5e'
2025-01-02 02:49:15,926 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='8052fd45-0628-4de8-aabb-93a4f6fb9d50'
2025-01-02 02:49:15,927 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='ba94af9a-c411-4e70-bfcf-f7cf0ae976ef'
2025-01-02 02:49:15,977 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='b8c09a9d-1048-4ff3-9bbd-2ed489d89431'
2025-01-02 02:49:15,979 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='096ea391-3c0b-4363-a531-a51f1000855d'
2025-01-02 02:49:15,981 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='ee419bcc-4ba3-436b-9d9a-324547254ddc'
2025-01-02 02:49:15,982 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='568c8112-e69b-4e3e-9b0c-b956aa033326'
2025-01-02 02:49:16,018 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='dcb69a41-8f7e-4fc5-8626-0b01f1e87262'
2025-01-02 02:49:16,019 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='60e5e2c6-4b5b-41b2-bf83-c2663b818449'
2025-01-02 02:49:16,028 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='277fe0aa-8009-41f5-a220-d23f6b78da81'
2025-01-02 02:49:16,029 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='5ae02894-acd7-4436-ad43-4fa3b4489540'
2025-01-02 02:49:16,038 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='9e809a06-9806-44e4-8405-e0e123a7dd78'
2025-01-02 02:49:16,039 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='6964e790-ae43-4111-a580-91cc04f075b6'
2025-01-02 02:49:16,077 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='e63e6655-f593-41b5-bbbd-bf41392de796'
2025-01-02 02:49:16,079 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='9a83f3b7-ab8b-421c-be87-00b68643f42e'
2025-01-02 02:49:16,102 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='4c2554d1-52c1-4f64-b5c2-4b952041d2a7'
2025-01-02 02:49:16,105 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='83bd9bdc-57ce-4d45-8d0a-f18ad4e80059'
2025-01-02 02:49:16,124 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='412ebb8a-8799-4778-ab15-2847ce66f7df'
2025-01-02 02:49:16,125 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='12c4c895-732a-4093-9ce1-e805aad3ff5e'
2025-01-02 02:49:16,126 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='04a6f7bd-ec1e-4c07-9ef0-9888bab5359b'
2025-01-02 02:49:16,141 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='cadfd42b-90b5-4fac-8c5f-caa8c80eb6f4'
2025-01-02 02:49:16,142 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='20b8e594-0510-42c1-b035-b498c0682c69'
2025-01-02 02:49:16,167 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='1e37a8b2-b842-4c61-86da-00aee6fd8935'
2025-01-02 02:49:16,169 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='60ed35c2-113d-4970-a81e-18b480e72a6b'
2025-01-02 02:49:16,206 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='a0ab5786-f9f9-4e8d-8fe5-a4fed3548704'
2025-01-02 02:49:16,208 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='d8db8f7a-b779-48b6-a25d-161d86bd6a6b'
2025-01-02 02:49:16,240 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='ae3de9ea-a941-42fc-8c4a-bd7c3da05e44'
2025-01-02 02:49:16,241 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='f21667b5-ed3e-43b2-9566-920efd0c238f'
2025-01-02 02:49:16,242 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='fdd4de21-4c77-4815-aaf8-68443a55cb3a'
2025-01-02 02:49:16,244 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='859a6eae-14a7-4435-8601-e78ac2b82bf2'
2025-01-02 02:49:16,300 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='35f8c21b-eca8-4420-96dd-b4f77de24548'
2025-01-02 02:49:16,302 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='bf82ae7b-ea2e-4724-b475-869b091dd046'
2025-01-02 02:49:16,328 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='d72439d8-8630-4c55-aaa8-eb54e26fbd40'
2025-01-02 02:49:16,329 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='8d6d1e5d-89dd-4dca-bf23-7888dd8c95c5'
2025-01-02 02:49:16,376 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='b88df242-c472-43bc-8c7d-c8d719246eda'
2025-01-02 02:49:16,378 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='55858094-7074-47e8-beb1-1bf0001f828f'
2025-01-02 02:49:16,380 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='a07c1865-4932-4a50-b676-306c0d8b9587'
2025-01-02 02:49:16,382 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='af4dc8b2-2675-4a88-9332-1c23af162215'
2025-01-02 02:49:16,402 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='495eaf21-9ae4-4091-8a54-00452004415c'
2025-01-02 02:49:16,404 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='d69b14b3-bba7-4dc2-8065-a2ae2808d13e'
2025-01-02 02:49:16,429 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='42abd320-11cc-4da7-bbe6-97a1f84abdda'
2025-01-02 02:49:16,430 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='ba72f2d4-ed8f-491c-8cfb-7255220513e3'
2025-01-02 02:49:16,460 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='d8fe4138-9428-4cc6-8ebb-a2b82ef2435e'
2025-01-02 02:49:16,462 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='a773a647-8a9f-4b96-89c8-688a7e94f966'
2025-01-02 02:49:16,479 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='1b03b4d6-8711-4a47-8966-6fce828b3546'
2025-01-02 02:49:16,480 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='aee6254e-e152-4a62-a77c-42328a070711'
2025-01-02 02:49:16,536 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='1616f528-b544-492c-98c9-78910e81adb4'
2025-01-02 02:49:16,538 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='64ed97f4-8057-453b-92e3-b1f76f2badca'
2025-01-02 02:49:16,542 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='6201c9b3-575e-4adf-b8a6-aa8fcf4a7e9f'
2025-01-02 02:49:16,543 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='3a8cdcf1-8d44-453c-8d9c-8e5ac7e32deb'
2025-01-02 02:49:16,564 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='5ee2f9b2-c871-431e-af75-3500c1a7b028'
2025-01-02 02:49:16,565 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='6656fc0a-2a32-4657-932e-9a696e213555'
2025-01-02 02:49:16,582 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='8aafea7a-a58b-4c13-abd1-96234621588e'
2025-01-02 02:49:16,583 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='3916dd56-7ae4-4487-98a2-5a84a517bca9'
2025-01-02 02:49:16,607 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='be11063b-3074-4283-aab3-8350c3905ba0'
2025-01-02 02:49:16,608 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='eb53b077-0896-4882-b755-02302393b348'
2025-01-02 02:49:16,651 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='d6bb3b7e-8c39-471a-92d2-6381dcd7387c'
2025-01-02 02:49:16,653 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='053c1d5a-cee4-4a40-905e-f178afc5159d'
2025-01-02 02:49:16,660 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='ba71fbef-f452-43c4-aa9d-08f8c3b71a9a'
2025-01-02 02:49:16,662 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='194e21de-daf5-4248-a906-f503ed4cfb68'
2025-01-02 02:49:16,689 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='09371852-130c-43db-999b-e5292b52bde5'
2025-01-02 02:49:16,691 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='4f8121ad-ee9c-4a51-8c76-9ea5501e144d'
2025-01-02 02:49:16,714 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='04dc5dd4-a2d8-4e84-9f6e-3070a4c7dc56'
2025-01-02 02:49:16,717 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='e404f644-5434-4a4a-bf38-3260ea143973'
2025-01-02 02:49:16,741 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='e33e5463-4d34-48d5-936e-9e1193226f8c'
2025-01-02 02:49:16,742 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='47c19c5b-d504-40c6-86c9-d349729cc896'
2025-01-02 02:49:16,770 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='2ad35861-27c0-42cd-80bb-0a8b7d34363f'
2025-01-02 02:49:16,771 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='8a774c65-fde3-4403-9b5b-02aaab020128'
2025-01-02 02:49:16,825 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='5c569832-7743-4664-86ea-0a5361b14c1c'
2025-01-02 02:49:16,826 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='86272b45-a0f0-45b6-9056-9d7c4f278d80'
2025-01-02 02:49:16,827 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='93288df4-8f4a-42ce-bc10-247b95883333'
2025-01-02 02:49:16,828 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='5df72183-309e-4bad-9bb5-a200bba258c8'
2025-01-02 02:49:16,854 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='6c2e8b7f-5c34-4734-a2d0-53842182761c'
2025-01-02 02:49:16,856 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='c478329b-b4ae-4886-891a-92a951c469db'
2025-01-02 02:49:16,878 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='cf9c91a3-a134-4657-9f92-72295850d512'
2025-01-02 02:49:16,879 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='a470426b-0411-4a17-8074-42ec3d305e0f'
2025-01-02 02:49:16,901 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='5c9017e3-b0fa-4eed-b9bf-408316fb84c6'
2025-01-02 02:49:16,903 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='1e2e6666-1ac3-4b46-bf41-3051766351fc'
2025-01-02 02:49:16,927 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='e2e18ed7-6e3c-4158-aa0e-de5185791335'
2025-01-02 02:49:16,929 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='c84a143b-9fa6-4d37-9a82-be10e94d4b01'
2025-01-02 02:49:16,951 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='0c9af92f-2eb9-4c25-9da2-39c04b64f398'
2025-01-02 02:49:16,953 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='9bebab01-675d-43eb-8ff1-afff2956ec17'
2025-01-02 02:49:16,982 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='2cd9cde6-7368-470a-a69d-ce9c2e858b56'
2025-01-02 02:49:16,984 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='aa39917a-32f9-4eb1-a7c9-554d0510b1f6'
2025-01-02 02:49:17,008 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='4bc13dd9-2f75-4db2-8701-f53036451c02'
2025-01-02 02:49:17,009 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='9d8588b8-4425-4254-a977-8cbc8c1d8455'
2025-01-02 02:49:17,036 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='2bf0d7f2-2397-48f6-bef1-19c45bc7b0fe'
2025-01-02 02:49:17,038 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='21a3f2b7-f149-4fa9-947c-1ec6f43129a9'
2025-01-02 02:49:17,053 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='5e0cc94f-9a78-4da9-a0b4-310491054e75'
2025-01-02 02:49:17,055 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='1fd753df-5d23-44cc-80b6-74ae338375a9'
2025-01-02 02:49:17,086 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='2414ba63-5e43-4df2-9bf9-cffd1be55c4b'
2025-01-02 02:49:17,089 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='917d1ec4-4693-4081-a0cf-064c45eb5447'
2025-01-02 02:49:17,104 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='d3860ba9-1a03-4ef3-8353-6f9b964e02c6'
2025-01-02 02:49:17,105 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='0fb26062-90e8-458c-8b4d-94a361274fc6'
2025-01-02 02:49:17,208 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='43825326-829c-4d4b-8bbd-4d6442d448e5'
2025-01-02 02:49:17,210 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='71fbeb38-d610-45e7-80c0-773e7a4f731c'
2025-01-02 02:49:17,234 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='eebc48ff-5109-49e5-a8c3-1021f8170e88'
2025-01-02 02:49:17,236 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='55be99a5-9ef3-42c7-8cec-6d133fc35944'
2025-01-02 02:49:17,266 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='7f23ff6a-962c-4c19-9c42-ae2e1339dca3'
2025-01-02 02:49:17,268 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='4360bbf0-d1f9-464d-bb47-bfcd8f56f821'
2025-01-02 02:49:17,296 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='0028fe6b-a287-46ac-a9e4-d6c6476840c4'
2025-01-02 02:49:17,297 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='93031b5c-5f41-4a45-bba8-1defe9fe6033'
2025-01-02 02:49:17,324 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='0d43a8c7-bb1a-4b86-ad41-a1f9b4991b2e'
2025-01-02 02:49:17,326 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='ff64e3ee-66f2-4701-bb40-9cf793a0640d'
2025-01-02 02:49:17,327 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='08c1bb49-2601-448e-8ebf-5d9eb8b16478'
2025-01-02 02:49:17,328 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='f64fd84b-5679-425b-8e1c-5a9df3566355'
2025-01-02 02:49:17,330 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3756444e-4b5d-44e6-9dbb-5c284c5ad15e', event.id_='658ad1f4-1bba-46b6-a569-f09a4e4ff022'
2025-01-02 02:49:17,548 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:49:18,273 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:49:20,698 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:49:20,699 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:49:20,700 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:49:21,054 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:49:22,818 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:49:23,732 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:49:25,573 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:49:27,829 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:49:30,593 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:49:33,562 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:49:34,207 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:49:43,033 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:49:43,035 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:49:43,035 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:49:43,384 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:49:44,857 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:49:45,681 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:49:49,539 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:49:51,994 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:49:54,245 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:49:56,106 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:49:56,810 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:49:59,144 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:49:59,145 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:49:59,145 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:49:59,571 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:50:01,616 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:50:03,775 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:50:05,923 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:50:08,993 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:50:11,658 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:50:16,451 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:50:19,850 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:50:22,767 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:50:22,769 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:50:22,769 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:50:24,904 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:50:26,115 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:50:26,916 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:50:28,349 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:50:30,398 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:50:32,641 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:50:34,094 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:50:34,759 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:50:36,476 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:50:36,476 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:50:36,477 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:50:37,256 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:50:38,350 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:50:39,200 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:50:40,638 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:57:40,189 - asyncio - ERROR - Exception in callback Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-a0e9fa43942d', bound_args=<BoundArgumen...ower door?"})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x344948540>)(<WorkflowHand...nthesize': ")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273
handle: <Handle Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-a0e9fa43942d', bound_args=<BoundArgumen...ower door?"})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x344948540>)(<WorkflowHand...nthesize': ")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 271, in __aiter__
    async for part in self._httpcore_stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 407, in __aiter__
    raise exc from None
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 403, in __aiter__
    async for part in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 342, in __aiter__
    raise exc
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 334, in __aiter__
    async for chunk in self._connection._receive_response_body(**kwargs):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 203, in _receive_response_body
    event = await self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 217, in _receive_event
    data = await self._network_stream.read(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_backends/anyio.py", line 32, in read
    with map_exceptions(exc_map):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 247, in _task
    new_ev = await instrumented_step(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/Documents/GitHub/AITA-Judge-Agent/src/agent/AITA_Agent.py", line 126, in synthesize
    response = await response_synthesizer.asynthesize(query, nodes=ev.nodes)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/base.py", line 306, in asynthesize
    response_str = await self.aget_response(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 370, in aget_response
    response = await self._arefine_response_single(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 396, in _arefine_response_single
    response = await aget_response_text(response)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response/utils.py", line 17, in aget_response_text
    async for response in response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/llm.py", line 151, in gen
    async for response in chat_response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/callbacks.py", line 88, in wrapped_gen
    async for x in f_return_val:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/llms/openai/base.py", line 724, in gen
    async for response in await aclient.chat.completions.create(
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 147, in __aiter__
    async for item in self._iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 160, in __stream__
    async for sse in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 151, in _iter_events
    async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 302, in aiter_bytes
    async for chunk in self._aiter_chunks(iterator):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 313, in _aiter_chunks
    async for chunk in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 997, in aiter_bytes
    async for raw_bytes in self.aiter_raw():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 1055, in aiter_raw
    async for raw_stream_bytes in self.stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_client.py", line 176, in __aiter__
    async for chunk in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 270, in __aiter__
    with map_httpcore_exceptions():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/asyncio/events.py", line 84, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 285, in handle_future_result
    raise exception
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 440, in _run_workflow
    raise exception_raised
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 254, in _task
    raise WorkflowRuntimeError(
llama_index.core.workflow.errors.WorkflowRuntimeError: Error in step 'synthesize': 
2025-01-02 02:57:40,197 - src.agent.evaluation.eval_util - WARNING - Error processing sample 37: Error in step 'synthesize': 
2025-01-02 02:57:40,212 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:57:40,213 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:57:40,214 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:57:40,697 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:57:42,430 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:57:43,231 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:57:46,425 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:57:48,988 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:57:52,267 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:57:54,362 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:57:55,135 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:57:57,057 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:57:57,058 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:57:57,058 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:57:57,498 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:57:58,653 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:57:59,541 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:58:01,004 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:58:04,554 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:58:06,808 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:58:08,506 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:58:09,073 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:58:10,649 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:58:10,650 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:58:10,650 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:58:11,174 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:58:12,744 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:58:13,875 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:58:15,070 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:58:17,149 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:58:19,095 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:58:20,767 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 02:58:21,343 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:58:23,122 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 02:58:23,124 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 02:58:23,124 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 02:58:23,604 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 02:58:24,740 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 02:58:25,547 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 02:58:26,776 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:02:34,846 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:02:34,848 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='665a4f1e-ddd6-4559-8961-f42039a81e1d'
2025-01-02 03:02:34,850 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='95925f9d-a33c-4b9b-b26e-3cf74f2c3ba5'
2025-01-02 03:02:34,850 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='f016121c-21ee-4981-bb21-00f3b93975a3'
2025-01-02 03:02:34,870 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='5c0a8619-dd53-4e12-b757-a150f60198f8'
2025-01-02 03:02:34,870 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='1034ed94-8cb0-4385-9d2a-a618a7afed26'
2025-01-02 03:02:34,897 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='871b9cb6-2502-4fb7-8816-d8ffe48d8cd0'
2025-01-02 03:02:34,899 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='ba7adc8d-88e6-4c7a-be1a-18fc6c8be6f1'
2025-01-02 03:02:34,923 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='1e9a75ef-d92b-4662-9db3-42d4c5ec3602'
2025-01-02 03:02:34,924 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='609aa264-28cf-40b6-8114-741e64e0077a'
2025-01-02 03:02:34,951 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='464eee08-1d5d-4d39-8c05-88036229b620'
2025-01-02 03:02:34,953 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='1cee59c9-a593-4a00-b401-ff671ce56fea'
2025-01-02 03:02:34,976 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='d0962745-1800-4c57-b7fc-bfd3fe971cb7'
2025-01-02 03:02:34,978 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='49b8b411-ca34-4bc6-9b5d-b66729863452'
2025-01-02 03:02:35,004 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='1b59a459-3a17-459f-a30e-6ec0e56dbde0'
2025-01-02 03:02:35,007 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='f8b09564-6c4c-4495-abd1-a87eb4604987'
2025-01-02 03:02:35,033 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='473326de-842e-4785-8eba-36667252f47f'
2025-01-02 03:02:35,034 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='cf3510af-c926-4d80-8cab-06166448bfba'
2025-01-02 03:02:35,062 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='9cfb4ebf-6015-4fda-a351-f564992c4ce7'
2025-01-02 03:02:35,063 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='a2c4571f-e213-4bdb-803e-de44d27323bc'
2025-01-02 03:02:35,084 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='4e2d64a0-6f98-4c69-919a-6f0c1eca86aa'
2025-01-02 03:02:35,086 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='8f75e007-5799-4791-9342-dbb0f0eeaaa6'
2025-01-02 03:02:35,120 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='39b2805d-150f-49ff-bcf7-c4f166bbd70e'
2025-01-02 03:02:35,122 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='6a01da81-e64b-44b3-9295-70f957e379a4'
2025-01-02 03:02:35,143 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='23d72dc1-7c39-4663-9030-0ff4befd52a0'
2025-01-02 03:02:35,145 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='204a29cf-90e0-4df5-b0b9-c837ec1aa2b0'
2025-01-02 03:02:35,168 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='9e285530-96a8-49d9-968c-2c5e9f2858a2'
2025-01-02 03:02:35,169 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='981cf3ef-7830-44c5-b3ea-2bf7efa89619'
2025-01-02 03:02:35,197 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='c0c8e77a-be5c-4bb6-a145-f04b121fa3f7'
2025-01-02 03:02:35,197 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='c6a0c35c-3a66-4ee6-9016-3ea32f9765a5'
2025-01-02 03:02:35,239 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='b2836a88-d07f-41ce-8bfc-2203d05d0cb5'
2025-01-02 03:02:35,240 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='e7640825-18ad-4c30-a513-668e880a7697'
2025-01-02 03:02:35,255 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='a5730fb3-d10d-4a66-b7e0-0c1d6e633ffc'
2025-01-02 03:02:35,255 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='cccb022d-f3e2-4d55-9896-46427600fa9f'
2025-01-02 03:02:35,287 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='c488de01-bd86-4a31-b4eb-fa8377363232'
2025-01-02 03:02:35,288 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='caf42996-595e-409b-af0d-2a9203c22275'
2025-01-02 03:02:35,307 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='129a6d4c-b5ae-4fc9-9047-e3c5398695ed'
2025-01-02 03:02:35,307 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='86424847-efb9-42e6-affe-19b3414844e8'
2025-01-02 03:02:35,384 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='a0be11c1-f246-4e82-bba2-d4b68d85eebb'
2025-01-02 03:02:35,385 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='75f26929-bcc5-4713-94fd-641e4d0c208d'
2025-01-02 03:02:35,386 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='a0c9e41f-0ce8-49d8-a545-b36298acbbdb'
2025-01-02 03:02:35,386 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='4bc6d324-0355-491c-96ba-8049e3821d08'
2025-01-02 03:02:35,405 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='cd04d000-1041-435f-8192-e88bf86f8448'
2025-01-02 03:02:35,405 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='5fb6bd80-8e4f-4074-b428-ba5c47306ea2'
2025-01-02 03:02:35,510 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='9809066a-49b2-40cf-af42-8795f6177ab3'
2025-01-02 03:02:35,511 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='0d6f4025-2764-49c0-b74b-6d6e596f2608'
2025-01-02 03:02:35,512 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='d31e7754-4c7e-483c-820a-5b6eb85d35a3'
2025-01-02 03:02:35,512 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='711558ef-8908-44c0-9017-f1fadd9cd555'
2025-01-02 03:02:35,520 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='6b252c89-22d4-4c50-9e6d-6737a2c830cc'
2025-01-02 03:02:35,521 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='2ef26008-9053-4eee-9b1b-495c6a567825'
2025-01-02 03:02:35,550 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='644306d9-e4bf-4805-9c2b-958d401e0825'
2025-01-02 03:02:35,551 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='cfd16c37-0380-4e77-9a45-c8aec7690453'
2025-01-02 03:02:35,584 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='278e3fcd-0ad2-4744-89a0-e08971f0c1a7'
2025-01-02 03:02:35,585 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='18a78cdf-d32a-4548-852d-58b280224b71'
2025-01-02 03:02:35,610 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='fc4fa951-e0ec-4e8a-a0a9-70c3cb6b9d2d'
2025-01-02 03:02:35,611 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='a76d18c2-76c6-427c-b1ad-12dee0e3c5d1'
2025-01-02 03:02:35,630 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='684f4d40-a5d4-4bf8-aff8-ba4da4c34df6'
2025-01-02 03:02:35,632 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='66039e43-d986-4d77-89cc-f6220cad76ac'
2025-01-02 03:02:35,666 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='1ac3bd79-75d2-43a0-958f-d1894d0d0f6c'
2025-01-02 03:02:35,667 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='bde63a36-2fc0-4c82-8ab2-41de9fbac05b'
2025-01-02 03:02:35,689 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='4608a337-0698-43fe-a3ed-9321afc508f2'
2025-01-02 03:02:35,691 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='f3fb66cb-9c11-4f1b-987d-0dcf3a7e827e'
2025-01-02 03:02:35,753 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='02fb8484-306b-47ed-868c-29d2dbe43ba8'
2025-01-02 03:02:35,756 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='07571cc3-0032-4de2-9376-3d3f0dbfb9ec'
2025-01-02 03:02:35,759 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='e73615da-45b5-40e4-b70f-f9dc07c4582f'
2025-01-02 03:02:35,761 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='d25c8eb5-4b3a-4e01-b69e-c23708385e6a'
2025-01-02 03:02:35,792 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='73d3f972-8cf2-444f-872d-bf331189d639'
2025-01-02 03:02:35,794 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='a1d7e897-f5e6-459c-af4a-d4ae8dab3d32'
2025-01-02 03:02:35,839 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='cd4e2236-ef8c-4a61-84d1-e95744f1d23f'
2025-01-02 03:02:35,841 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='4c75790c-9d9e-4241-932f-09f3a4f4d511'
2025-01-02 03:02:35,870 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='52076179-655c-41f6-95e2-d7ed0c838049'
2025-01-02 03:02:35,872 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='98405268-faa6-4b7c-b6e3-b013fdad948b'
2025-01-02 03:02:35,885 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='d20ca956-3881-4389-b022-80b025292d30'
2025-01-02 03:02:35,887 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='dd86e023-38d4-4622-9490-9365054b041b'
2025-01-02 03:02:35,895 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='d1751ade-59e5-4350-bf86-dd69b5ddc634'
2025-01-02 03:02:35,896 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='661a6601-f029-466f-882a-8cf799906e7f'
2025-01-02 03:02:35,912 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='a6563d2c-9030-4360-a4b3-e2de3c514c28'
2025-01-02 03:02:35,913 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='2d102ca6-99a3-403e-b505-d1da956a8a49'
2025-01-02 03:02:36,060 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='07fe0998-013c-4560-8bab-df51253ec090'
2025-01-02 03:02:36,063 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='496acb62-1eed-4b73-90fc-64c7f9362bd5'
2025-01-02 03:02:36,066 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='9d478fa5-94fe-4f95-8998-e32923a55405'
2025-01-02 03:02:36,067 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='521878b3-cc0f-4111-973a-3e4aaf64e94d'
2025-01-02 03:02:36,069 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='ae0b6963-e49a-4057-a5b8-b35ccd813d8e'
2025-01-02 03:02:36,070 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='388a5dec-fdc5-48f5-9d8c-28dfe2cc4139'
2025-01-02 03:02:36,072 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='385836c8-8576-4680-9d22-279b1ae45d84'
2025-01-02 03:02:36,073 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='ce54ff41-f9c0-4ef5-b9d3-95069b3cfa0b'
2025-01-02 03:02:36,098 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='44e3e862-818e-435b-816e-db543ae030c5'
2025-01-02 03:02:36,100 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='7b47861d-2074-4712-b4ae-9e93bca0819e'
2025-01-02 03:02:36,126 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='80e59b1e-8440-456a-8617-04d4b55107d7'
2025-01-02 03:02:36,127 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='d8b38f4e-b20c-4bd2-a8d5-a935bfd616af'
2025-01-02 03:02:36,162 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='de1de87a-3b09-49dd-a2ed-f5adfbc0a14f'
2025-01-02 03:02:36,164 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='c64be3e9-34cb-4a8b-818a-5b238ef1e73a'
2025-01-02 03:02:36,189 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='a661582f-d129-4368-a36c-c086e1815ebc'
2025-01-02 03:02:36,190 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='df84fae1-0bf8-40e2-afa5-3d6490d54843'
2025-01-02 03:02:36,239 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='766a6ec8-b18c-4e25-b040-35359b291045'
2025-01-02 03:02:36,240 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='0dd84360-2770-4e77-ab6a-eb7395a92d01'
2025-01-02 03:02:36,253 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='3f91a317-03d8-4bc3-88e9-e9801158fce7'
2025-01-02 03:02:36,254 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='8cbe743c-fe64-4b07-94a5-f276fa52abda'
2025-01-02 03:02:36,274 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='17b9e592-ce32-4929-a97e-f43dcb9f05bb'
2025-01-02 03:02:36,275 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='c2b00b4f-a17f-40e6-9b98-698e24730375'
2025-01-02 03:02:36,328 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='44a802a1-b1b4-4b66-a2b5-8924a28903b8'
2025-01-02 03:02:36,330 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='05feba51-704b-4801-ba2c-838993a73102'
2025-01-02 03:02:36,347 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='288e58ac-e992-4c71-9885-a9769cfee241'
2025-01-02 03:02:36,348 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='0b581612-df65-40a7-8e07-da4cbbb41e08'
2025-01-02 03:02:36,391 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='2ee4e798-b438-4879-8446-25be8db24b0d'
2025-01-02 03:02:36,393 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='e8c7fec3-478d-400d-ab12-a85f592fb736'
2025-01-02 03:02:36,425 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='5378a500-4baf-4009-aca6-36c41c9c8178'
2025-01-02 03:02:36,426 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='bb38bdb9-f5ce-4760-8b75-c6a8573af519'
2025-01-02 03:02:36,453 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='0a9d4102-3566-4ee5-85ea-29b053329914'
2025-01-02 03:02:36,454 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='f7f83407-6b10-4bc6-a81f-fa467d6efc7e'
2025-01-02 03:02:36,500 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='53160d91-ce82-49f1-8f16-b2d89d07c0cd'
2025-01-02 03:02:36,502 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='a3f2ff70-b5c1-4498-a838-97e641bb08ca'
2025-01-02 03:02:36,524 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='481d3177-9878-46fb-aacf-43cbe4c26c3c'
2025-01-02 03:02:36,526 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='738c764b-b12e-4a74-be7d-24498843ea66'
2025-01-02 03:02:36,535 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='0258b5ed-675e-4bcb-82ba-3368b0d73ac1'
2025-01-02 03:02:36,537 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='49df8538-6833-4311-9b3d-2bdc3ef41a0e'
2025-01-02 03:02:36,544 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='bc543a46-aec9-4c84-890b-baa086407fba'
2025-01-02 03:02:36,546 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='aa14791f-fc1a-492a-8053-473aab6be86f'
2025-01-02 03:02:36,580 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='597ed287-9d62-4645-b97d-8c9045d7e912'
2025-01-02 03:02:36,581 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='5191844f-d4d6-45a7-a82d-2e8b9efb98a5'
2025-01-02 03:02:36,604 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='8d22d03c-fd6a-4790-a9fb-b1ee3baf9b8a'
2025-01-02 03:02:36,606 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='ff8fda1d-4e76-42f7-9bdf-188dc864d493'
2025-01-02 03:02:36,624 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='525d3e44-140b-483d-a6d4-082858f15f3b'
2025-01-02 03:02:36,625 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='c1298998-f41c-487d-9a54-9d44a8ea1805'
2025-01-02 03:02:36,628 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='cdc8e839-f814-42dd-9e6c-92d77a74286f'
2025-01-02 03:02:36,630 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-0fe68279-8a7d-4487-a9ba-e2a7b2f3351e', event.id_='55518197-7362-456b-bf06-868620f66828'
2025-01-02 03:02:37,150 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:02:40,128 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:02:40,841 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:02:43,408 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:02:43,409 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:02:43,409 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:02:44,280 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:02:46,246 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:02:47,086 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:02:48,665 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:02:52,740 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:02:55,657 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:02:59,815 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:03:00,628 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:03:03,741 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:03:03,742 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:03:03,742 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:03:04,207 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:03:05,391 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:03:06,141 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:03:08,285 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:03:10,740 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:03:14,868 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:03:18,102 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:03:18,644 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:03:21,388 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:03:21,390 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:03:21,390 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:03:21,804 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:20:23,237 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 03:20:24,470 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:20:25,234 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:20:26,370 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:20:28,675 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:20:31,225 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:20:33,852 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:20:34,488 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:20:36,745 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:20:36,745 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:20:36,746 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:20:37,172 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:20:38,486 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:20:39,243 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:20:40,772 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:20:44,735 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:20:49,592 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:20:54,024 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:20:54,649 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:20:59,365 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:20:59,367 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:20:59,367 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:20:59,910 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:21:01,976 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:21:04,703 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:21:06,565 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:21:11,890 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:21:14,483 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:21:16,881 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:21:17,724 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:21:20,014 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:21:20,016 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:21:20,016 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:21:20,593 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:21:21,628 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:21:22,344 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:21:23,523 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:21:25,916 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:21:28,374 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:21:29,640 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:21:30,187 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:21:33,127 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:21:33,128 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:21:33,129 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:21:33,801 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:21:34,885 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:21:35,735 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:21:37,591 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:21:39,332 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:21:42,197 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:21:45,361 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:21:45,984 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:21:52,147 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:21:52,148 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:21:52,148 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:21:52,390 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:21:53,528 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:21:54,545 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:21:56,020 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:21:58,276 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:22:00,500 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:22:02,981 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:22:03,700 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:22:05,285 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:22:05,286 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:22:05,286 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:22:05,611 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:22:06,777 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:22:07,521 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:22:09,033 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:22:11,177 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:22:12,635 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:22:15,579 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:22:16,299 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:22:17,834 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:22:17,835 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:22:17,835 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:22:18,313 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:22:20,494 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:22:21,320 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:22:22,644 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:22:25,217 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:22:27,666 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:22:30,854 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:22:31,560 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:22:33,801 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:22:33,801 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:22:33,801 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:22:34,177 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:22:35,359 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:22:36,281 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:22:38,109 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:22:39,795 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:22:41,285 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:22:42,822 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:22:43,539 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:22:45,432 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:22:45,433 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:22:45,433 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:22:45,818 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:22:47,371 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:22:48,594 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:22:53,098 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:22:55,109 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:22:57,157 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:23:02,761 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:23:03,609 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:23:05,936 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:23:05,937 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:23:05,937 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:23:06,246 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:23:07,904 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:23:08,729 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:23:10,264 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:23:11,811 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:23:13,849 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:23:15,374 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:23:16,100 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:23:18,671 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:23:18,674 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:23:18,674 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:23:19,069 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:23:20,157 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:23:21,018 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:23:22,106 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:23:24,369 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:23:26,237 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:23:29,299 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:23:30,028 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:23:31,337 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:23:31,338 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:23:31,338 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:23:31,767 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:23:32,827 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:23:33,714 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:23:35,149 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:23:38,015 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:23:39,977 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:23:41,974 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:23:42,601 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:23:44,783 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:23:44,783 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:23:44,784 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:23:45,367 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:23:46,412 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:23:47,231 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:23:48,980 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:23:53,172 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:23:54,912 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:23:57,059 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:23:57,676 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:23:59,968 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:23:59,970 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:23:59,970 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:24:00,648 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:24:04,432 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:24:05,206 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:24:07,098 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:24:09,038 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:24:12,214 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:24:14,750 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:24:15,440 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:24:18,387 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:24:18,388 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:24:18,389 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:24:18,771 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:24:21,023 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:24:21,844 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:24:23,585 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:24:26,042 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:24:30,547 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:24:33,626 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:24:34,337 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:24:36,469 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:24:36,471 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:24:36,471 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:24:36,900 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:24:38,151 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:24:39,051 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:24:40,686 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:24:42,800 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:24:47,642 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:24:52,263 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:24:52,907 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:24:54,651 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:24:54,652 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:24:54,652 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:24:55,126 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:24:56,185 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:24:57,494 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:24:58,859 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:25:00,822 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:25:03,531 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:25:08,492 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:25:09,841 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:25:11,717 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:25:11,719 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:25:11,719 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:25:12,126 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:25:13,756 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:25:14,541 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:25:17,375 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:25:20,531 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:25:28,329 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:25:31,027 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:25:31,788 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:25:34,321 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:25:34,323 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:25:34,323 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:25:34,645 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:25:35,736 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:25:36,495 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:25:37,723 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:25:39,157 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:25:40,693 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:25:42,331 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:25:42,944 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:25:45,498 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:25:45,499 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:25:45,499 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:25:45,918 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:25:47,025 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:25:48,201 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:25:51,430 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:25:53,700 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:25:57,180 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:25:59,759 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:26:00,561 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:26:03,507 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:26:03,508 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:26:03,508 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:26:06,398 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:26:07,600 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:26:08,445 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:26:10,494 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:26:12,938 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:26:15,102 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:26:17,421 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:26:18,175 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:26:20,147 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:26:20,149 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:26:20,149 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:26:20,632 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:26:21,744 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:26:22,577 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:26:24,620 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:26:26,466 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:26:28,717 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:26:31,123 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:26:31,895 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:26:34,623 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:26:34,623 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:26:34,624 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:26:35,174 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:26:36,234 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:26:37,117 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:26:38,362 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:26:41,111 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:26:43,056 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:26:44,683 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:26:45,315 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:26:48,166 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:26:48,167 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:26:48,168 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:26:48,597 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:26:50,453 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:26:53,196 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:26:55,037 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:26:56,881 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:26:58,928 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:27:02,685 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:27:05,792 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:27:07,366 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:27:07,368 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:27:07,368 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:27:07,939 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:27:09,093 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:27:09,887 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:27:11,316 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:27:13,061 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:27:16,128 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:27:17,754 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:27:18,487 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:27:19,675 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:27:19,676 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:27:19,676 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:27:20,127 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:27:21,205 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:27:21,969 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:27:23,811 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:27:25,655 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:27:27,805 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:27:30,976 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:27:31,698 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:27:33,622 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:27:33,623 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:27:33,623 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:27:34,159 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:27:35,243 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:27:36,205 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:27:37,533 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:27:39,374 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:27:41,018 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:27:43,343 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:27:44,059 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:27:47,030 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:27:47,031 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:27:47,032 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:27:47,458 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:27:48,683 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:27:49,470 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:27:52,687 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:27:55,046 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:27:57,297 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:27:58,772 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:27:59,464 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:28:02,759 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:28:02,760 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:28:02,761 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:28:03,050 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:28:04,909 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:28:05,901 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:28:08,152 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:28:10,099 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:28:13,608 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:28:14,701 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:28:15,330 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:28:18,492 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:28:18,494 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:28:18,494 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:28:19,112 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:28:20,190 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:28:20,954 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:28:22,797 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:28:25,154 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:28:28,120 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:28:30,686 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:28:31,261 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:28:36,268 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:28:36,269 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:28:36,269 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:28:39,186 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:28:40,269 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:28:41,231 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:28:45,837 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:28:48,080 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:28:52,289 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:28:55,549 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:28:56,487 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:28:58,136 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:28:58,139 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:28:58,139 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:28:58,506 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:28:59,582 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:29:00,480 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:29:04,575 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:29:05,945 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:29:08,157 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:29:09,885 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:29:10,619 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:29:12,404 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:29:12,405 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:29:12,405 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:29:12,772 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:29:13,836 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:29:14,713 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:29:16,147 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:29:17,887 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:29:19,728 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:29:25,495 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:29:26,389 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:29:29,426 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:29:29,427 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:29:29,427 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:29:30,360 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:29:31,493 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:29:32,329 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:29:34,171 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:29:36,219 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:29:37,960 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:29:39,494 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:29:40,214 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:29:41,519 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:29:41,521 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:29:41,521 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:29:41,956 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:29:43,008 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:29:43,796 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:29:45,231 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:29:49,994 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:29:52,913 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:29:54,877 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:29:55,574 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:29:58,061 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:29:58,062 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:29:58,063 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:29:58,319 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:29:59,536 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:30:00,387 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:30:03,460 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:30:06,019 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:30:07,760 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:30:10,827 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:30:11,549 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:30:12,987 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:30:12,987 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:30:12,988 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:30:13,598 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:30:15,337 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:30:16,569 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:30:18,304 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:30:20,355 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:30:23,480 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:30:26,064 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:30:26,704 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:30:29,533 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:30:29,535 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:30:29,535 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:30:29,824 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:30:30,948 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:30:31,824 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:30:33,564 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:30:35,104 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:30:37,969 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:30:40,332 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:30:41,039 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:30:47,100 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:30:47,101 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:30:47,101 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:30:47,555 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:30:48,728 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:30:49,578 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:30:52,741 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:30:55,170 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:30:57,573 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:30:59,265 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:30:59,984 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:31:04,299 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:31:04,301 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:31:04,301 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:31:04,543 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:31:05,631 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:31:06,847 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:31:07,993 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:31:09,915 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:31:12,376 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:31:13,711 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:31:14,423 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:31:15,911 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:31:15,911 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:31:15,912 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:31:16,679 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:31:17,847 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:31:18,829 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:31:20,261 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:31:23,027 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:31:25,278 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:31:27,951 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:31:28,655 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:31:30,711 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:31:30,711 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:31:30,712 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:31:31,115 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:31:32,249 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:31:33,063 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:31:34,800 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:31:37,363 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:31:40,538 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:31:42,556 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:31:42,950 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:31:42,951 - openai._base_client - INFO - Retrying request to /chat/completions in 0.604000 seconds
2025-01-02 03:31:44,016 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:31:45,688 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:31:45,689 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:31:45,689 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:31:46,066 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:31:48,242 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:31:49,239 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:31:52,601 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:31:56,613 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:31:59,275 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:32:02,565 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:32:03,268 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:32:05,308 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:32:05,308 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:32:05,309 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:32:05,730 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:32:06,849 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:32:07,777 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:32:10,746 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:32:12,279 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:32:14,292 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:32:14,294 - openai._base_client - INFO - Retrying request to /chat/completions in 1.308000 seconds
2025-01-02 03:32:16,070 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:32:17,779 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:32:18,273 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:32:18,275 - openai._base_client - INFO - Retrying request to /chat/completions in 0.992000 seconds
2025-01-02 03:32:19,564 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:32:22,172 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:32:22,174 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:32:22,174 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:32:23,006 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:32:24,160 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:32:25,287 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:32:26,615 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:32:28,710 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:32:28,712 - openai._base_client - INFO - Retrying request to /chat/completions in 0.424000 seconds
2025-01-02 03:32:29,449 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:32:32,965 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:32:36,265 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:32:36,960 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:32:41,070 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:32:41,071 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:32:41,072 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:32:41,414 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:32:42,554 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:32:43,414 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:32:44,332 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:32:46,562 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:32:48,042 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:32:52,385 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:32:53,342 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:32:54,852 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:32:54,853 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:32:54,853 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:32:55,496 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:32:56,600 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:32:57,544 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:33:01,225 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:33:03,478 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:33:05,224 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:33:06,915 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:33:07,316 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:33:07,317 - openai._base_client - INFO - Retrying request to /chat/completions in 0.820000 seconds
2025-01-02 03:33:08,603 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:33:10,499 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:33:10,500 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:33:10,500 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:33:10,781 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:33:12,063 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:33:13,213 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:33:15,017 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:33:15,018 - openai._base_client - INFO - Retrying request to /chat/completions in 0.836000 seconds
2025-01-02 03:33:16,281 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:33:18,325 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:33:18,327 - openai._base_client - INFO - Retrying request to /chat/completions in 1.708000 seconds
2025-01-02 03:33:20,350 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:33:22,444 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:33:22,446 - openai._base_client - INFO - Retrying request to /chat/completions in 1.830000 seconds
2025-01-02 03:33:24,782 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:33:27,064 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:33:27,463 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:33:27,464 - openai._base_client - INFO - Retrying request to /chat/completions in 0.284000 seconds
2025-01-02 03:33:28,086 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:33:30,474 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:33:30,474 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:33:30,474 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:33:30,927 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:33:32,176 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:33:32,975 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:33:34,299 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:33:34,301 - openai._base_client - INFO - Retrying request to /chat/completions in 0.958000 seconds
2025-01-02 03:33:36,047 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:33:37,886 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:33:37,888 - openai._base_client - INFO - Retrying request to /chat/completions in 1.772000 seconds
2025-01-02 03:33:40,348 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:33:42,246 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:33:42,248 - openai._base_client - INFO - Retrying request to /chat/completions in 2.012000 seconds
2025-01-02 03:33:44,647 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:33:46,843 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:33:47,232 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:33:47,233 - openai._base_client - INFO - Retrying request to /chat/completions in 0.610000 seconds
2025-01-02 03:33:48,241 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:33:52,283 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:33:52,285 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:33:52,285 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:33:52,739 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:33:53,780 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:33:54,584 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:33:55,501 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:33:56,835 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:33:58,370 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:34:00,360 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:34:01,033 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:34:03,593 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:34:03,594 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:34:03,594 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:34:03,865 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:34:05,031 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:34:06,052 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:34:08,842 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:34:08,844 - openai._base_client - INFO - Retrying request to /chat/completions in 0.008000 seconds
2025-01-02 03:34:09,326 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:34:10,996 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:34:10,997 - openai._base_client - INFO - Retrying request to /chat/completions in 2.146000 seconds
2025-01-02 03:34:13,459 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:34:15,177 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:34:15,178 - openai._base_client - INFO - Retrying request to /chat/completions in 1.996000 seconds
2025-01-02 03:34:17,518 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:34:19,302 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:34:19,732 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:34:19,734 - openai._base_client - INFO - Retrying request to /chat/completions in 1.666000 seconds
2025-01-02 03:34:21,788 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:34:23,364 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:34:23,366 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:34:23,367 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:34:23,975 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:34:25,084 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:34:26,118 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:34:27,276 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:34:27,278 - openai._base_client - INFO - Retrying request to /chat/completions in 0.286000 seconds
2025-01-02 03:34:27,964 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:34:29,229 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:34:29,230 - openai._base_client - INFO - Retrying request to /chat/completions in 2.226000 seconds
2025-01-02 03:34:31,786 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:34:33,733 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:34:33,735 - openai._base_client - INFO - Retrying request to /chat/completions in 1.324000 seconds
2025-01-02 03:34:35,342 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:34:37,840 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:34:38,223 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:34:38,225 - openai._base_client - INFO - Retrying request to /chat/completions in 0.864000 seconds
2025-01-02 03:34:39,489 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:34:41,056 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:34:41,057 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:34:41,057 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:34:41,483 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:34:42,534 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:34:43,428 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:34:44,860 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:34:45,714 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:34:45,715 - openai._base_client - INFO - Retrying request to /chat/completions in 1.614000 seconds
2025-01-02 03:34:47,682 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:34:51,256 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:34:53,845 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:34:54,414 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:34:57,666 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:34:57,668 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:34:57,668 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:34:58,175 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:34:59,296 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:35:00,122 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:35:01,605 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:35:04,541 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:35:04,543 - openai._base_client - INFO - Retrying request to /chat/completions in 0.020000 seconds
2025-01-02 03:35:04,932 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:35:06,750 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:35:06,751 - openai._base_client - INFO - Retrying request to /chat/completions in 1.988000 seconds
2025-01-02 03:35:11,414 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:35:12,812 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:35:13,375 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:35:15,724 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:35:15,725 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:35:15,725 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:35:16,274 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:35:17,832 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:35:21,831 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:35:27,678 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:35:30,123 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:35:32,684 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:35:34,447 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:35:35,240 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:35:36,679 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:35:36,680 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:35:36,681 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:35:37,108 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:35:38,151 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:35:38,930 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:35:40,159 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:35:42,105 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:35:43,844 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:35:47,344 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:35:47,963 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:35:52,218 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:35:52,218 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:35:52,219 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:35:52,752 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:35:54,388 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:35:55,420 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:35:56,676 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:35:58,795 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:36:01,151 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:36:03,274 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:36:04,019 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:36:05,576 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:36:05,576 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:36:05,577 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:36:06,068 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:36:07,133 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:36:07,845 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:36:09,135 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:36:10,981 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:36:12,824 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:36:14,305 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:36:14,702 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:36:14,704 - openai._base_client - INFO - Retrying request to /chat/completions in 0.234000 seconds
2025-01-02 03:36:15,463 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:36:17,456 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:36:17,457 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:36:17,457 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:36:18,048 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:36:19,157 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:36:19,995 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:36:21,221 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:36:23,279 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:36:25,590 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:36:27,621 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:36:28,080 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:36:28,083 - openai._base_client - INFO - Retrying request to /chat/completions in 0.386000 seconds
2025-01-02 03:36:28,902 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:36:30,548 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:36:30,549 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:36:30,550 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:36:31,053 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:36:32,117 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:36:32,896 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:36:33,711 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:36:33,712 - openai._base_client - INFO - Retrying request to /chat/completions in 1.638000 seconds
2025-01-02 03:36:35,762 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:36:38,152 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:36:38,155 - openai._base_client - INFO - Retrying request to /chat/completions in 0.610000 seconds
2025-01-02 03:36:39,453 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:36:40,608 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:36:40,609 - openai._base_client - INFO - Retrying request to /chat/completions in 1.842000 seconds
2025-01-02 03:36:43,239 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:36:45,323 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:36:45,703 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:36:45,705 - openai._base_client - INFO - Retrying request to /chat/completions in 0.262000 seconds
2025-01-02 03:36:46,411 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:36:52,463 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:36:52,465 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:36:52,465 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:36:53,082 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:36:54,190 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:36:55,015 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:36:57,268 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:36:59,212 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:37:04,027 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:37:08,113 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:37:08,839 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:37:10,579 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:37:10,580 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:37:10,580 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:37:11,194 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:37:12,277 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:37:13,141 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:37:14,439 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:37:16,129 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:37:16,130 - openai._base_client - INFO - Retrying request to /chat/completions in 0.224000 seconds
2025-01-02 03:37:16,826 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:37:18,320 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:37:18,321 - openai._base_client - INFO - Retrying request to /chat/completions in 0.960000 seconds
2025-01-02 03:37:19,590 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:37:22,372 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:37:23,070 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:37:24,981 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:37:24,982 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:37:24,983 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:37:25,425 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:37:26,484 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:37:27,271 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:37:28,236 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:37:28,238 - openai._base_client - INFO - Retrying request to /chat/completions in 1.342000 seconds
2025-01-02 03:37:29,936 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:37:33,375 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:37:33,376 - openai._base_client - INFO - Retrying request to /chat/completions in 0.164000 seconds
2025-01-02 03:37:34,030 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:37:35,488 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:37:35,489 - openai._base_client - INFO - Retrying request to /chat/completions in 1.466000 seconds
2025-01-02 03:37:37,410 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:37:38,727 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:37:39,115 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:37:39,117 - openai._base_client - INFO - Retrying request to /chat/completions in 1.874000 seconds
2025-01-02 03:37:41,505 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:37:43,847 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:37:43,848 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:37:43,849 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:37:44,272 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:37:45,426 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:37:46,216 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:37:47,358 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:37:47,377 - openai._base_client - INFO - Retrying request to /chat/completions in 1.604000 seconds
2025-01-02 03:37:49,344 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:37:51,337 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:37:51,339 - openai._base_client - INFO - Retrying request to /chat/completions in 1.634000 seconds
2025-01-02 03:37:53,427 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:37:55,371 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:37:55,372 - openai._base_client - INFO - Retrying request to /chat/completions in 1.474000 seconds
2025-01-02 03:37:57,206 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:38:00,460 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:38:01,682 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:38:03,484 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:38:03,486 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:38:03,486 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:38:04,035 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:38:05,465 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:38:06,285 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:38:07,615 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:38:09,095 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:38:09,097 - openai._base_client - INFO - Retrying request to /chat/completions in 0.368000 seconds
2025-01-02 03:38:09,974 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:38:11,243 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:38:11,244 - openai._base_client - INFO - Retrying request to /chat/completions in 1.824000 seconds
2025-01-02 03:38:13,403 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:38:16,777 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:38:17,342 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:38:19,930 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:38:19,930 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:38:19,930 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:38:20,518 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:38:21,559 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:38:22,469 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:38:24,003 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:38:25,358 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:38:25,360 - openai._base_client - INFO - Retrying request to /chat/completions in 0.990000 seconds
2025-01-02 03:38:26,769 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:38:28,502 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:38:28,503 - openai._base_client - INFO - Retrying request to /chat/completions in 1.288000 seconds
2025-01-02 03:38:30,096 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:38:32,836 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:38:33,234 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:38:33,236 - openai._base_client - INFO - Retrying request to /chat/completions in 0.410000 seconds
2025-01-02 03:38:34,141 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:38:35,453 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:38:35,455 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:38:35,455 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:38:35,882 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:38:36,969 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:38:37,725 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:38:39,321 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:38:39,323 - openai._base_client - INFO - Retrying request to /chat/completions in 0.730000 seconds
2025-01-02 03:38:40,486 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:38:41,993 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:38:41,995 - openai._base_client - INFO - Retrying request to /chat/completions in 1.754000 seconds
2025-01-02 03:38:44,176 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:38:45,616 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:38:45,616 - openai._base_client - INFO - Retrying request to /chat/completions in 1.392000 seconds
2025-01-02 03:38:47,365 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:38:51,426 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:38:52,166 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:38:53,795 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:38:53,796 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:38:53,796 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:38:54,210 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:38:55,301 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:38:56,056 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:38:57,194 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:38:57,195 - openai._base_client - INFO - Retrying request to /chat/completions in 0.235000 seconds
2025-01-02 03:38:57,898 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:38:59,149 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:38:59,150 - openai._base_client - INFO - Retrying request to /chat/completions in 1.962000 seconds
2025-01-02 03:39:01,688 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:39:03,631 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:39:03,632 - openai._base_client - INFO - Retrying request to /chat/completions in 0.822000 seconds
2025-01-02 03:39:04,786 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:39:07,672 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:39:08,086 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:39:08,087 - openai._base_client - INFO - Retrying request to /chat/completions in 0.304000 seconds
2025-01-02 03:39:08,854 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:39:11,597 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:39:11,599 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:39:11,599 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:39:12,132 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:39:13,276 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:39:14,079 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:39:15,715 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:39:17,660 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:39:19,284 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:39:19,286 - openai._base_client - INFO - Retrying request to /chat/completions in 0.190000 seconds
2025-01-02 03:39:19,913 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:39:21,938 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:39:22,335 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:39:22,337 - openai._base_client - INFO - Retrying request to /chat/completions in 0.060000 seconds
2025-01-02 03:39:22,885 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:39:24,589 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:39:24,590 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:39:24,590 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:39:25,241 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:39:26,291 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:39:27,085 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:39:28,208 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:39:29,342 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:39:29,344 - openai._base_client - INFO - Retrying request to /chat/completions in 0.202000 seconds
2025-01-02 03:39:29,842 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:39:31,940 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:39:31,941 - openai._base_client - INFO - Retrying request to /chat/completions in 1.100000 seconds
2025-01-02 03:39:33,537 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:39:38,205 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:39:38,856 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:39:40,605 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:39:40,605 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:39:40,605 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:39:41,213 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:39:42,472 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:39:43,265 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:39:44,489 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:39:47,305 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:39:49,067 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:39:52,193 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:39:52,888 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:39:56,605 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:39:56,606 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:39:56,606 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:39:57,052 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:39:58,479 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:39:59,236 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:40:00,477 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:40:03,228 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:40:05,152 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:40:05,154 - openai._base_client - INFO - Retrying request to /chat/completions in 1.648000 seconds
2025-01-02 03:40:09,581 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:40:14,353 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:40:15,110 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:40:16,655 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:40:16,656 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:40:16,656 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:40:17,158 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:40:18,248 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:40:19,003 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:40:20,534 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:40:22,176 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:40:23,916 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:40:25,892 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:40:26,252 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:40:26,253 - openai._base_client - INFO - Retrying request to /chat/completions in 0.802000 seconds
2025-01-02 03:40:27,503 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:40:37,204 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:40:37,206 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:40:37,207 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:40:38,868 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:40:40,093 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:40:40,913 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:40:42,217 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:40:46,546 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:40:52,588 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:40:55,019 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:40:55,611 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:40:58,860 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:40:58,861 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:40:58,862 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:40:59,349 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:41:00,591 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:41:01,396 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:41:04,468 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:41:06,112 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:41:08,155 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:41:10,553 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:41:11,225 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:41:13,534 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:41:13,536 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:41:13,536 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:41:13,993 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:41:15,319 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:41:16,246 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:41:17,371 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:41:18,909 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:41:20,545 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:41:21,960 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:41:22,592 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:41:24,612 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:41:24,613 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:41:24,613 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:41:25,359 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:41:26,535 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:41:27,303 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:41:28,530 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:41:30,886 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:41:33,651 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:41:39,374 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:41:40,104 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:41:42,077 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:41:42,078 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:41:42,078 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:41:42,563 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:41:43,646 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:41:44,403 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:41:48,323 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:41:51,877 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:41:53,518 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:41:56,301 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:41:56,869 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:41:58,612 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:41:58,613 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:41:58,614 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:41:59,050 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:42:00,238 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:42:01,914 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:42:04,208 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:42:06,523 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:42:08,060 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:42:09,982 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:42:10,720 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:42:17,747 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:42:17,748 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:42:17,748 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:42:18,198 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:42:19,261 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:42:20,146 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:42:21,060 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:42:22,603 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:42:27,316 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:42:28,859 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:42:29,518 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:42:30,746 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:42:30,747 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:42:30,748 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:42:31,154 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:42:32,317 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:42:33,252 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:42:35,503 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:42:38,371 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:42:40,519 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:42:42,937 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:42:43,594 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:42:46,519 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:42:46,520 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:42:46,520 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:42:46,973 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:42:48,279 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:42:49,097 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:42:52,597 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:42:54,654 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:42:56,085 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:42:58,087 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:42:58,849 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:42:59,877 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:42:59,878 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:42:59,878 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:43:00,164 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:43:04,686 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:43:05,492 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:43:07,041 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:43:10,115 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:43:11,855 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:43:14,420 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:43:15,131 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:43:18,316 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:43:18,318 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:43:18,318 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:43:18,822 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:43:19,899 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:43:20,765 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:43:21,991 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:43:24,357 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:43:25,781 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:43:30,874 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:43:31,619 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:43:33,082 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:43:33,083 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:43:33,083 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:43:33,668 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:43:34,740 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:43:35,614 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:43:36,738 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:43:38,886 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:43:40,836 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:43:42,971 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:43:43,904 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:43:45,523 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:43:45,524 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:43:45,524 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:43:45,957 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:43:47,025 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:43:47,846 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:43:49,310 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:43:52,390 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:43:54,909 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:43:56,711 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:43:57,407 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:44:00,480 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:44:00,482 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:44:00,482 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:44:00,820 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:44:04,564 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:44:05,515 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:44:06,722 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:44:08,993 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:44:11,862 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:44:14,224 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:44:14,935 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:44:17,966 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:44:17,966 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:44:17,967 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:44:18,521 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:44:19,542 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:44:20,364 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:44:22,207 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:44:23,797 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:44:25,892 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:44:28,101 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:44:28,715 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:44:32,269 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:44:32,270 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:44:32,270 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:44:32,620 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:44:33,751 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:44:34,600 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:44:37,598 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:44:39,718 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:44:41,459 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:44:43,844 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:44:44,527 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:44:46,751 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:44:46,753 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:44:46,753 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:44:47,054 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:44:48,084 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:44:48,868 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:44:50,685 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:44:53,129 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:44:54,338 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:44:54,339 - openai._base_client - INFO - Retrying request to /chat/completions in 0.598000 seconds
2025-01-02 03:44:55,386 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:44:56,957 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:44:57,430 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:44:57,431 - openai._base_client - INFO - Retrying request to /chat/completions in 0.864000 seconds
2025-01-02 03:44:58,761 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:45:00,279 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:45:00,279 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:45:00,279 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:45:00,711 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:45:03,679 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:45:04,474 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:45:05,645 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:45:05,647 - openai._base_client - INFO - Retrying request to /chat/completions in 0.402000 seconds
2025-01-02 03:45:06,444 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:45:08,110 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:45:08,111 - openai._base_client - INFO - Retrying request to /chat/completions in 1.670000 seconds
2025-01-02 03:45:10,234 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:45:11,996 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:45:11,998 - openai._base_client - INFO - Retrying request to /chat/completions in 1.574000 seconds
2025-01-02 03:45:14,123 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:45:17,067 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:45:17,709 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:45:23,897 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:45:23,900 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:45:23,900 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:45:24,465 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:45:25,546 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:45:26,393 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:45:28,336 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:45:32,862 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:45:34,602 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:45:38,017 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:45:38,697 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:45:41,877 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:45:41,878 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:45:41,878 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:45:42,195 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:45:43,315 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:45:44,130 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:45:45,560 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:45:47,328 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:45:52,375 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:45:54,857 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:45:55,597 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:45:57,313 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:45:57,316 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:45:57,316 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:45:57,672 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:45:58,834 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:45:59,698 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:46:04,302 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:46:06,554 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:46:09,625 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:46:14,111 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:46:14,850 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:46:19,434 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:46:19,435 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:46:19,435 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:46:20,177 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:46:21,399 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:46:22,223 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:46:23,961 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:46:25,907 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:46:28,849 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:46:30,847 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:46:31,541 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:46:33,669 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:46:33,670 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:46:33,671 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:46:34,101 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:46:35,124 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:46:35,945 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:46:38,196 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:46:39,833 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:46:42,498 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:46:44,282 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 03:46:44,679 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-01-02 03:46:44,681 - openai._base_client - INFO - Retrying request to /chat/completions in 0.568000 seconds
2025-01-02 03:46:45,672 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 03:46:48,283 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 03:46:48,284 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 03:46:48,284 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 03:46:48,605 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 03:46:52,541 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 03:46:53,354 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:02:07,318 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 04:02:07,965 - asyncio - ERROR - Exception in callback Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-94fb5d6ff81b', bound_args=<BoundArgumen...ationship?"})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x34aee0880>)(<WorkflowHand...nthesize': ")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273
handle: <Handle Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-94fb5d6ff81b', bound_args=<BoundArgumen...ationship?"})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x34aee0880>)(<WorkflowHand...nthesize': ")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 271, in __aiter__
    async for part in self._httpcore_stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 407, in __aiter__
    raise exc from None
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 403, in __aiter__
    async for part in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 342, in __aiter__
    raise exc
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 334, in __aiter__
    async for chunk in self._connection._receive_response_body(**kwargs):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 203, in _receive_response_body
    event = await self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 217, in _receive_event
    data = await self._network_stream.read(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_backends/anyio.py", line 32, in read
    with map_exceptions(exc_map):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 247, in _task
    new_ev = await instrumented_step(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/Documents/GitHub/AITA-Judge-Agent/src/agent/AITA_Agent.py", line 126, in synthesize
    response = await response_synthesizer.asynthesize(query, nodes=ev.nodes)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/base.py", line 306, in asynthesize
    response_str = await self.aget_response(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 370, in aget_response
    response = await self._arefine_response_single(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 396, in _arefine_response_single
    response = await aget_response_text(response)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response/utils.py", line 17, in aget_response_text
    async for response in response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/llm.py", line 151, in gen
    async for response in chat_response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/callbacks.py", line 88, in wrapped_gen
    async for x in f_return_val:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/llms/openai/base.py", line 724, in gen
    async for response in await aclient.chat.completions.create(
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 147, in __aiter__
    async for item in self._iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 160, in __stream__
    async for sse in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 151, in _iter_events
    async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 302, in aiter_bytes
    async for chunk in self._aiter_chunks(iterator):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 313, in _aiter_chunks
    async for chunk in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 997, in aiter_bytes
    async for raw_bytes in self.aiter_raw():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 1055, in aiter_raw
    async for raw_stream_bytes in self.stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_client.py", line 176, in __aiter__
    async for chunk in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 270, in __aiter__
    with map_httpcore_exceptions():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/asyncio/events.py", line 84, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 285, in handle_future_result
    raise exception
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 440, in _run_workflow
    raise exception_raised
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 254, in _task
    raise WorkflowRuntimeError(
llama_index.core.workflow.errors.WorkflowRuntimeError: Error in step 'synthesize': 
2025-01-02 04:02:07,968 - src.agent.evaluation.eval_util - WARNING - Error processing sample 141: Error in step 'synthesize': 
2025-01-02 04:02:07,976 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 04:02:07,977 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 04:02:07,977 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 04:02:08,397 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 04:02:10,216 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 04:02:10,975 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:02:12,611 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:02:15,381 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:02:18,326 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:02:21,032 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 04:02:21,827 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:02:24,592 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 04:02:24,594 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 04:02:24,594 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 04:02:24,984 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 04:02:26,431 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 04:02:27,253 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:02:30,206 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:02:33,705 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:02:36,778 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:02:39,161 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 04:02:39,849 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:02:42,977 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 04:02:42,978 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 04:02:42,978 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 04:02:43,290 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 04:02:45,070 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 04:02:45,994 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:02:47,506 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:02:49,986 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:02:52,241 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:02:54,477 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 04:02:55,315 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:02:58,312 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 04:02:58,314 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 04:02:58,314 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 04:02:58,606 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 04:02:59,779 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 04:03:00,599 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:03:04,127 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:03:07,753 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:03:10,877 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:03:13,958 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 04:03:14,665 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:03:16,298 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 04:03:16,300 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 04:03:16,300 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 04:03:18,869 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 04:03:20,293 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 04:03:21,117 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:03:26,438 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:03:29,206 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:03:33,062 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:03:36,325 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 04:03:37,095 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:03:42,093 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 04:03:42,094 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 04:03:42,095 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 04:03:42,724 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 04:03:43,845 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 04:03:44,671 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:03:47,129 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:03:50,199 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:03:53,577 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:03:55,927 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 04:03:57,060 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:04:00,079 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 04:04:00,080 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 04:04:00,080 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 04:04:00,540 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 04:04:04,375 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 04:04:05,207 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:04:09,152 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:04:11,499 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:04:14,773 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:04:17,219 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 04:04:17,797 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:04:21,002 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 04:04:21,004 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 04:04:21,004 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 04:04:21,431 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 04:04:22,555 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 04:04:24,812 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:04:26,753 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:04:29,313 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:04:31,875 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:04:35,318 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 04:04:36,482 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:04:40,622 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 04:04:40,623 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 04:04:40,624 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 04:04:41,194 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 04:04:42,271 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 04:04:43,035 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:04:44,980 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:04:47,233 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:04:49,580 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:15:41,168 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 04:31:33,440 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-dbe555d2-c5e9-4baa-b2a5-09e983c1a317', event.id_='fce56bbe-a848-4d79-8da9-cbe7f12286a0'
2025-01-02 04:31:33,502 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 271, in __aiter__
    async for part in self._httpcore_stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 407, in __aiter__
    raise exc from None
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 403, in __aiter__
    async for part in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 342, in __aiter__
    raise exc
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 334, in __aiter__
    async for chunk in self._connection._receive_response_body(**kwargs):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 203, in _receive_response_body
    event = await self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 217, in _receive_event
    data = await self._network_stream.read(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_backends/anyio.py", line 32, in read
    with map_exceptions(exc_map):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 370, in aget_response
    response = await self._arefine_response_single(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 396, in _arefine_response_single
    response = await aget_response_text(response)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response/utils.py", line 17, in aget_response_text
    async for response in response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/llm.py", line 151, in gen
    async for response in chat_response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/callbacks.py", line 88, in wrapped_gen
    async for x in f_return_val:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/llms/openai/base.py", line 724, in gen
    async for response in await aclient.chat.completions.create(
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 147, in __aiter__
    async for item in self._iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 160, in __stream__
    async for sse in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 151, in _iter_events
    async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 302, in aiter_bytes
    async for chunk in self._aiter_chunks(iterator):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 313, in _aiter_chunks
    async for chunk in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 997, in aiter_bytes
    async for raw_bytes in self.aiter_raw():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 1055, in aiter_raw
    async for raw_stream_bytes in self.stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_client.py", line 176, in __aiter__
    async for chunk in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 270, in __aiter__
    with map_httpcore_exceptions():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 04:31:34,022 - asyncio - ERROR - Exception in callback Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-f25ed5f7aeb6', bound_args=<BoundArgumen...g my wife?'})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x348e2c480>)(<WorkflowHand...nthesize': ")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273
handle: <Handle Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-f25ed5f7aeb6', bound_args=<BoundArgumen...g my wife?'})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x348e2c480>)(<WorkflowHand...nthesize': ")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 271, in __aiter__
    async for part in self._httpcore_stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 407, in __aiter__
    raise exc from None
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 403, in __aiter__
    async for part in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 342, in __aiter__
    raise exc
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 334, in __aiter__
    async for chunk in self._connection._receive_response_body(**kwargs):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 203, in _receive_response_body
    event = await self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 217, in _receive_event
    data = await self._network_stream.read(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_backends/anyio.py", line 32, in read
    with map_exceptions(exc_map):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 247, in _task
    new_ev = await instrumented_step(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/Documents/GitHub/AITA-Judge-Agent/src/agent/AITA_Agent.py", line 126, in synthesize
    response = await response_synthesizer.asynthesize(query, nodes=ev.nodes)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/base.py", line 306, in asynthesize
    response_str = await self.aget_response(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 370, in aget_response
    response = await self._arefine_response_single(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 396, in _arefine_response_single
    response = await aget_response_text(response)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response/utils.py", line 17, in aget_response_text
    async for response in response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/llm.py", line 151, in gen
    async for response in chat_response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/callbacks.py", line 88, in wrapped_gen
    async for x in f_return_val:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/llms/openai/base.py", line 724, in gen
    async for response in await aclient.chat.completions.create(
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 147, in __aiter__
    async for item in self._iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 160, in __stream__
    async for sse in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 151, in _iter_events
    async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 302, in aiter_bytes
    async for chunk in self._aiter_chunks(iterator):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 313, in _aiter_chunks
    async for chunk in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 997, in aiter_bytes
    async for raw_bytes in self.aiter_raw():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 1055, in aiter_raw
    async for raw_stream_bytes in self.stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_client.py", line 176, in __aiter__
    async for chunk in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 270, in __aiter__
    with map_httpcore_exceptions():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/asyncio/events.py", line 84, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 285, in handle_future_result
    raise exception
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 440, in _run_workflow
    raise exception_raised
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 254, in _task
    raise WorkflowRuntimeError(
llama_index.core.workflow.errors.WorkflowRuntimeError: Error in step 'synthesize': 
2025-01-02 04:31:34,028 - src.agent.evaluation.eval_util - WARNING - Error processing sample 150: Error in step 'synthesize': 
2025-01-02 04:31:34,045 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 04:31:34,046 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 04:31:34,046 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 04:31:34,497 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 04:31:36,472 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 04:31:37,347 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:31:39,493 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:31:42,156 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:31:47,309 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:31:49,766 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 04:31:50,454 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:31:53,031 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 04:31:53,032 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 04:31:53,032 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 04:31:53,424 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 04:31:55,365 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 04:31:56,291 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:31:58,030 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:32:03,562 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:32:06,001 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:32:08,470 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 04:32:09,190 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:32:11,902 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 04:32:11,905 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 04:32:11,905 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 04:32:12,521 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 04:32:13,647 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 04:32:14,617 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:32:19,947 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:32:23,074 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:32:25,782 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:32:28,058 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 04:32:28,858 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:32:37,619 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 04:32:37,620 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 04:32:37,620 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 04:32:37,948 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 04:32:39,096 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 04:32:39,916 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:32:42,738 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:32:45,979 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:32:49,231 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:32:51,964 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 04:32:52,572 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:32:55,483 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 04:32:55,486 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 04:32:55,486 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 04:32:56,199 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 04:32:57,730 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 04:32:59,268 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:33:04,181 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:33:07,457 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:33:11,250 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:33:14,631 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 04:33:15,344 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:33:20,737 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 04:33:20,740 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 04:33:20,740 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 04:33:21,001 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 04:33:22,047 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 04:33:22,926 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:33:26,068 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:33:28,454 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:33:32,184 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:33:35,524 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 04:33:36,229 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:33:40,142 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 04:33:40,144 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 04:33:40,144 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 04:33:40,562 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 04:33:41,894 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 04:33:43,122 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:33:46,000 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:33:49,421 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:33:52,950 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:33:57,274 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 04:33:57,923 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:34:03,795 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 04:34:03,798 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 04:34:03,798 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 04:34:04,326 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 04:34:05,425 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 04:34:06,193 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:34:09,105 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:34:13,403 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:34:17,020 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:49:19,155 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 04:50:18,378 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-3d85f807-9d24-4625-ae71-8d47e6e078cd', event.id_='c8007d85-e920-4c39-9cf9-88f43104bf37'
2025-01-02 04:50:18,766 - asyncio - ERROR - Exception in callback Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-a63587fe343a', bound_args=<BoundArgumen...ssed away?'})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x34bf8f680>)(<WorkflowHand...nthesize': ")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273
handle: <Handle Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-a63587fe343a', bound_args=<BoundArgumen...ssed away?'})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x34bf8f680>)(<WorkflowHand...nthesize': ")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 271, in __aiter__
    async for part in self._httpcore_stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 407, in __aiter__
    raise exc from None
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 403, in __aiter__
    async for part in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 342, in __aiter__
    raise exc
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 334, in __aiter__
    async for chunk in self._connection._receive_response_body(**kwargs):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 203, in _receive_response_body
    event = await self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 217, in _receive_event
    data = await self._network_stream.read(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_backends/anyio.py", line 32, in read
    with map_exceptions(exc_map):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 247, in _task
    new_ev = await instrumented_step(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/Documents/GitHub/AITA-Judge-Agent/src/agent/AITA_Agent.py", line 126, in synthesize
    response = await response_synthesizer.asynthesize(query, nodes=ev.nodes)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/base.py", line 306, in asynthesize
    response_str = await self.aget_response(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 370, in aget_response
    response = await self._arefine_response_single(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 396, in _arefine_response_single
    response = await aget_response_text(response)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response/utils.py", line 17, in aget_response_text
    async for response in response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/llm.py", line 151, in gen
    async for response in chat_response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/callbacks.py", line 88, in wrapped_gen
    async for x in f_return_val:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/llms/openai/base.py", line 724, in gen
    async for response in await aclient.chat.completions.create(
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 147, in __aiter__
    async for item in self._iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 160, in __stream__
    async for sse in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 151, in _iter_events
    async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 302, in aiter_bytes
    async for chunk in self._aiter_chunks(iterator):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 313, in _aiter_chunks
    async for chunk in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 997, in aiter_bytes
    async for raw_bytes in self.aiter_raw():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 1055, in aiter_raw
    async for raw_stream_bytes in self.stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_client.py", line 176, in __aiter__
    async for chunk in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 270, in __aiter__
    with map_httpcore_exceptions():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/asyncio/events.py", line 84, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 285, in handle_future_result
    raise exception
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 440, in _run_workflow
    raise exception_raised
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 254, in _task
    raise WorkflowRuntimeError(
llama_index.core.workflow.errors.WorkflowRuntimeError: Error in step 'synthesize': 
2025-01-02 04:50:18,773 - src.agent.evaluation.eval_util - WARNING - Error processing sample 158: Error in step 'synthesize': 
2025-01-02 04:50:18,795 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 04:50:18,798 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 04:50:18,799 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 04:50:19,557 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 04:50:21,174 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 04:50:21,976 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:50:23,749 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:50:26,192 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:50:29,445 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:50:33,813 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 04:50:34,421 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:50:38,023 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 04:50:38,026 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 04:50:38,027 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 04:50:38,565 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 04:50:39,677 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 04:50:40,510 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:50:42,716 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:50:45,975 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:50:49,515 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 04:50:52,665 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 05:07:07,094 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 05:08:06,162 - openai._base_client - INFO - Retrying request to /chat/completions in 0.496357 seconds
2025-01-02 05:08:07,096 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:08:07,109 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='21aaa10a-cd25-4765-9dc4-9b36111e32f5'
2025-01-02 05:08:07,114 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='0b9993fa-8bf3-471c-971d-d86e5ac45d4d'
2025-01-02 05:08:07,115 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='9064d048-b402-4410-98ba-87362e1b69cd'
2025-01-02 05:08:07,181 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='7a5f5df5-d52e-4934-8d57-2fbf81a1feec'
2025-01-02 05:08:07,182 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='a66d95ef-6e6f-4091-877e-5787075ecac0'
2025-01-02 05:08:07,209 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='d4e71d00-8aba-443d-9128-cc803c7f4fb7'
2025-01-02 05:08:07,210 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='d3c7e5ab-8d4e-4893-903c-37e11794c808'
2025-01-02 05:08:07,225 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='d8fe1191-e65c-4361-baf9-938f403d36e0'
2025-01-02 05:08:07,226 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='eb3081d9-4a4b-421e-ad9d-a9c8bc02fb64'
2025-01-02 05:08:07,267 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='462100b0-e7b6-45b3-af1b-bc4e9efec735'
2025-01-02 05:08:07,268 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='969006f0-92f3-4012-b7ac-eb80be632574'
2025-01-02 05:08:07,286 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='12fde4a8-21e9-4e3d-8dd0-8f8155e2771c'
2025-01-02 05:08:07,287 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='1ae93c9c-c9b7-4d4a-8ecf-3436a0305a51'
2025-01-02 05:08:07,305 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='f5c5f89e-b1e4-485b-8e0d-e8414458ffb6'
2025-01-02 05:08:07,306 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='28568ccc-ae13-43fb-8f4b-752b5bb284b4'
2025-01-02 05:08:07,363 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='0749a5be-d820-41b7-a9a8-288afaab3d73'
2025-01-02 05:08:07,364 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='55b95c4a-0eb0-42a8-9835-d08ecf5c9dfa'
2025-01-02 05:08:07,420 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='6ba301ff-e4e1-4019-8886-a704f6c8f215'
2025-01-02 05:08:07,422 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='29cee60b-a42c-4dd3-9d6e-bad5e35130f4'
2025-01-02 05:08:07,439 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='640860c1-58e1-4509-ac21-b20eed3ae12e'
2025-01-02 05:08:07,440 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='6ef81348-f347-45ee-bd50-3dc336836e7c'
2025-01-02 05:08:07,455 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='659d0940-bfe4-4719-9eaa-a36350b691a1'
2025-01-02 05:08:07,456 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='2ab63127-0000-4913-bce7-0efa98ad50a4'
2025-01-02 05:08:07,490 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='f5b8165e-5634-4bd0-9fce-219addb9087d'
2025-01-02 05:08:07,492 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='9846f75c-a944-4beb-9d42-be9958b610fd'
2025-01-02 05:08:07,515 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='fe832b1c-d881-4656-8ea0-c301826b591a'
2025-01-02 05:08:07,517 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='7e334ee3-7f83-493e-a8fc-19b6456719a4'
2025-01-02 05:08:07,567 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='7e4dbaa2-da68-41a9-8d1f-aeb52ef47c63'
2025-01-02 05:08:07,570 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='b6f9d592-d8b7-43d6-a2c6-597d0e6d09df'
2025-01-02 05:08:07,572 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='bc024595-f93e-4d1f-a46a-fc86450807bd'
2025-01-02 05:08:07,573 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='144aa502-45c9-4d62-b990-8f976ee43777'
2025-01-02 05:08:07,587 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='53e24fec-0040-40c1-a806-a4f65e6ea074'
2025-01-02 05:08:07,589 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='3e7e9a64-b4d8-44c3-9a40-4948f7ca5480'
2025-01-02 05:08:07,654 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='722f71b8-d304-4be6-be9d-3de55e1f6535'
2025-01-02 05:08:07,656 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='0d6596b8-de29-4ec3-b1bf-0687a1d153d0'
2025-01-02 05:08:07,677 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='ebffe684-a335-442c-8ee0-3607c8f30df4'
2025-01-02 05:08:07,680 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='4d71baf5-e771-4858-92de-2c1af14c5c7a'
2025-01-02 05:08:07,742 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='2ecdb635-71cb-485c-81b1-84a7b2104427'
2025-01-02 05:08:07,744 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='c7029de4-98b8-47c6-b74d-33553951a825'
2025-01-02 05:08:07,780 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='4f847f4e-31b6-43a8-8404-6e5b7f06f843'
2025-01-02 05:08:07,782 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='2410ebe6-c594-4b80-ac38-25f3aa886308'
2025-01-02 05:08:07,787 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='9b50b06e-6c80-4f65-8e5b-596f4ed0921e'
2025-01-02 05:08:07,789 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='8dc42fd8-ef7a-4c39-ae3b-f1d71e575b03'
2025-01-02 05:08:07,816 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='fb8c5a02-0aed-485c-b905-74de7899eb3c'
2025-01-02 05:08:07,818 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='684826df-608a-4691-b320-219993b7eae9'
2025-01-02 05:08:07,830 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='1b6aaf92-b01b-4390-835a-0ba47bdac2e0'
2025-01-02 05:08:07,831 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='1f6111e9-2f1e-41bf-a60a-7e9c99fa6e07'
2025-01-02 05:08:07,889 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='6cd1805a-e5d0-4562-9523-69e9457271e6'
2025-01-02 05:08:07,892 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='f6ad22a4-2263-449f-a4cf-9aeb8c03e41f'
2025-01-02 05:08:07,917 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='b2b4b382-c1cc-46b3-8bfe-f5f3700ce84a'
2025-01-02 05:08:07,918 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='47d19e37-1e70-40bf-bf45-397e6e044c8a'
2025-01-02 05:08:07,943 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='9ead3f83-fce5-4617-ae93-fcb865ee7ec1'
2025-01-02 05:08:07,945 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='1568a259-311a-4ac5-b141-46a3483fd897'
2025-01-02 05:08:07,976 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='38cf9066-53b3-4eb9-bacd-78a7c26c01a4'
2025-01-02 05:08:07,979 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='9a9101b6-eb72-48b9-833f-fb3baba9622b'
2025-01-02 05:08:08,037 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='92a80456-daf4-413d-a7e9-6ebe7b43c0ad'
2025-01-02 05:08:08,039 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='ca464d90-4e46-4f27-b8b1-f3328143045b'
2025-01-02 05:08:08,046 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='468efe5a-509e-48a1-9390-3866a61bb982'
2025-01-02 05:08:08,047 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='31305df0-d5db-4a05-a6f0-1466b58257c6'
2025-01-02 05:08:08,063 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='4fcb3243-f689-4783-a551-d3f5e0c83ef0'
2025-01-02 05:08:08,065 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='a97eba03-aa13-47b2-a383-0bf591900045'
2025-01-02 05:08:08,086 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='1aeed836-dcae-4338-88be-9b6cad7f404c'
2025-01-02 05:08:08,088 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='cbf4346e-7836-4651-98fd-a08e95f9eff3'
2025-01-02 05:08:08,150 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='60108cc7-812f-454c-891c-1c1262f415e2'
2025-01-02 05:08:08,151 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='a9feb6ff-0b31-4fc1-a220-e6331f99a805'
2025-01-02 05:08:08,154 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='f53b959d-aa0e-4bb6-ad62-655705c2958f'
2025-01-02 05:08:08,155 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='9c772981-8896-4db5-a91a-d4648f2424ae'
2025-01-02 05:08:08,179 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='9b691a12-1040-4684-933f-248d54320763'
2025-01-02 05:08:08,180 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='5081ab28-c246-46e2-aa1d-b8b1c4475e24'
2025-01-02 05:08:08,223 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='93422e5b-6b83-45d2-b39c-bd0f2855a12f'
2025-01-02 05:08:08,225 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='dfb2bc83-0e90-4a21-a325-7a7d84457fc0'
2025-01-02 05:08:08,282 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='380056b0-5a2b-44b5-9637-b7dbc7fd0f88'
2025-01-02 05:08:08,284 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='06832efa-56b6-4bcc-acb0-2f5892de9f59'
2025-01-02 05:08:08,327 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='835d281c-7110-4ebd-b1dd-fec4ed8e4c96'
2025-01-02 05:08:08,329 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='729a2326-f01f-4b1e-864b-684e4b2e7c2a'
2025-01-02 05:08:08,369 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='2ef14d4f-297f-4134-88ff-cc56b71d0eeb'
2025-01-02 05:08:08,371 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='448dedc6-59a1-49dd-ad76-4831221b9e10'
2025-01-02 05:08:08,400 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='74c5e1a7-b6e4-4233-bb8f-0234bd45afbc'
2025-01-02 05:08:08,402 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='0e4b30c4-db75-4b05-9de3-9db10102f7ce'
2025-01-02 05:08:08,414 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='0fc59d00-abfd-4adf-abc8-40acf266cec6'
2025-01-02 05:08:08,416 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='50800502-5006-4234-bfb6-f611e23db98d'
2025-01-02 05:08:08,444 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='67beda9d-033c-44b9-a9b4-e723c452f117'
2025-01-02 05:08:08,446 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='ad877944-0263-4f01-a752-ca33d743d54f'
2025-01-02 05:08:08,496 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='7db1150f-2895-4fa9-b85f-d0e0882865cf'
2025-01-02 05:08:08,497 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='e44fffcd-cb35-492f-a603-36b0d0cc1645'
2025-01-02 05:08:08,590 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='16e11a8f-f599-475c-9968-51a1527c4c9a'
2025-01-02 05:08:08,592 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='ca33752b-4c5e-41ef-8536-c2801c2bcde2'
2025-01-02 05:08:08,613 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='eb1612e5-aa36-44e0-af9b-f6fea19ffd95'
2025-01-02 05:08:08,615 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='ffaf3383-5c53-48d4-8872-0d18e931048c'
2025-01-02 05:08:08,656 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='70cf0320-fe13-4065-b125-f28031e2905d'
2025-01-02 05:08:08,657 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='370baa27-68f9-4254-bc5b-e88c9b064502'
2025-01-02 05:08:08,670 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='ef3cdb13-53b5-4c14-9b86-dfdd0a8b3b04'
2025-01-02 05:08:08,670 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='08f09f4d-4d1a-4e17-9d67-05746a9c5ccd'
2025-01-02 05:08:08,689 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='ba8da44d-ceed-4d33-a0f7-26987b47f8f2'
2025-01-02 05:08:08,690 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='6ed13742-91db-4ab9-aa7c-c363af45c80e'
2025-01-02 05:08:08,705 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='9f0b4464-4397-48b9-8e6b-c4aa70491d1f'
2025-01-02 05:08:08,706 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='88055d92-da21-4038-bbf5-dbf21cce7e7e'
2025-01-02 05:08:08,722 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='d67c8125-dcf6-48d1-9096-d79d15f61ea7'
2025-01-02 05:08:08,724 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='59532c2c-46d3-416a-b5fa-3fb51937d057'
2025-01-02 05:08:08,775 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='a34640d9-0556-44aa-bce8-0c70b63c5620'
2025-01-02 05:08:08,777 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='a889c0cb-03bb-4e9c-bfde-9c1981f19005'
2025-01-02 05:08:08,795 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='aae47197-263c-4d23-bfa9-d5733aa1f55a'
2025-01-02 05:08:08,797 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='28c71383-5526-48d0-b0c1-bbcef097becb'
2025-01-02 05:08:08,864 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='36cd3b5f-2b84-4c21-b5fd-34a33779f969'
2025-01-02 05:08:08,866 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='098cc6df-839d-420d-a965-3422937037bb'
2025-01-02 05:08:08,878 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='55448893-69e8-412e-8cde-77ee4a983ef0'
2025-01-02 05:08:08,879 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='0540858e-fa54-43e0-afdc-bac3468b36f3'
2025-01-02 05:08:08,898 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='c7227413-abb4-40a3-b7ad-713a850c9e03'
2025-01-02 05:08:08,899 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='c8025f56-cbb7-4dac-97c7-0b204b4f7731'
2025-01-02 05:08:08,938 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='c9ce09ca-231f-4c19-8b4b-0400194977ba'
2025-01-02 05:08:08,940 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='9eada1f6-bc9e-40a8-8d45-5cbc80472573'
2025-01-02 05:08:08,999 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='580ae3a0-e707-4509-ba02-066bea672857'
2025-01-02 05:08:09,001 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='79165181-9bc5-479c-9414-0e782ee02150'
2025-01-02 05:08:09,052 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='c222e290-e52c-41b3-87b1-f2340ff6b435'
2025-01-02 05:08:09,054 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='b049448c-cd6f-49ed-8c9c-93da0a29d383'
2025-01-02 05:08:09,087 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='fa073b1d-2cc5-4b83-a4b2-3ca4fcd31d83'
2025-01-02 05:08:09,088 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='e1d17560-3f2f-4a91-85d6-66d1eca53951'
2025-01-02 05:08:09,092 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='bea951ac-bdb8-4a55-84ae-4b369ae56b51'
2025-01-02 05:08:09,093 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='858b4f2a-0b66-4597-a669-9ab521105090'
2025-01-02 05:08:09,095 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='b30d3f1c-088d-404e-8105-933c69ebbd4f'
2025-01-02 05:08:09,096 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='b10e96cd-f24b-440f-afad-647ec5530524'
2025-01-02 05:08:09,115 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='c2571c81-a915-43b3-98e4-8bfeb29cf9b7'
2025-01-02 05:08:09,117 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='8c2d5ad4-c929-4e81-8bcc-7ada08877a79'
2025-01-02 05:08:09,216 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='c6637c68-1b5c-4f3b-93d9-2ae755f7c736'
2025-01-02 05:08:09,218 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='b8a290c1-90a6-4982-b204-e9ba915d1b71'
2025-01-02 05:08:09,231 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='293ab6d4-879f-4ed7-b81f-7436e910b361'
2025-01-02 05:08:09,233 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='5401e432-3721-425d-89a9-10ae84850f28'
2025-01-02 05:08:09,238 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='fbfd76f1-7ae2-4e1d-bf8b-a9e1b533b62a'
2025-01-02 05:08:09,240 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='fa335722-9309-46a9-beb2-c14b9440b941'
2025-01-02 05:08:09,266 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='c2812699-e02a-49a9-b0e1-67674e773047'
2025-01-02 05:08:09,267 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='87b6e6e8-7c4b-4dff-a152-e58dae0fae34'
2025-01-02 05:08:09,268 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='9f68e9a1-4a02-4efb-9882-de8a17210bd6'
2025-01-02 05:08:09,270 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='50eb1a16-def1-49be-af8b-c2c4842bee78'
2025-01-02 05:08:09,299 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='f6959e1c-4bf3-4ca1-a21b-7cfa2ed1bb28'
2025-01-02 05:08:09,301 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='aa2c983b-b713-4d3d-93a0-01df82439655'
2025-01-02 05:08:09,322 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='09147ff5-eab5-461e-98ad-541923835eac'
2025-01-02 05:08:09,324 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='ca83e054-7290-43cf-92af-59fee3d01b85'
2025-01-02 05:08:09,355 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='2545b24f-0bc5-4559-9c7b-b792d249658d'
2025-01-02 05:08:09,357 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='7b243b1c-abe1-4de4-a07b-972d16064b9a'
2025-01-02 05:08:09,383 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='82f38062-38e2-4937-ae16-8f65944a8089'
2025-01-02 05:08:09,385 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='c3f3e8de-bbf2-433f-b9fd-59a56670346e'
2025-01-02 05:08:09,437 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='e1d88a1c-3f13-47c3-a19d-38b160ddeff2'
2025-01-02 05:08:09,438 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='7d4f4021-f40b-444a-882b-bf0ecf1f8e7a'
2025-01-02 05:08:09,444 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='15638db3-5009-4bee-b14c-be4b0ec705bc'
2025-01-02 05:08:09,445 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='34aa11f3-0785-450b-bb98-3cdb3161e724'
2025-01-02 05:08:09,520 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='7fde1979-7626-462e-98df-6e15aae64759'
2025-01-02 05:08:09,522 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='8a2f62cb-508e-4350-937b-fcfb6fa54cd0'
2025-01-02 05:08:09,535 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='60f47235-b2a1-44b8-b40b-81fda944861f'
2025-01-02 05:08:09,538 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='5aade936-9fc1-46c2-bab1-441756020527'
2025-01-02 05:08:09,600 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='2eaf933e-9a74-46a7-bdcf-e41a7e79c9d8'
2025-01-02 05:08:09,601 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='de48b0da-f4a7-44bb-87ff-1130560d29be'
2025-01-02 05:08:09,603 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='98730bde-f0db-4e0d-be13-a711572a484d'
2025-01-02 05:08:09,605 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='555dbe3f-1511-4cb7-a974-0855421afd16'
2025-01-02 05:08:09,607 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='b656f2e7-8469-4188-a24f-7314cc1e2eee'
2025-01-02 05:08:09,607 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='8e18fc92-bf86-4b92-ae84-4caf9e1a26a1'
2025-01-02 05:08:09,651 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='47740caa-a6a8-4668-b382-504f042b7cd6'
2025-01-02 05:08:09,652 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='d093f27b-5210-4bbf-91e1-2d2e872d819f'
2025-01-02 05:08:09,677 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='82c33bbd-af25-42fe-894c-26599e24970d'
2025-01-02 05:08:09,679 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='e39d3373-68e5-48c6-9b22-aa27f784aaae'
2025-01-02 05:08:09,703 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='14ab430d-af9d-47d3-a283-d618df97ec8b'
2025-01-02 05:08:09,704 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='030ddef4-8183-4ae3-8225-1c4d44a0f225'
2025-01-02 05:08:09,706 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='39f18e00-2f8e-45bb-93ad-684e8825fcdf'
2025-01-02 05:08:09,707 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='b865e566-6501-465c-b9ce-17e7dc6052ab'
2025-01-02 05:08:09,709 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d01ad929-15d7-44bb-a010-f36bccc1f0f7', event.id_='a4179b55-f13d-4f0e-96de-bf004aa4dc0e'
2025-01-02 05:08:09,727 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 05:08:09,728 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 05:08:09,729 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 05:08:10,201 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 05:08:11,996 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 05:08:12,866 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:08:14,397 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:08:17,574 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:08:20,343 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:08:23,419 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 05:08:24,124 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:08:26,436 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 05:08:26,437 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 05:08:26,437 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 05:08:27,098 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 05:08:28,256 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 05:08:29,248 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:08:31,510 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:08:35,085 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:08:38,871 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:08:43,030 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 05:08:43,688 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:08:49,153 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 05:08:49,155 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 05:08:49,155 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 05:08:49,833 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 05:08:51,279 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 05:08:52,188 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:08:54,232 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:08:57,230 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:09:00,071 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:09:03,691 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 05:09:04,300 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:09:06,868 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 05:09:06,870 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 05:09:06,870 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 05:09:07,178 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 05:09:08,263 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 05:09:09,080 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:09:12,049 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:09:14,231 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:09:17,068 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:09:19,063 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 05:09:19,730 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:09:22,208 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 05:09:22,208 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 05:09:22,209 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 05:09:22,602 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 05:09:23,664 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 05:09:24,543 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:09:27,101 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:09:30,787 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:09:34,988 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:09:39,297 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 05:09:39,877 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:09:42,785 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 05:09:42,788 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 05:09:42,788 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 05:09:43,387 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 05:09:44,701 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 05:09:45,538 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:09:49,424 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:09:52,294 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:09:55,571 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:09:59,764 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 05:10:00,793 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:25:02,033 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 05:26:01,275 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-8e99b89e-f23f-4c29-8b47-ee41fe32fe06', event.id_='eb17dcc6-a902-4bd9-9edb-9926b9e66150'
2025-01-02 05:26:01,277 - src.agent.evaluation.eval_util - WARNING - Error processing sample 166: 
2025-01-02 05:26:01,294 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 05:26:01,295 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 05:26:01,295 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 05:26:02,186 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 05:26:04,621 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 05:26:05,455 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:26:07,395 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:26:10,166 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:26:12,251 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:26:14,598 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 05:26:15,177 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:26:17,362 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 05:26:17,363 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 05:26:17,363 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 05:26:18,153 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 05:26:19,307 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 05:26:20,099 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:26:22,248 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:26:25,012 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:26:34,239 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:26:38,573 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 05:26:39,249 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:26:42,400 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 05:26:42,401 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 05:26:42,402 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 05:26:43,036 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 05:26:44,105 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 05:26:44,983 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:41:45,196 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 05:57:43,076 - openai._base_client - INFO - Retrying request to /chat/completions in 0.467657 seconds
2025-01-02 05:57:43,883 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:57:43,890 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='d854d706-4a42-41ba-affc-0e280f2ef9f8'
2025-01-02 05:57:43,910 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='e0e62b1a-99cc-4cd4-8a1e-77249837212d'
2025-01-02 05:57:43,911 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='0ce6e17b-4d53-410c-b426-2d58d6bed976'
2025-01-02 05:57:43,964 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='81c91dbc-6567-4fde-95ef-118cb38bd70e'
2025-01-02 05:57:43,966 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='ad227806-4ba1-4e57-ad30-92bf59dde4a8'
2025-01-02 05:57:44,005 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='f2eb8f88-1be7-4965-a641-38a79d0b0a94'
2025-01-02 05:57:44,007 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='2f7a63e9-8c91-4b12-9261-a333bbcc7063'
2025-01-02 05:57:44,009 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='84c954c9-ade4-4ac0-9b60-962420f9d8ee'
2025-01-02 05:57:44,011 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='6cef0030-6df5-4f07-8246-6093b210a401'
2025-01-02 05:57:44,042 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='ff429971-d166-477f-8eb2-d4abbc6d6520'
2025-01-02 05:57:44,043 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='cc7af208-d5c3-4177-9fec-98b414c75ffb'
2025-01-02 05:57:44,060 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='e04d6baf-5e9e-45fa-9df3-ece8b9dfe8e2'
2025-01-02 05:57:44,061 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='fcb3490d-83e5-4468-8044-02865dea915b'
2025-01-02 05:57:44,092 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='287f9bcf-f3bf-4fbb-a545-fe2d9c7da3ab'
2025-01-02 05:57:44,094 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='b4ccd69f-5d2b-4112-9aff-cc599d0dd3aa'
2025-01-02 05:57:44,156 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='a0a67b3b-f05d-4b34-9082-8e84d66b2cd4'
2025-01-02 05:57:44,157 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='5e8e52da-ad8d-4528-8572-6e267353fe82'
2025-01-02 05:57:44,170 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='4d8af155-29cb-49b8-85b8-232ccee86e90'
2025-01-02 05:57:44,171 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='6bce7cb2-c2da-4f68-a212-3e21f20b2f68'
2025-01-02 05:57:44,224 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='49ca3f88-8ecd-4e67-8594-d3608fd8db9b'
2025-01-02 05:57:44,224 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='6a911ff7-4a0e-4fce-8901-de0bc8584c25'
2025-01-02 05:57:44,225 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='6930c309-daa3-4c94-8c22-ad5a2d17c54e'
2025-01-02 05:57:44,226 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='5f734bdf-2b4d-4875-8d22-bbd8873156a6'
2025-01-02 05:57:44,258 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='76e8d105-120b-444d-881f-4a68ec60342e'
2025-01-02 05:57:44,259 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='382ae7a9-f608-49f6-ba0d-ddbc0691c573'
2025-01-02 05:57:44,278 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='dfb07fcf-edf8-4128-ba91-e676bfd117be'
2025-01-02 05:57:44,279 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='05d0e5d4-5abe-4663-ad6d-fd83d4c58402'
2025-01-02 05:57:44,311 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='2ca96d35-56d9-404f-a244-8428a53b8503'
2025-01-02 05:57:44,312 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='2bb1cc15-5004-46e2-ae00-7c335dad6fd4'
2025-01-02 05:57:44,354 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='7e90a50e-49f1-45a2-bffe-83ac94efa1df'
2025-01-02 05:57:44,355 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='92dd6bf4-4750-4843-b13a-8ed8d171c6ff'
2025-01-02 05:57:44,452 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='9e23d5dd-11a7-446a-b2cc-2bb44ea12ff9'
2025-01-02 05:57:44,453 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='3c878db4-2060-447a-a7e6-b0b48eb5d74c'
2025-01-02 05:57:44,551 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='f40567c9-9e72-4e54-bb20-10d783b5f251'
2025-01-02 05:57:44,554 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='8dc223e9-4f44-4cf1-af62-f5b26e3e04c2'
2025-01-02 05:57:44,622 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='eac58438-3089-45c3-8650-d40e6ab933b6'
2025-01-02 05:57:44,624 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='f1690454-3690-473c-97e2-1281b73d870b'
2025-01-02 05:57:44,651 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='0fc99bcd-6d66-4ea0-9f2a-8dd11e0094e5'
2025-01-02 05:57:44,652 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='484af249-815a-4fb4-85ee-20bcae4f7c0d'
2025-01-02 05:57:44,683 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='c90bc813-2a3c-4ef2-9b5c-24657744ece7'
2025-01-02 05:57:44,685 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='8f832db0-4fc3-4a4e-8509-85ec0b05656b'
2025-01-02 05:57:44,746 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='fe24e7ec-d59c-4f32-bd61-b82dd67caa4d'
2025-01-02 05:57:44,748 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='b2f951aa-925a-45b2-8285-e30d436e3f60'
2025-01-02 05:57:44,767 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='2b6c3392-37f5-42d0-b622-6b3e53e179d3'
2025-01-02 05:57:44,769 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='d3c20ecb-b443-471a-ad02-5275a7217ae9'
2025-01-02 05:57:44,780 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='1c590ecb-c0a4-4b2e-ad4f-81e076b7d9a5'
2025-01-02 05:57:44,782 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='b17bdab7-0295-4fde-9972-ab78a35a522c'
2025-01-02 05:57:44,821 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='52fe8fec-b6fb-42df-9620-e330ff05acfa'
2025-01-02 05:57:44,823 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='a95dcfe5-cf91-4eff-b127-8dcd197b310a'
2025-01-02 05:57:44,845 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='b4d1bb1f-e674-45b8-b26d-c8b3f05cbc60'
2025-01-02 05:57:44,846 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='484d9e57-bd4e-4ea0-a2c6-a939353af8d2'
2025-01-02 05:57:44,875 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='5bd3aeec-c965-47e7-b4e5-250800670c1f'
2025-01-02 05:57:44,877 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='117bd7e7-288b-431c-bc66-94a29ce6d053'
2025-01-02 05:57:44,903 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='747e38d6-bc9f-4aea-b2c7-0a2fdfb50161'
2025-01-02 05:57:44,905 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='e0de8ac7-63fb-4204-88ea-3bd6d50f1ca6'
2025-01-02 05:57:44,947 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='48e113cf-a317-4314-b82a-0e5f9b91998e'
2025-01-02 05:57:44,949 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='ce62a047-73a4-48a4-97f9-1b33764997e4'
2025-01-02 05:57:44,964 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='215812aa-48b5-4b77-a783-841c12ce1c45'
2025-01-02 05:57:44,965 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='535cf42d-7fdb-4ca7-957a-8863fdc6d3da'
2025-01-02 05:57:45,052 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='f75a7fb6-aaf5-4f53-a8e3-0b6bc9231785'
2025-01-02 05:57:45,055 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='35a1c347-230d-40b4-9c68-9fe32381259d'
2025-01-02 05:57:45,094 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='cb3c8f05-31ea-4db3-8b9a-50427f812d78'
2025-01-02 05:57:45,096 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='b9924cd9-01ea-476e-8128-e09150e524e6'
2025-01-02 05:57:45,152 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='38288013-f6cf-4af7-8493-1b1ee57ca0ac'
2025-01-02 05:57:45,154 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='a07bc1fc-3398-4a7b-9a42-32b7ce5a364e'
2025-01-02 05:57:45,179 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='285aa40a-0fab-401d-9556-3322a0009a20'
2025-01-02 05:57:45,181 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='fc994970-3637-4ab1-ad89-5f8809c45314'
2025-01-02 05:57:45,223 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='a0868b8f-63e9-427e-83d8-eea4b679eba0'
2025-01-02 05:57:45,226 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='34047d9c-cff7-469c-b07d-ee37f90c62d7'
2025-01-02 05:57:45,229 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='2e39fc7b-815e-4bc5-b198-b54c9c51fb38'
2025-01-02 05:57:45,231 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='665b528e-c2c6-4f5e-98c6-ec3f31435ba9'
2025-01-02 05:57:45,279 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='92f32f37-4ca9-46f3-9b3d-931125ff84a7'
2025-01-02 05:57:45,280 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='d490fff2-4e32-4d8e-864e-a06e45661e1e'
2025-01-02 05:57:45,347 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='1477c04e-2242-4bc6-a086-db0eed61dd63'
2025-01-02 05:57:45,349 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='8a3fdbf8-d5a2-4fcc-b489-93d97af83170'
2025-01-02 05:57:45,351 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='05c684d6-1d7e-4dc2-b012-80e3ddbca592'
2025-01-02 05:57:45,353 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='4f9bdcee-1e62-4707-b06d-f1bf8e93f587'
2025-01-02 05:57:45,355 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='f1810540-5adc-4ab7-9755-45f2ac804752'
2025-01-02 05:57:45,391 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='3c411709-3216-4d8b-a477-5fdeb316c42d'
2025-01-02 05:57:45,393 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='ec4fce1d-f5bf-4a75-812e-e6eaa22c0efb'
2025-01-02 05:57:45,402 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='77ad428f-1d46-40e7-b914-1b6f25add09c'
2025-01-02 05:57:45,403 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='a53a491a-8163-437a-b276-97bf45aa2418'
2025-01-02 05:57:45,422 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='ff0f37b0-4063-4984-b47d-9fb917eb70f6'
2025-01-02 05:57:45,423 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='ded8c305-53d3-4e12-bf90-856908c7abc4'
2025-01-02 05:57:45,493 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='cb77f097-be44-47b4-8341-882408809765'
2025-01-02 05:57:45,495 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='dacdd143-5459-4264-8c13-46769fbd6060'
2025-01-02 05:57:45,497 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='43905b4d-3033-4b7a-ae4e-427cd312f71f'
2025-01-02 05:57:45,498 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='ce1a4c18-8bd1-4123-9cda-d51a74c6650d'
2025-01-02 05:57:45,500 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='fa47185f-9880-4fef-b23a-7ed14e5ad1fa'
2025-01-02 05:57:45,501 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='48f8b1ff-4c35-4efc-9f22-ea277b24dc3a'
2025-01-02 05:57:45,538 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='5def881e-2fb5-4746-a404-bd816bde064a'
2025-01-02 05:57:45,540 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='c42f4343-bcee-4f5e-95eb-0d9136ef79ac'
2025-01-02 05:57:45,620 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='38052a60-7871-4db9-8def-64591ddc072d'
2025-01-02 05:57:45,621 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='8897aac9-f843-4a66-9d9b-fc593cda417a'
2025-01-02 05:57:45,625 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='699facbe-fb1d-438a-8229-ee2c731a2432'
2025-01-02 05:57:45,626 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='15cfc0dd-ce59-486c-81e2-79478c1158b7'
2025-01-02 05:57:45,662 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='27c5386a-b54c-4324-b955-f939a2f34d88'
2025-01-02 05:57:45,663 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='42a27a9c-99ac-4899-b7f0-1462dd080979'
2025-01-02 05:57:45,689 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='1883fc1b-ed99-4d52-8d9f-86ff58c882f6'
2025-01-02 05:57:45,690 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='7110009a-7ee8-4d8d-aae0-43db5357580f'
2025-01-02 05:57:45,692 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='4aa08cca-f47a-47b8-b4c9-eb41012da1c5'
2025-01-02 05:57:45,693 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='188a7ce2-0bd5-40b6-be5d-15d604f7cf17'
2025-01-02 05:57:45,695 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e01df9ef-d6e2-42a4-8c58-6e0b7ced4455', event.id_='74809728-a1da-49b9-a660-370f813d752b'
2025-01-02 05:57:46,299 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:57:49,781 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:57:53,928 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 05:57:56,326 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:57:58,758 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 05:57:58,760 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 05:57:58,760 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 05:57:59,150 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 05:58:01,274 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 05:58:04,527 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:58:06,261 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:58:10,973 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:58:13,742 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:58:16,133 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 05:58:16,812 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:58:19,942 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 05:58:19,944 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 05:58:19,944 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 05:58:20,602 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 05:58:21,677 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 05:58:22,545 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:58:24,696 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:58:27,453 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:58:30,101 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:58:32,622 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 05:58:33,271 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:58:34,973 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 05:58:34,976 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 05:58:34,976 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 05:58:38,934 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 05:58:39,997 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 05:58:40,776 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:58:42,512 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:58:44,464 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:58:46,612 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:58:48,795 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 05:58:49,785 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:58:52,112 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 05:58:52,112 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 05:58:52,112 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 05:58:52,395 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 05:58:53,895 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 05:58:56,138 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:58:57,774 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:58:59,922 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:59:04,021 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:59:05,729 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 05:59:06,478 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:59:08,565 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 05:59:08,566 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 05:59:08,566 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 05:59:09,035 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 05:59:10,070 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 05:59:10,880 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:59:14,568 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:59:16,716 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:59:18,561 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:59:20,898 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 05:59:21,736 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:59:25,933 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 05:59:25,934 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 05:59:25,934 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 05:59:26,858 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 05:59:28,040 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 05:59:28,908 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:59:32,898 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:59:35,366 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:59:37,910 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:59:40,445 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 05:59:41,192 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:59:43,649 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 05:59:43,652 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 05:59:43,652 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 05:59:44,164 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 05:59:45,272 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 05:59:46,043 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:59:48,156 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:59:50,099 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:59:52,660 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:59:55,485 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 05:59:56,244 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 05:59:58,147 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 05:59:58,148 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 05:59:58,148 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 05:59:58,905 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 05:59:59,964 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 06:00:00,851 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:00:04,330 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:00:07,507 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:00:10,686 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:00:12,981 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 06:00:13,653 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:00:16,826 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 06:00:16,828 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 06:00:16,828 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 06:00:17,341 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 06:00:19,593 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 06:00:20,825 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:00:22,864 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:00:25,533 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:00:28,518 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:15:28,130 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 06:16:27,442 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-826dc83e-1d87-4151-b207-cc6b6f72847d', event.id_='bcc89b06-6abb-42a9-8b43-2c529a44ecd7'
2025-01-02 06:16:27,786 - asyncio - ERROR - Exception in callback Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-2b31d29811c8', bound_args=<BoundArgumen... payments?"})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x348fe8b80>)(<WorkflowHand...nthesize': ")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273
handle: <Handle Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-2b31d29811c8', bound_args=<BoundArgumen... payments?"})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x348fe8b80>)(<WorkflowHand...nthesize': ")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 271, in __aiter__
    async for part in self._httpcore_stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 407, in __aiter__
    raise exc from None
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 403, in __aiter__
    async for part in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 342, in __aiter__
    raise exc
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 334, in __aiter__
    async for chunk in self._connection._receive_response_body(**kwargs):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 203, in _receive_response_body
    event = await self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 217, in _receive_event
    data = await self._network_stream.read(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_backends/anyio.py", line 32, in read
    with map_exceptions(exc_map):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 247, in _task
    new_ev = await instrumented_step(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/Documents/GitHub/AITA-Judge-Agent/src/agent/AITA_Agent.py", line 126, in synthesize
    response = await response_synthesizer.asynthesize(query, nodes=ev.nodes)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/base.py", line 306, in asynthesize
    response_str = await self.aget_response(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 370, in aget_response
    response = await self._arefine_response_single(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 396, in _arefine_response_single
    response = await aget_response_text(response)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response/utils.py", line 17, in aget_response_text
    async for response in response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/llm.py", line 151, in gen
    async for response in chat_response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/callbacks.py", line 88, in wrapped_gen
    async for x in f_return_val:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/llms/openai/base.py", line 724, in gen
    async for response in await aclient.chat.completions.create(
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 147, in __aiter__
    async for item in self._iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 160, in __stream__
    async for sse in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 151, in _iter_events
    async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 302, in aiter_bytes
    async for chunk in self._aiter_chunks(iterator):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 313, in _aiter_chunks
    async for chunk in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 997, in aiter_bytes
    async for raw_bytes in self.aiter_raw():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 1055, in aiter_raw
    async for raw_stream_bytes in self.stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_client.py", line 176, in __aiter__
    async for chunk in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 270, in __aiter__
    with map_httpcore_exceptions():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/asyncio/events.py", line 84, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 285, in handle_future_result
    raise exception
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 440, in _run_workflow
    raise exception_raised
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 254, in _task
    raise WorkflowRuntimeError(
llama_index.core.workflow.errors.WorkflowRuntimeError: Error in step 'synthesize': 
2025-01-02 06:16:27,793 - src.agent.evaluation.eval_util - WARNING - Error processing sample 178: Error in step 'synthesize': 
2025-01-02 06:16:27,809 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 06:16:27,810 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 06:16:27,810 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 06:16:28,206 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 06:16:29,837 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 06:16:30,781 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:16:33,751 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:16:37,232 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:16:40,611 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:16:44,063 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 06:16:44,814 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:16:48,579 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 06:16:48,580 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 06:16:48,580 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 06:16:48,872 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 06:16:49,975 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 06:16:50,897 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:16:52,320 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:16:55,525 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:16:58,631 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:17:02,286 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 06:17:02,934 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:17:07,604 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 06:17:07,605 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 06:17:07,605 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 06:17:08,060 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 06:17:09,139 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 06:17:10,000 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:17:11,637 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:17:14,406 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:17:17,475 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:17:20,651 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 06:17:21,470 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:17:24,456 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 06:17:24,457 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 06:17:24,457 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 06:17:24,955 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 06:17:27,206 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 06:17:29,257 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:17:32,427 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:17:34,781 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:17:37,649 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:17:40,761 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 06:17:41,541 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:17:44,056 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 06:17:44,058 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 06:17:44,058 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 06:17:44,378 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 06:17:45,460 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 06:17:46,255 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:17:48,600 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:17:55,670 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:17:59,257 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:18:02,288 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 06:18:02,947 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:18:05,231 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 06:18:05,232 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 06:18:05,233 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 06:18:05,711 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 06:18:06,936 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 06:18:07,861 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:18:09,246 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:33:10,212 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 06:49:16,899 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-d82dc2f9-7294-476f-9198-e0b8d3b05d09', event.id_='ed68531d-b1f8-4df8-84e4-a23c4c71ef46'
2025-01-02 06:49:16,957 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 271, in __aiter__
    async for part in self._httpcore_stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 407, in __aiter__
    raise exc from None
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 403, in __aiter__
    async for part in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 342, in __aiter__
    raise exc
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 334, in __aiter__
    async for chunk in self._connection._receive_response_body(**kwargs):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 203, in _receive_response_body
    event = await self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 217, in _receive_event
    data = await self._network_stream.read(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_backends/anyio.py", line 32, in read
    with map_exceptions(exc_map):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 370, in aget_response
    response = await self._arefine_response_single(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 396, in _arefine_response_single
    response = await aget_response_text(response)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response/utils.py", line 17, in aget_response_text
    async for response in response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/llm.py", line 151, in gen
    async for response in chat_response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/callbacks.py", line 88, in wrapped_gen
    async for x in f_return_val:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/llms/openai/base.py", line 724, in gen
    async for response in await aclient.chat.completions.create(
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 147, in __aiter__
    async for item in self._iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 160, in __stream__
    async for sse in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 151, in _iter_events
    async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 302, in aiter_bytes
    async for chunk in self._aiter_chunks(iterator):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 313, in _aiter_chunks
    async for chunk in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 997, in aiter_bytes
    async for raw_bytes in self.aiter_raw():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 1055, in aiter_raw
    async for raw_stream_bytes in self.stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_client.py", line 176, in __aiter__
    async for chunk in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 270, in __aiter__
    with map_httpcore_exceptions():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 06:49:17,447 - asyncio - ERROR - Exception in callback Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-c0ffcf53e2b3', bound_args=<BoundArgumen... is dairy?'})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x342756000>)(<WorkflowHand...nthesize': ")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273
handle: <Handle Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-c0ffcf53e2b3', bound_args=<BoundArgumen... is dairy?'})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x342756000>)(<WorkflowHand...nthesize': ")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 271, in __aiter__
    async for part in self._httpcore_stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 407, in __aiter__
    raise exc from None
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 403, in __aiter__
    async for part in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 342, in __aiter__
    raise exc
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 334, in __aiter__
    async for chunk in self._connection._receive_response_body(**kwargs):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 203, in _receive_response_body
    event = await self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 217, in _receive_event
    data = await self._network_stream.read(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_backends/anyio.py", line 32, in read
    with map_exceptions(exc_map):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 247, in _task
    new_ev = await instrumented_step(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/Documents/GitHub/AITA-Judge-Agent/src/agent/AITA_Agent.py", line 126, in synthesize
    response = await response_synthesizer.asynthesize(query, nodes=ev.nodes)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/base.py", line 306, in asynthesize
    response_str = await self.aget_response(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 370, in aget_response
    response = await self._arefine_response_single(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 396, in _arefine_response_single
    response = await aget_response_text(response)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response/utils.py", line 17, in aget_response_text
    async for response in response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/llm.py", line 151, in gen
    async for response in chat_response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/callbacks.py", line 88, in wrapped_gen
    async for x in f_return_val:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/llms/openai/base.py", line 724, in gen
    async for response in await aclient.chat.completions.create(
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 147, in __aiter__
    async for item in self._iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 160, in __stream__
    async for sse in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 151, in _iter_events
    async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 302, in aiter_bytes
    async for chunk in self._aiter_chunks(iterator):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 313, in _aiter_chunks
    async for chunk in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 997, in aiter_bytes
    async for raw_bytes in self.aiter_raw():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 1055, in aiter_raw
    async for raw_stream_bytes in self.stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_client.py", line 176, in __aiter__
    async for chunk in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 270, in __aiter__
    with map_httpcore_exceptions():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/asyncio/events.py", line 84, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 285, in handle_future_result
    raise exception
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 440, in _run_workflow
    raise exception_raised
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 254, in _task
    raise WorkflowRuntimeError(
llama_index.core.workflow.errors.WorkflowRuntimeError: Error in step 'synthesize': 
2025-01-02 06:49:17,455 - src.agent.evaluation.eval_util - WARNING - Error processing sample 184: Error in step 'synthesize': 
2025-01-02 06:49:17,473 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 06:49:17,474 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 06:49:17,475 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 06:49:18,024 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 06:49:19,743 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 06:49:20,649 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:49:23,347 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:49:32,192 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:49:39,804 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:49:54,435 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 06:49:55,088 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:50:04,423 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 06:50:04,425 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 06:50:04,425 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 06:50:04,921 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 06:50:06,133 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 06:50:07,028 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:50:09,323 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:50:11,751 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:50:18,543 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:50:20,061 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 06:50:20,688 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 06:50:23,066 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 06:50:23,067 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 06:50:23,067 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 06:50:23,557 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:05:24,768 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 07:05:25,970 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:05:26,858 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:05:28,814 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:05:31,138 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:05:33,559 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:05:36,637 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:05:37,346 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:05:40,098 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:05:40,100 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:05:40,100 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:05:40,364 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:05:41,780 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:05:42,702 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:05:45,124 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:05:48,063 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:05:50,980 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:05:53,350 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:05:54,062 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:05:56,987 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:05:56,988 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:05:56,988 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:05:57,359 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:05:58,604 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:05:59,435 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:06:01,451 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:06:05,828 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:06:13,310 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:06:17,079 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:06:18,022 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:06:22,670 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:06:22,671 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:06:22,671 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:06:23,147 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:06:24,221 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:06:25,088 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:06:27,247 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:06:29,794 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:06:33,890 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:06:36,803 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:06:37,477 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:06:40,118 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:06:40,119 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:06:40,119 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:06:40,613 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:06:41,687 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:06:42,433 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:06:44,136 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:06:46,232 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:06:49,149 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:06:52,314 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:06:53,039 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:06:56,177 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:06:56,177 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:06:56,178 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:06:56,618 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:06:57,750 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:06:58,591 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:07:03,792 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:07:06,812 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:07:09,857 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:07:15,010 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:07:15,599 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:07:18,521 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:07:18,522 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:07:18,522 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:07:18,832 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:07:19,945 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:07:20,794 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:07:22,842 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:07:25,496 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:07:30,516 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:07:34,340 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:07:35,024 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:07:39,223 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:07:39,224 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:07:39,224 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:07:39,738 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:07:40,800 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:07:41,682 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:07:44,143 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:07:46,386 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:07:49,873 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:07:53,311 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:07:54,071 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:23:44,057 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 286, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/socket.py", line 706, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/ssl.py", line 1314, in recv_into
    return self.read(nbytes, buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/ssl.py", line 1166, in read
    return self._sslobj.read(len, buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TimeoutError: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 39, in reraise
    raise value
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 713, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)
2025-01-02 07:23:44,110 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:23:44,111 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:23:44,111 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:23:44,581 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:23:46,820 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:23:47,717 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:23:49,968 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:23:52,218 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:23:55,619 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:24:00,401 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:24:05,932 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:24:07,595 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:24:07,597 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:24:07,597 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:24:08,290 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:24:09,443 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:24:10,284 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:24:11,756 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:24:13,507 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:24:16,784 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:24:20,120 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:24:20,767 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:24:23,771 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:24:23,772 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:24:23,772 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:24:24,033 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:24:25,068 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:24:25,780 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:24:27,329 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:24:29,685 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:24:32,349 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:24:34,381 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:24:35,111 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:24:37,582 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:24:37,583 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:24:37,583 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:24:38,083 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:24:39,207 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:24:40,129 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:24:42,279 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:24:43,916 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:24:46,684 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:24:49,369 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:24:50,063 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:24:52,358 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:24:52,360 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:24:52,360 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:24:52,829 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:24:53,920 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:24:55,082 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:24:58,565 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:25:03,606 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:25:07,778 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:25:11,695 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:25:12,386 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:25:17,442 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:25:17,444 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:25:17,444 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:25:17,797 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:25:19,048 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:25:19,813 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:25:22,525 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:25:24,978 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:25:28,664 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:25:31,154 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:25:31,824 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:25:36,743 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:25:36,745 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:25:36,745 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:25:37,110 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:25:38,231 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:25:39,111 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:25:42,490 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:25:44,640 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:25:46,586 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:25:48,427 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:25:49,146 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:25:51,678 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:25:51,679 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:25:51,679 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:25:52,220 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:25:54,086 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:25:55,035 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:25:58,154 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:26:00,824 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:26:05,632 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:26:08,322 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:41:40,076 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 07:41:40,089 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
urllib3.exceptions.SSLError: EOF occurred in violation of protocol (_ssl.c:2427)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Max retries exceeded with url: /v1/traces (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:2427)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 698, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Max retries exceeded with url: /v1/traces (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:2427)')))
2025-01-02 07:41:40,508 - openai._base_client - INFO - Retrying request to /chat/completions in 0.388141 seconds
2025-01-02 07:41:41,256 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:41:41,258 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='0ff99a24-1fae-40cf-b7f8-e4362398bd98'
2025-01-02 07:41:41,283 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='47205f80-814d-4a43-ad86-b69ba30a05ef'
2025-01-02 07:41:41,283 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='22f9054d-3e5e-4760-89cb-bab67e1db58b'
2025-01-02 07:41:41,317 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='ce0661e1-b877-4521-8a90-e05063c7653e'
2025-01-02 07:41:41,317 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='f64c0ea0-c08d-4be0-b16a-ac800e201118'
2025-01-02 07:41:41,333 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='288b231e-3e9d-4139-a2fc-49798debd15a'
2025-01-02 07:41:41,333 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='4fdc21d1-df23-4e02-a4d9-f32eb9a20598'
2025-01-02 07:41:41,376 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='211f7c82-2888-4870-bd69-618e3f05b7db'
2025-01-02 07:41:41,377 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='7b8f7d5f-2c11-4343-b2d7-27b5845bbb15'
2025-01-02 07:41:41,391 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='4778e6d7-916b-410e-b34e-ca5317a077dd'
2025-01-02 07:41:41,392 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='73b50564-e9cb-4e66-b420-24763e50f2e5'
2025-01-02 07:41:41,434 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='00b292e6-21fd-4d2e-a75b-742a31c5e248'
2025-01-02 07:41:41,435 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='f29d4e4b-ebfa-410b-a210-7ecc27d5629f'
2025-01-02 07:41:41,452 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='71f51bf1-43e0-4596-8e37-46cff0344e64'
2025-01-02 07:41:41,453 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='56f367c3-e9e6-4cef-9053-6afc4b851b1c'
2025-01-02 07:41:41,475 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='2631184f-0062-43bd-b415-7f86624d6716'
2025-01-02 07:41:41,476 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='2e1d22ec-e071-4102-84d8-21be9c642ca0'
2025-01-02 07:41:41,502 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='01cc6c11-0231-4fb0-8061-35d2144c3238'
2025-01-02 07:41:41,503 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='49b4a100-0ab1-4f12-b695-f56f64f8a12f'
2025-01-02 07:41:41,555 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='e66131b5-5e67-4810-9bc5-bc193e123987'
2025-01-02 07:41:41,555 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='a0ccc9fd-f4d3-4579-a942-3f4f3cfbebe7'
2025-01-02 07:41:41,556 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='8ee8849e-3c0a-4e30-b8f2-86883a1d8068'
2025-01-02 07:41:41,556 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='7e6f78c9-c637-40ee-8b2f-4f725d3c24fe'
2025-01-02 07:41:41,586 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='36caedf0-9e70-4abe-95f6-d4f0486596ca'
2025-01-02 07:41:41,587 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='4b7d1250-924c-4dff-acce-88983b28b887'
2025-01-02 07:41:41,623 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='c893d3fa-7148-430b-9aaf-ec73344f2384'
2025-01-02 07:41:41,624 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='c7d78cd9-2f0d-427a-a155-44afb8bdedfc'
2025-01-02 07:41:41,637 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='185a106f-16f1-41df-9826-ab1c7fb46050'
2025-01-02 07:41:41,639 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='cdd4fa90-2f83-4bfd-be99-cb3b5a9224ba'
2025-01-02 07:41:41,669 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='dc3243ad-cca6-4e6d-96c7-8b1734ae02d7'
2025-01-02 07:41:41,678 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='52ef3505-96d2-4d46-8d1a-25f27f2e5853'
2025-01-02 07:41:41,688 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='54dedd39-f55d-4a4c-aa19-42a4ad1b532a'
2025-01-02 07:41:41,689 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='c40dfcef-65db-4f45-b7bc-bc761df55952'
2025-01-02 07:41:41,723 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='01c727ca-3620-486d-820f-ddfde7b6952f'
2025-01-02 07:41:41,723 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='7a210504-97ad-450a-a7df-605407c44103'
2025-01-02 07:41:41,746 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='d187e608-15ee-431c-91fa-4d5156e0ef35'
2025-01-02 07:41:41,746 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='ca464c9f-1977-4ad5-a580-e7f5170e2830'
2025-01-02 07:41:41,795 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='536068a4-64a8-417e-a236-0320d05c99c0'
2025-01-02 07:41:41,795 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='b80422d3-645e-4f4a-ac85-dc837089484d'
2025-01-02 07:41:41,860 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='e405f871-005d-4ca8-9a24-102bfccf442c'
2025-01-02 07:41:41,861 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='b90f705b-3082-48e9-986b-022e12921ba8'
2025-01-02 07:41:41,864 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='7ed496b0-1af0-4981-a8d2-0d74be03b830'
2025-01-02 07:41:41,864 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='3bd898ed-bdf0-4fb6-a67f-40851e4a4f7a'
2025-01-02 07:41:41,938 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='d8bf965c-2425-4871-b9b2-fe933e47bc8f'
2025-01-02 07:41:41,939 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='a274b5a6-b874-41d6-9923-4e8418f9cf08'
2025-01-02 07:41:41,951 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='f80f6fa2-b630-4e50-a5db-3dc4e65d12c9'
2025-01-02 07:41:41,953 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='dadc74e7-4057-4094-81c7-64fa7d3ffdec'
2025-01-02 07:41:41,968 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='1e256d06-a7cd-4380-bfc5-ab54ea588990'
2025-01-02 07:41:41,969 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='5eab8652-fc71-44a2-bb54-07dcb5290596'
2025-01-02 07:41:42,010 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='9d6fba2e-5ec2-4dbe-b181-b8b4cfbea040'
2025-01-02 07:41:42,012 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='296d84d1-f769-4c52-9fb4-91cac0f722e3'
2025-01-02 07:41:42,015 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='86dc4753-6f1e-4841-8c0b-6335d0271bee'
2025-01-02 07:41:42,015 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='1a4a1164-4900-41e4-b5f8-7222fbf9eabe'
2025-01-02 07:41:42,049 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='05881342-1baf-4843-ac94-1b75c83dbe62'
2025-01-02 07:41:42,051 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='55cdb5a5-267c-4540-8ed4-5f64f1881159'
2025-01-02 07:41:42,079 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='884c9f55-e8c5-4305-a227-3367fb874b05'
2025-01-02 07:41:42,080 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='62528808-da4d-4409-bda2-b9974ffb6b67'
2025-01-02 07:41:42,116 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='0242f1ae-48ec-46cf-b428-8eb17b74c454'
2025-01-02 07:41:42,119 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='82aca39c-a346-44a8-9de1-a96932e4abb4'
2025-01-02 07:41:42,158 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='ab268c10-44fe-4c1a-bedb-30c40dc1cc52'
2025-01-02 07:41:42,160 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='2c114855-a588-44ba-9727-eb2e07e0af6f'
2025-01-02 07:41:42,175 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='98e08af3-ad89-4589-8089-6e70278ce5e8'
2025-01-02 07:41:42,176 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='608f9433-5922-44f6-9c58-d258ec0be3b7'
2025-01-02 07:41:42,209 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='0f6990da-b251-4233-9714-adae6d89795c'
2025-01-02 07:41:42,211 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='7b6c4358-59d6-4c76-8785-86532238c69f'
2025-01-02 07:41:42,236 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='49994467-3f13-4638-9c44-22346d421a0b'
2025-01-02 07:41:42,237 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='0857030d-720f-4ccd-a15d-d38f57fad32f'
2025-01-02 07:41:42,261 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='cbb59f25-77b6-49b8-b7a7-56eb058b0bf5'
2025-01-02 07:41:42,263 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='e8c970bf-a013-4567-abfc-9c76783a5755'
2025-01-02 07:41:42,287 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='063c86be-4b3c-461b-ae12-3f6c6cdf2051'
2025-01-02 07:41:42,289 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='1e7e3ef4-c93c-4dd7-8f25-e0907256ffce'
2025-01-02 07:41:42,319 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='8f630d70-45d0-4ff8-94ec-676dfea35e06'
2025-01-02 07:41:42,321 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='cb262b55-3e71-4862-802b-716fe0d92fa2'
2025-01-02 07:41:42,385 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='39ad77ed-ecda-41bf-8a2b-a42f31ada9d9'
2025-01-02 07:41:42,387 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='0f374828-4c27-4db9-9f62-841fd30e2aa0'
2025-01-02 07:41:42,388 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='82904f87-e9f8-450a-84d9-7ecc00f997ca'
2025-01-02 07:41:42,390 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='7d04a1dc-ab09-425c-952b-66ecef11bb62'
2025-01-02 07:41:42,409 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='e7fc6bf5-a70f-4f37-8385-5d702d65a6da'
2025-01-02 07:41:42,410 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='739e8d87-6b15-48de-9417-65acc5553af8'
2025-01-02 07:41:42,432 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='ec339bb0-e232-48b1-8073-8cae880fda3b'
2025-01-02 07:41:42,433 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='f7e02467-e172-4518-87ff-090f3ac4a740'
2025-01-02 07:41:42,473 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='68b4457a-96b7-4523-a972-2c9021dcfe0a'
2025-01-02 07:41:42,475 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='89f68eb5-0156-4c2b-a920-8acff87b1cab'
2025-01-02 07:41:42,504 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='d9bb74f9-c0ac-41fa-ba37-da0c3f9606a8'
2025-01-02 07:41:42,506 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='2f7d7b35-eaa6-40ae-ac40-03deaa88084d'
2025-01-02 07:41:42,554 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='aabd3b3c-50e6-4e94-97ca-4944a4e79cfb'
2025-01-02 07:41:42,557 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='bf3a7160-6f12-4252-a7df-5f3cca9e087c'
2025-01-02 07:41:42,561 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='196233f9-4be6-4b4e-ba2a-c7e7161655e0'
2025-01-02 07:41:42,562 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='b809a9c5-8e5e-4acf-9001-4f362dbde255'
2025-01-02 07:41:42,599 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='feeb4748-c65b-415d-acb5-eb1b32ca81c9'
2025-01-02 07:41:42,600 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='e54b489d-d1d9-4bad-a1e5-b3b8593a8ff6'
2025-01-02 07:41:42,628 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='fe99a487-9179-4f2f-9406-8dba7f1e279d'
2025-01-02 07:41:42,630 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='be80d7d3-ff06-47cc-af16-c3ba5a1609db'
2025-01-02 07:41:42,660 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='fa07b2da-33e1-46e7-a5e5-ae680998f918'
2025-01-02 07:41:42,661 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='12a8fa34-a562-48b9-b0b2-2032479518b3'
2025-01-02 07:41:42,708 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='e69900fd-4ca1-47ff-9f12-fe380b3d627c'
2025-01-02 07:41:42,709 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='9572d3f8-8197-4dd6-921e-08522a34d487'
2025-01-02 07:41:42,717 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='997b02a0-fa6d-46ba-9f7a-0d276552aae2'
2025-01-02 07:41:42,718 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='0330fc0f-9294-47c5-bee4-da6df79de04e'
2025-01-02 07:41:42,843 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='0aec9c25-b9f9-4cb5-b89b-ffcd89a19531'
2025-01-02 07:41:42,844 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='adc03e7c-c228-4f06-8df9-29e774452a8d'
2025-01-02 07:41:42,846 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='4351ebbe-e89b-48d0-a090-2fa040ddbaa4'
2025-01-02 07:41:42,847 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='bebc3ba2-dec8-4537-8791-ce00ba82fc46'
2025-01-02 07:41:42,848 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='69f9b20f-4595-4c58-a3f2-5b72db2a4fe9'
2025-01-02 07:41:42,849 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='45c86131-1776-4fa0-b163-e35d8d39c90b'
2025-01-02 07:41:42,879 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='cea95c61-8621-4e18-871b-6c64fbc75834'
2025-01-02 07:41:42,880 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='1fdca1f1-11b6-4c97-9a90-1f0d92413640'
2025-01-02 07:41:42,881 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='658e5188-b8a3-464b-b270-64a3c167354e'
2025-01-02 07:41:42,882 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='3935abb5-5e95-4766-9171-c578a21f33c9'
2025-01-02 07:41:42,957 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='32441bd6-ff15-4bf9-a31e-697be7267cf3'
2025-01-02 07:41:42,958 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='b2e65c5a-e6f6-4265-a448-7057f7a32a28'
2025-01-02 07:41:42,963 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='e86e632d-55f5-43d8-91de-e45562103763'
2025-01-02 07:41:42,964 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='13b0dea3-7c42-4c24-aada-c06009a91792'
2025-01-02 07:41:42,980 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='04166bc4-82b2-4bee-86f1-776189db10b1'
2025-01-02 07:41:42,982 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='5f3915f6-c9a3-49d4-9497-5c90d6d71885'
2025-01-02 07:41:43,026 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='6540ea11-68ce-4385-b729-5171455b5fbd'
2025-01-02 07:41:43,028 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='4673aa11-6c61-4684-8a2b-e3d67bfdad60'
2025-01-02 07:41:43,034 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='45338d20-3f2c-4739-9d56-45fd9831a82b'
2025-01-02 07:41:43,036 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='e62f74d5-2989-4137-81cf-9011dea175fe'
2025-01-02 07:41:43,067 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='ed882b34-1bf3-47c2-8ad2-88f8566e57be'
2025-01-02 07:41:43,068 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='3e0f1f30-90a2-4dec-92ee-c7e8a85a2182'
2025-01-02 07:41:43,130 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='4529ddfd-3337-46f5-9f84-961cbc7eae4b'
2025-01-02 07:41:43,132 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='e13b0586-4461-45aa-8715-f7f317f65c2d'
2025-01-02 07:41:43,135 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='e585fb12-8fb2-4e8a-ab1b-05a73081c926'
2025-01-02 07:41:43,136 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='a44322d4-9651-4d80-a254-07e88c3c7cce'
2025-01-02 07:41:43,149 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='59af58db-1510-495e-906f-f7750c087a16'
2025-01-02 07:41:43,150 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='e0534e47-644c-4c24-b3e7-5507bcb77fc3'
2025-01-02 07:41:43,175 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='bcee85ec-5be7-4774-acdb-822672fe79a9'
2025-01-02 07:41:43,176 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='83b07438-80a9-4867-8dbc-825e62c9f073'
2025-01-02 07:41:43,208 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='3cceeb25-70c4-4077-8614-2e83bba7123a'
2025-01-02 07:41:43,209 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='43865228-c228-4881-91e3-29126fb8c8fb'
2025-01-02 07:41:43,248 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='c8660649-a74c-4ea6-b928-7fdaa1182a27'
2025-01-02 07:41:43,250 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='79b529e3-ce16-43df-9492-df3eee314cc6'
2025-01-02 07:41:43,255 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='7af7156f-dfe9-4c13-ac12-2d6d54222c58'
2025-01-02 07:41:43,257 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='f6451089-d896-41d9-b2ef-8f83183f86e8'
2025-01-02 07:41:43,283 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='77ba2d4e-8eb6-466f-a885-e1f008c0884e'
2025-01-02 07:41:43,284 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='d9d5ce5a-7e8d-4adb-9727-911108d15e43'
2025-01-02 07:41:43,387 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='fa31b0d5-f1df-44ea-92df-9b77510d08bb'
2025-01-02 07:41:43,389 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='ec454ffe-f57b-47a0-927c-a3a1a8551340'
2025-01-02 07:41:43,391 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='44d71d2b-078a-4073-84db-7eb39c122a20'
2025-01-02 07:41:43,392 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='28256d82-ade9-4249-b5b8-3f251a00ad76'
2025-01-02 07:41:43,394 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='9c316f61-e553-4055-94e1-bd2dd4a9dab8'
2025-01-02 07:41:43,395 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='94d1e7d3-1083-48a4-8c23-4bf6948d1157'
2025-01-02 07:41:43,408 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='d28e2fb3-619b-4def-b525-58c48febca76'
2025-01-02 07:41:43,409 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='5af13014-1b20-4aa5-8e65-854d7dfce314'
2025-01-02 07:41:43,437 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='35cf4834-08c2-4e23-a302-be3cf2c32f95'
2025-01-02 07:41:43,438 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='7a166101-8343-4143-99f3-7f05882d958a'
2025-01-02 07:41:43,462 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='05fae356-9ac7-4e15-a223-8b9a11e7a04e'
2025-01-02 07:41:43,464 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='8fcf3fa5-6703-414e-ae88-92ec3447c373'
2025-01-02 07:41:43,486 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='d0ad28ff-e6f0-4228-8a09-8da48b7d676b'
2025-01-02 07:41:43,488 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='ff3668a0-6b48-4a9d-8b9c-a2816b49fe24'
2025-01-02 07:41:43,519 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='c166ccf1-2064-446f-ad44-897497639a36'
2025-01-02 07:41:43,520 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='afed84f1-f266-42df-9d04-9472b304fd32'
2025-01-02 07:41:43,540 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='1d9faaad-5a03-45ec-9a16-b49679c93adf'
2025-01-02 07:41:43,542 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='94713c2a-6735-473d-9344-07794d218a72'
2025-01-02 07:41:43,563 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='c0fb49f5-f1e3-4293-824f-201a523f9844'
2025-01-02 07:41:43,565 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='f71d84ff-33fc-47f8-9ebc-5b9a076f5018'
2025-01-02 07:41:43,592 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='9fb677eb-c5b1-4097-8aa3-c2c1a2b7704e'
2025-01-02 07:41:43,594 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='99f1ede9-f25d-437f-a159-fc2a1937d91b'
2025-01-02 07:41:43,659 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='707dfa2b-3ff6-40f2-8ae4-9afb41873aa3'
2025-01-02 07:41:43,661 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='9b366817-b134-4ab1-a956-e7a373fdd8c7'
2025-01-02 07:41:43,663 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='593b2070-dbc9-43f3-ab87-7d1302fccfb1'
2025-01-02 07:41:43,664 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='b4117a18-0638-4359-a59a-28613c5df21f'
2025-01-02 07:41:43,665 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='f0ab022a-4639-4c43-b34b-1f9f37ae5fb8'
2025-01-02 07:41:43,943 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='420bb939-9e90-4fb2-8ecf-7208048d6cde'
2025-01-02 07:41:43,944 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='c5a8d3c4-eeff-4b02-aeeb-76ccfe3f6b73'
2025-01-02 07:41:43,948 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='7a66daa9-29fd-4530-bcb6-f67ffd9c212a'
2025-01-02 07:41:43,949 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='e5dbdfc2-a189-41c9-86e1-8211e185c68b'
2025-01-02 07:41:43,950 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='984f40d1-2684-4a0a-b905-4492bedfef8e'
2025-01-02 07:41:43,950 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='8cae256e-e2e6-4c6b-97d7-27d254fe873b'
2025-01-02 07:41:43,953 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='185fd52c-b558-4728-b0ae-93c13b770ff6'
2025-01-02 07:41:43,954 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='648ab4d3-e0f0-4da2-b506-442aa441b056'
2025-01-02 07:41:43,997 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='d8bc6f93-4c65-4403-ad8c-33f85d02adba'
2025-01-02 07:41:43,998 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='39001569-543f-447c-8415-ac4ddf2b9538'
2025-01-02 07:41:44,009 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='4f5a82ae-bbc3-421b-b92e-bc07adda5e2b'
2025-01-02 07:41:44,010 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='27d4391e-e8a6-4107-b9ed-2d8d461f048c'
2025-01-02 07:41:44,046 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='8f6daf7f-45de-4d0e-97da-924636217e04'
2025-01-02 07:41:44,047 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='4299a4e0-ee00-4a76-bbfa-5db5cceead26'
2025-01-02 07:41:44,065 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='d64d0530-3a04-4cfb-8938-05f2f80c5eed'
2025-01-02 07:41:44,066 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='2dedef8b-9448-4d39-8888-e4e19a5cd9a3'
2025-01-02 07:41:44,096 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='d82dce18-c9b3-47e5-a538-e61b8ce69e9e'
2025-01-02 07:41:44,097 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='a688d716-e998-4d89-bbed-2f16f2910afe'
2025-01-02 07:41:44,122 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='20af6aaa-1da3-4111-a702-5a2fc943fdc4'
2025-01-02 07:41:44,123 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='a448b483-51a8-47a8-a4b7-f2fff2c63627'
2025-01-02 07:41:44,182 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='4567eb49-9ac2-440e-b766-af7b671adca8'
2025-01-02 07:41:44,183 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='30a1a765-b44c-413a-8b76-7a96ffea2efb'
2025-01-02 07:41:44,186 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='362680bd-6546-4c07-a333-e8b30a3cf93f'
2025-01-02 07:41:44,187 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='a4623f71-ff96-4046-8a22-fa455b101c1d'
2025-01-02 07:41:44,198 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='89f469a3-b0b6-4132-bd63-74ce709ace32'
2025-01-02 07:41:44,199 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='d174f9dd-3df3-4d8f-9cf8-e01a7cad8788'
2025-01-02 07:41:44,200 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='b2060752-e4dd-4692-bb47-6b8ccac77b08'
2025-01-02 07:41:44,203 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5c3e704d-0cbc-4e58-884b-a1c25f454b39', event.id_='151bd994-08ba-404d-a657-e3d53a4cbda5'
2025-01-02 07:41:44,224 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:41:44,226 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:41:44,226 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:41:44,594 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:41:46,473 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:41:47,297 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:41:49,160 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:41:51,211 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:41:53,673 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:41:55,615 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:41:56,232 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:41:58,329 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:41:58,330 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:41:58,330 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:41:58,800 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:41:59,922 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:42:00,844 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:42:03,577 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:42:06,213 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:42:08,225 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:42:10,660 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:42:11,294 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:42:13,864 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:42:13,865 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:42:13,865 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:42:14,219 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:42:15,280 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:42:16,117 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:42:17,546 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:42:19,388 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:42:22,744 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:42:25,994 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:42:26,763 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:42:28,534 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:42:28,536 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:42:28,536 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:42:28,800 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:42:29,833 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:42:30,752 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:42:32,597 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:42:34,797 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:42:38,462 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:42:40,747 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:42:41,416 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:42:43,396 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:42:43,397 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:42:43,397 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:42:43,866 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:42:44,941 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:42:45,807 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:42:47,959 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:42:50,111 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:42:52,980 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:42:57,136 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:42:57,698 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:42:59,950 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:42:59,951 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:42:59,952 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:43:00,969 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:43:04,661 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:43:05,404 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:43:07,007 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:43:09,260 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:45:05,280 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='b22b5915-666f-4a72-b6df-f82ea9e5cdd7'
2025-01-02 07:45:05,283 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='f9129d8e-110e-46a6-8dbe-dd7618f6d1af'
2025-01-02 07:45:05,408 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='18b1b291-57f1-43ef-ab74-d299f29e9398'
2025-01-02 07:45:05,410 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='ce2d6afc-5dd4-4236-b23b-2537474c3274'
2025-01-02 07:45:05,411 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='683edabb-2571-484e-bde3-8a0ddcb671c8'
2025-01-02 07:45:05,413 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='7f42bfaa-4f44-4531-b6f2-7f4737e76386'
2025-01-02 07:45:05,416 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='4031bc21-2ef3-4ff3-8913-9a028b20e136'
2025-01-02 07:45:05,417 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='a8ff14a9-e438-411c-aeff-65849126da86'
2025-01-02 07:45:05,418 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='5f96bc74-c1b7-494e-8cd2-945c4cdeab02'
2025-01-02 07:45:05,419 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='b566c952-15e4-422e-8c99-2fa507b1ebe5'
2025-01-02 07:45:05,421 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='1ccf23f7-a472-4189-baf7-0e236c7adbc7'
2025-01-02 07:45:05,422 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='045f119d-5e4b-43c3-b217-c92d7c6eb11b'
2025-01-02 07:45:05,423 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='5a3bde78-30c7-4a6b-97ab-11daaa3ed47e'
2025-01-02 07:45:05,424 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='faf5c4bc-b2ca-4633-85b3-037d94ddf93d'
2025-01-02 07:45:05,425 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='b2806695-c533-4103-a3bd-096618b3e024'
2025-01-02 07:45:05,426 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='1b009d76-2acc-4eb1-80e2-c0a21effd2fd'
2025-01-02 07:45:05,428 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='3bf541cf-40f2-4734-8af9-866a23448a67'
2025-01-02 07:45:05,429 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='17c7a8a8-e52f-4887-bec9-eab09f12b71a'
2025-01-02 07:45:05,430 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='1ac06e4b-aa7d-4009-b212-afd72a6c5153'
2025-01-02 07:45:05,430 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='345d0a34-269f-4059-9c93-bb238fa055a1'
2025-01-02 07:45:05,432 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='025f2224-6f22-4dec-bb37-43278314694b'
2025-01-02 07:45:05,433 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='b97d13b3-dbe5-48dc-92ea-9d9829d35be1'
2025-01-02 07:45:05,434 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='6ba1bea0-f5b3-4a2f-b2ba-1ab5de3142e5'
2025-01-02 07:45:05,435 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='e06db4cf-aded-436d-8f44-2404b1335487'
2025-01-02 07:45:05,436 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='299c372e-b363-4b43-9980-04920bfb6879'
2025-01-02 07:45:05,437 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='eeced111-60d4-40c9-bbd3-d230a8d3ff36'
2025-01-02 07:45:05,438 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='e369b993-d17a-4aec-8e38-a9056bf1ad1e'
2025-01-02 07:45:05,438 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='dad70c5a-24c5-44d4-a6b6-a3e7ee5734ea'
2025-01-02 07:45:05,439 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='9536723e-0d28-439d-b5c8-d8be5bf0459e'
2025-01-02 07:45:05,440 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='3c235933-0ae4-48cf-9b7d-8ec7d236d575'
2025-01-02 07:45:05,441 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='a07576c3-dd0e-42b7-9bdf-44619b746ac1'
2025-01-02 07:45:05,441 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='8606d624-8711-4845-a54d-f91d39e48840'
2025-01-02 07:45:05,442 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='a795cefb-2723-4d89-bebe-bda7b19f94a7'
2025-01-02 07:45:05,443 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='6fbf1e3d-9f30-44d1-89df-476b02c81f42'
2025-01-02 07:45:05,444 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='acc8ccaa-dc74-4f33-984d-fd015f5458db'
2025-01-02 07:45:05,444 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='d3a8b38d-7267-4cc9-9b4e-2ef37f294390'
2025-01-02 07:45:05,445 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='4796920e-511b-45c4-90d7-8d24428d5a3e'
2025-01-02 07:45:05,446 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='5c059754-2d1f-4f98-a7da-6a91b2ba4188'
2025-01-02 07:45:05,447 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='570c128e-e65d-4c6f-9dc0-3bfb6ee86345'
2025-01-02 07:45:05,448 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='80ce0ef6-e54f-4ae4-9218-91e88df24cdd'
2025-01-02 07:45:05,448 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='3f74d92c-b668-4d0b-9050-dfc9b691d4e4'
2025-01-02 07:45:05,449 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='58cd6cea-f244-4ee1-821b-cfcbe516ee88'
2025-01-02 07:45:05,450 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='3e30b03e-f27d-4867-86dd-db3c871094d6'
2025-01-02 07:45:05,450 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='954ca0cc-ab45-49c1-9129-52f0af9464e0'
2025-01-02 07:45:05,451 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='ae40ca18-21f0-4dcc-8f6e-9637b3c9c81c'
2025-01-02 07:45:05,452 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='6ba9495d-fed1-4696-a754-ea28ddcfdb5e'
2025-01-02 07:45:05,452 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='cfab1ff0-98dd-468f-bd4f-da27ec5213fd'
2025-01-02 07:45:05,453 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='6fa1c234-9d3d-417f-a9f0-924f4569a13a'
2025-01-02 07:45:05,454 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='d627dfc7-c68a-4615-b54d-666f1d8b3f46'
2025-01-02 07:45:05,454 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='a9a1e622-3913-4132-8526-1ed32203c11b'
2025-01-02 07:45:05,455 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='b075c340-94f6-4c20-b6b6-d941a170fe92'
2025-01-02 07:45:05,456 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='3930c8f8-6c21-4024-8ce6-126dc6fc4533'
2025-01-02 07:45:05,456 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='6360e645-76d3-4a7d-83d9-771971620853'
2025-01-02 07:45:05,457 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='8f02540d-6c24-4954-9c02-de9599ab58e9'
2025-01-02 07:45:05,458 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='e18cc1cd-3254-4167-ad85-22f45ecfab17'
2025-01-02 07:45:05,458 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='6f2b5c3c-1926-4ba8-bbb3-362de6f16f10'
2025-01-02 07:45:05,459 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='db549b7a-8f5b-43eb-be3e-1126d0b8749c'
2025-01-02 07:45:05,459 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='be2d8e27-def0-4492-b092-05cac1561038'
2025-01-02 07:45:05,460 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='040c6a27-6594-461c-86d1-07cc679dbfd8'
2025-01-02 07:45:05,460 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='a7422cc5-175f-4cb4-9ca6-c605a156bd6f'
2025-01-02 07:45:05,461 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='5140ce4f-6292-4f35-8854-6ae4e3b2647b'
2025-01-02 07:45:05,462 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='99acf745-e70e-4d80-ba8d-a7feb9293c72'
2025-01-02 07:45:05,462 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='757cddb7-c083-45af-acb8-6fad372850bc'
2025-01-02 07:45:05,463 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='efe9e1a9-e8ff-4a07-9dbf-8d946774beb2'
2025-01-02 07:45:05,463 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='08349fa8-af6e-4c3c-bb2a-3a6b65387181'
2025-01-02 07:45:05,464 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='05ef8c06-4218-4adb-b44a-368bd242e6bd'
2025-01-02 07:45:05,465 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='1638fbc6-346d-49f1-af59-f37548b9323a'
2025-01-02 07:45:05,465 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='8cf29759-0594-4f9a-a338-8620bf0c5d3c'
2025-01-02 07:45:05,466 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='93465543-00cd-4d22-831d-3aa044ce2dfb'
2025-01-02 07:45:05,467 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-120ef77f-6f7e-407f-a24d-d853c07ff044', event.id_='b775de3b-b705-4e32-b15c-67aa4e8a6bf2'
2025-01-02 07:45:05,896 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:45:08,262 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:45:08,860 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:45:14,795 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:45:14,797 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:45:14,797 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:45:15,170 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:45:16,301 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:45:17,239 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:45:20,712 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:45:23,811 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:45:30,469 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:45:33,729 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:45:36,865 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:45:40,126 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:45:40,129 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:45:40,129 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:45:40,615 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:45:41,744 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:45:42,557 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:45:44,600 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:45:46,956 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:45:56,177 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:45:58,563 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:45:59,227 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:46:03,701 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:46:03,702 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:46:03,702 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:46:04,010 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:46:05,126 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:46:06,006 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:46:08,051 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:46:10,615 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:46:13,582 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:46:16,402 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:46:17,166 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:46:20,992 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:46:20,995 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:46:20,995 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:46:21,281 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:46:22,370 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:46:23,210 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:46:25,768 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:46:27,503 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:46:32,545 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:46:35,678 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:46:36,418 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:46:39,650 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:46:39,652 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:46:39,652 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:46:40,025 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:46:41,334 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:46:42,254 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:46:44,258 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:46:46,505 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:46:49,175 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:46:52,502 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:46:53,209 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:46:58,349 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:46:58,352 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:46:58,352 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:46:58,950 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:47:00,478 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:47:01,405 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:47:03,658 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:47:07,138 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:47:10,007 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:47:12,268 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:47:12,814 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:47:15,589 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:47:15,590 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:47:15,590 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:47:16,053 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:47:17,158 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:47:17,996 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:47:20,348 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:47:22,749 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:47:26,596 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:47:29,398 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:47:30,177 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:47:32,976 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:47:32,978 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:47:32,979 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:47:33,459 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:47:34,576 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:47:35,609 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:47:38,169 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:51:17,739 - asyncio - ERROR - Exception in callback Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-eb01e97ac769', bound_args=<BoundArgumen...e wedding?'})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x34d9ee540>)(<WorkflowHand...nthesize': ")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273
handle: <Handle Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-eb01e97ac769', bound_args=<BoundArgumen...e wedding?'})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x34d9ee540>)(<WorkflowHand...nthesize': ")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 271, in __aiter__
    async for part in self._httpcore_stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 407, in __aiter__
    raise exc from None
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 403, in __aiter__
    async for part in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 342, in __aiter__
    raise exc
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 334, in __aiter__
    async for chunk in self._connection._receive_response_body(**kwargs):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 203, in _receive_response_body
    event = await self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 217, in _receive_event
    data = await self._network_stream.read(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_backends/anyio.py", line 32, in read
    with map_exceptions(exc_map):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 247, in _task
    new_ev = await instrumented_step(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/Documents/GitHub/AITA-Judge-Agent/src/agent/AITA_Agent.py", line 126, in synthesize
    response = await response_synthesizer.asynthesize(query, nodes=ev.nodes)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/base.py", line 306, in asynthesize
    response_str = await self.aget_response(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 370, in aget_response
    response = await self._arefine_response_single(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 396, in _arefine_response_single
    response = await aget_response_text(response)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response/utils.py", line 17, in aget_response_text
    async for response in response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/llm.py", line 151, in gen
    async for response in chat_response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/callbacks.py", line 88, in wrapped_gen
    async for x in f_return_val:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/llms/openai/base.py", line 724, in gen
    async for response in await aclient.chat.completions.create(
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 147, in __aiter__
    async for item in self._iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 160, in __stream__
    async for sse in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 151, in _iter_events
    async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 302, in aiter_bytes
    async for chunk in self._aiter_chunks(iterator):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 313, in _aiter_chunks
    async for chunk in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 997, in aiter_bytes
    async for raw_bytes in self.aiter_raw():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 1055, in aiter_raw
    async for raw_stream_bytes in self.stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_client.py", line 176, in __aiter__
    async for chunk in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 270, in __aiter__
    with map_httpcore_exceptions():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/asyncio/events.py", line 84, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 285, in handle_future_result
    raise exception
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 440, in _run_workflow
    raise exception_raised
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 254, in _task
    raise WorkflowRuntimeError(
llama_index.core.workflow.errors.WorkflowRuntimeError: Error in step 'synthesize': 
2025-01-02 07:51:17,749 - src.agent.evaluation.eval_util - WARNING - Error processing sample 216: Error in step 'synthesize': 
2025-01-02 07:51:17,764 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:51:17,766 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:51:17,766 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:51:18,331 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:51:19,882 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:51:20,686 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:51:22,007 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:51:24,166 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:51:26,624 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:51:29,952 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:51:30,615 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:51:33,052 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:51:33,053 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:51:33,054 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:51:33,321 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:51:34,404 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:51:35,323 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:51:37,168 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:51:39,321 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:51:41,445 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:51:44,264 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:51:45,706 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:51:48,718 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:51:48,719 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:51:48,719 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:51:49,064 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:51:50,116 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:51:51,002 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:51:52,527 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:51:55,809 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:51:58,777 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:52:02,652 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:52:03,281 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:52:06,284 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:52:06,287 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:52:06,287 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:52:06,722 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:52:09,221 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:52:09,974 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:52:11,342 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:52:14,645 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:52:16,963 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:52:19,855 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:52:20,488 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:52:22,780 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:52:22,782 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:52:22,783 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:52:23,253 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:52:24,305 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:52:25,302 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:52:26,802 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:52:29,192 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:52:31,648 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:52:34,287 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 07:52:34,971 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:52:37,008 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 07:52:37,009 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 07:52:37,009 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 07:52:37,487 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 07:52:38,548 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 07:52:39,329 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:52:40,357 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:52:42,244 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 07:52:47,721 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:07:54,056 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 08:08:03,322 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 286, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/socket.py", line 706, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/ssl.py", line 1314, in recv_into
    return self.read(nbytes, buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/ssl.py", line 1166, in read
    return self._sslobj.read(len, buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TimeoutError: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 39, in reraise
    raise value
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 713, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)
2025-01-02 08:08:03,698 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 08:08:04,462 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:08:06,476 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 08:08:06,477 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 08:08:06,477 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 08:08:06,760 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 08:08:08,432 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 08:08:09,187 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:08:11,614 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:08:14,965 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:08:18,623 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:08:21,906 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 08:08:22,546 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:08:27,254 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 08:08:27,255 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 08:08:27,255 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 08:08:27,973 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 08:08:29,131 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 08:08:29,931 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:08:31,656 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:08:33,395 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:08:35,599 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:08:38,121 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 08:08:38,797 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:25:18,082 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 08:26:17,376 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-bc255177-2de1-4ed2-8514-97355b607fec', event.id_='ff7ae8f6-31e2-4a5d-8a41-0661d4f56c5c'
2025-01-02 08:26:17,379 - src.agent.evaluation.eval_util - WARNING - Error processing sample 224: 
2025-01-02 08:26:17,395 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 08:26:17,397 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 08:26:17,397 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 08:26:17,803 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 08:26:19,587 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 08:26:20,436 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:26:22,996 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:26:25,453 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:26:28,523 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:26:31,015 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 08:26:31,609 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:26:34,401 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 08:26:34,402 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 08:26:34,402 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 08:26:34,874 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 08:26:36,511 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 08:26:37,436 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:26:39,378 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:26:41,323 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:26:43,679 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:26:46,454 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 08:26:47,368 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:26:49,587 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 08:26:49,590 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 08:26:49,591 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 08:26:50,343 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 08:26:51,493 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 08:26:52,710 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:26:55,339 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:27:04,170 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:27:14,397 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:27:25,952 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 08:27:26,671 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:27:31,831 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 08:27:31,833 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 08:27:31,834 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 08:27:32,328 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 08:27:33,753 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 08:27:34,577 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:27:36,621 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:27:43,078 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:27:48,811 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:27:51,348 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 08:27:51,980 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:43:56,155 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 08:44:55,314 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-e1a565ec-3981-4788-ba56-e2854fadb427', event.id_='3dc44bf9-668a-4182-98c6-f9273075f145'
2025-01-02 08:44:55,316 - src.agent.evaluation.eval_util - WARNING - Error processing sample 228: 
2025-01-02 08:44:55,354 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 08:44:55,356 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 08:44:55,356 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 08:44:55,825 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 08:44:57,522 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 08:44:58,361 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:45:00,202 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:45:03,105 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:45:05,629 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:45:07,969 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 08:45:08,596 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:45:11,152 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 08:45:11,153 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 08:45:11,153 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 08:45:11,571 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 08:45:12,631 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 08:45:13,449 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:45:15,975 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 08:45:18,125 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:00:01,069 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 09:01:00,271 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-4b1d5fdb-f6f5-4e45-969d-1e6ffcc31f50', event.id_='5b102a79-9b3f-4963-b147-9d2aa89e6627'
2025-01-02 09:01:00,687 - asyncio - ERROR - Exception in callback Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-06dd883da8ef', bound_args=<BoundArgumen...hen broke?'})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x34bb945c0>)(<WorkflowHand...nthesize': ")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273
handle: <Handle Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-06dd883da8ef', bound_args=<BoundArgumen...hen broke?'})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x34bb945c0>)(<WorkflowHand...nthesize': ")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 271, in __aiter__
    async for part in self._httpcore_stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 407, in __aiter__
    raise exc from None
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 403, in __aiter__
    async for part in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 342, in __aiter__
    raise exc
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 334, in __aiter__
    async for chunk in self._connection._receive_response_body(**kwargs):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 203, in _receive_response_body
    event = await self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 217, in _receive_event
    data = await self._network_stream.read(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_backends/anyio.py", line 32, in read
    with map_exceptions(exc_map):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 247, in _task
    new_ev = await instrumented_step(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/Documents/GitHub/AITA-Judge-Agent/src/agent/AITA_Agent.py", line 126, in synthesize
    response = await response_synthesizer.asynthesize(query, nodes=ev.nodes)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/base.py", line 306, in asynthesize
    response_str = await self.aget_response(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 370, in aget_response
    response = await self._arefine_response_single(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 396, in _arefine_response_single
    response = await aget_response_text(response)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response/utils.py", line 17, in aget_response_text
    async for response in response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/llm.py", line 151, in gen
    async for response in chat_response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/callbacks.py", line 88, in wrapped_gen
    async for x in f_return_val:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/llms/openai/base.py", line 724, in gen
    async for response in await aclient.chat.completions.create(
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 147, in __aiter__
    async for item in self._iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 160, in __stream__
    async for sse in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 151, in _iter_events
    async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 302, in aiter_bytes
    async for chunk in self._aiter_chunks(iterator):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 313, in _aiter_chunks
    async for chunk in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 997, in aiter_bytes
    async for raw_bytes in self.aiter_raw():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 1055, in aiter_raw
    async for raw_stream_bytes in self.stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_client.py", line 176, in __aiter__
    async for chunk in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 270, in __aiter__
    with map_httpcore_exceptions():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/asyncio/events.py", line 84, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 285, in handle_future_result
    raise exception
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 440, in _run_workflow
    raise exception_raised
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 254, in _task
    raise WorkflowRuntimeError(
llama_index.core.workflow.errors.WorkflowRuntimeError: Error in step 'synthesize': 
2025-01-02 09:01:00,697 - src.agent.evaluation.eval_util - WARNING - Error processing sample 230: Error in step 'synthesize': 
2025-01-02 09:01:00,714 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 09:01:00,715 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 09:01:00,716 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 09:01:01,093 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 09:01:04,782 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 09:01:05,572 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:01:07,222 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:01:10,379 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:01:13,552 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:01:16,878 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 09:01:17,651 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:01:21,715 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 09:01:21,716 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 09:01:21,716 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 09:01:22,148 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 09:01:23,894 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 09:01:24,821 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:01:27,274 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:01:31,269 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:01:35,058 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:01:38,447 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 09:01:39,153 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:01:43,415 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 09:01:43,417 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 09:01:43,417 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 09:01:43,685 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 09:01:44,787 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 09:01:45,608 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:01:47,550 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:01:51,343 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:01:53,592 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:01:57,822 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 09:01:58,611 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:02:02,991 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 09:02:02,992 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 09:02:02,992 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 09:02:03,482 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 09:02:04,580 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 09:02:05,678 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:02:08,236 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:02:12,846 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:02:15,709 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:02:19,523 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 09:02:20,214 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:02:22,820 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 09:02:22,822 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 09:02:22,822 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 09:02:23,170 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 09:02:24,428 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 09:02:25,441 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:02:27,075 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:02:31,685 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:02:34,756 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:02:41,612 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 09:02:42,539 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:18:24,044 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 09:19:23,263 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-622e39a7-640f-4711-a9cc-ca020f5a1ef0', event.id_='1a0c2f2e-9fbd-4980-b754-6625a282afce'
2025-01-02 09:19:23,265 - src.agent.evaluation.eval_util - WARNING - Error processing sample 235: 
2025-01-02 09:19:23,289 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 09:19:23,292 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 09:19:23,293 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 09:19:23,986 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 09:19:26,378 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 09:19:27,341 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:19:30,512 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:19:33,648 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:19:38,081 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:19:41,799 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 09:19:42,556 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:19:45,275 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 09:19:45,276 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 09:19:45,276 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 09:19:45,979 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 09:19:47,080 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 09:19:51,199 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:19:53,165 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:19:55,396 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:19:57,956 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:20:00,110 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 09:20:00,924 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:20:03,360 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 09:20:03,362 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 09:20:03,363 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 09:20:04,102 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 09:20:05,631 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 09:20:08,444 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:20:10,436 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:20:13,009 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:20:16,185 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:20:18,249 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 09:20:19,050 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:20:22,496 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 09:20:22,496 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 09:20:22,497 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 09:20:22,982 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 09:20:24,073 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 09:20:25,093 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:20:28,372 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:20:32,254 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:20:35,433 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:20:39,474 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 09:20:40,436 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:20:44,868 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 09:20:44,870 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 09:20:44,871 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 09:20:45,364 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 09:20:47,105 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 09:20:48,032 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:20:50,282 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:20:53,865 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:20:57,655 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:21:02,438 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 09:21:03,185 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:21:06,461 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 09:21:06,462 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 09:21:06,462 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 09:21:06,873 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 09:21:07,979 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 09:21:08,816 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:21:11,684 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:21:15,885 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:21:19,470 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:21:23,715 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 09:21:24,798 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:21:28,763 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 09:21:28,766 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 09:21:28,766 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 09:21:29,301 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 09:21:30,393 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 09:21:31,243 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:21:34,464 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:21:37,487 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:21:41,479 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:21:46,001 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 09:21:46,806 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:21:49,516 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 09:21:49,517 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 09:21:49,517 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 09:21:49,820 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 09:21:50,926 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 09:21:51,829 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:21:54,254 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:21:57,866 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:22:03,452 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:22:06,225 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 09:22:07,085 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:22:10,680 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 09:22:10,682 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 09:22:10,683 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 09:22:11,184 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 09:22:12,816 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 09:22:13,648 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:22:16,403 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:22:19,371 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:22:22,649 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:22:26,282 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 09:22:26,948 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:22:29,210 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 09:22:29,210 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 09:22:29,211 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 09:22:29,716 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 09:22:30,962 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 09:22:32,174 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:22:34,431 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:22:36,984 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:22:39,748 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:22:43,544 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 09:22:44,254 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:22:48,144 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 09:22:48,145 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 09:22:48,145 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 09:22:48,556 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 09:22:49,809 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 09:22:50,913 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:22:53,368 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:22:56,234 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:22:58,868 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:23:02,546 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 09:23:04,430 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:23:09,640 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 09:23:09,643 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 09:23:09,643 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 09:23:10,268 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 09:23:11,382 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 09:23:12,320 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:23:15,488 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:38:17,875 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 09:39:17,137 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-9dd9ccb1-9f9f-4857-b1c5-561c7dc601f6', event.id_='4f19dfa9-7687-4ab1-bf22-c74363e5868e'
2025-01-02 09:39:17,527 - asyncio - ERROR - Exception in callback Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-ebea6421cd12', bound_args=<BoundArgumen...ld digger?'})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x3492f8400>)(<WorkflowHand...nthesize': ")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273
handle: <Handle Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-ebea6421cd12', bound_args=<BoundArgumen...ld digger?'})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x3492f8400>)(<WorkflowHand...nthesize': ")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 271, in __aiter__
    async for part in self._httpcore_stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 407, in __aiter__
    raise exc from None
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 403, in __aiter__
    async for part in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 342, in __aiter__
    raise exc
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 334, in __aiter__
    async for chunk in self._connection._receive_response_body(**kwargs):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 203, in _receive_response_body
    event = await self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 217, in _receive_event
    data = await self._network_stream.read(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_backends/anyio.py", line 32, in read
    with map_exceptions(exc_map):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 247, in _task
    new_ev = await instrumented_step(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/Documents/GitHub/AITA-Judge-Agent/src/agent/AITA_Agent.py", line 126, in synthesize
    response = await response_synthesizer.asynthesize(query, nodes=ev.nodes)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/base.py", line 306, in asynthesize
    response_str = await self.aget_response(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 370, in aget_response
    response = await self._arefine_response_single(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 396, in _arefine_response_single
    response = await aget_response_text(response)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response/utils.py", line 17, in aget_response_text
    async for response in response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/llm.py", line 151, in gen
    async for response in chat_response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/callbacks.py", line 88, in wrapped_gen
    async for x in f_return_val:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/llms/openai/base.py", line 724, in gen
    async for response in await aclient.chat.completions.create(
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 147, in __aiter__
    async for item in self._iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 160, in __stream__
    async for sse in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 151, in _iter_events
    async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 302, in aiter_bytes
    async for chunk in self._aiter_chunks(iterator):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 313, in _aiter_chunks
    async for chunk in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 997, in aiter_bytes
    async for raw_bytes in self.aiter_raw():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 1055, in aiter_raw
    async for raw_stream_bytes in self.stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_client.py", line 176, in __aiter__
    async for chunk in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 270, in __aiter__
    with map_httpcore_exceptions():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/asyncio/events.py", line 84, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 285, in handle_future_result
    raise exception
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 440, in _run_workflow
    raise exception_raised
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 254, in _task
    raise WorkflowRuntimeError(
llama_index.core.workflow.errors.WorkflowRuntimeError: Error in step 'synthesize': 
2025-01-02 09:39:17,534 - src.agent.evaluation.eval_util - WARNING - Error processing sample 247: Error in step 'synthesize': 
2025-01-02 09:39:17,550 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 09:39:17,552 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 09:39:17,552 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 09:39:18,116 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 09:39:20,101 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 09:39:21,023 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:39:23,268 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:39:24,962 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:39:30,642 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:39:34,773 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 09:39:35,507 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:39:38,417 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 09:39:38,418 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 09:39:38,418 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 09:39:39,042 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 09:39:40,092 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 09:39:40,986 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:39:43,033 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:39:45,590 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:39:48,562 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:39:51,848 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 09:39:52,446 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:39:55,624 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 09:39:55,626 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 09:39:55,626 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 09:39:56,452 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 09:39:57,500 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 09:39:58,604 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:40:04,539 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:40:06,801 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:40:09,248 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:40:12,233 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 09:40:13,044 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:40:18,058 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 09:40:18,059 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 09:40:18,059 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 09:40:18,470 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 09:40:19,535 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 09:40:20,432 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:40:27,120 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:40:30,035 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:40:34,029 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:40:37,263 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 09:40:38,031 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:40:42,215 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 09:40:42,217 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 09:40:42,217 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 09:40:42,578 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 09:40:43,868 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 09:40:44,784 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:40:47,240 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:40:50,434 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:40:54,306 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:40:58,721 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 09:40:59,423 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:56:02,019 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 09:57:01,333 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-ce7a0bf4-c16f-4618-badc-ec1bba75072d', event.id_='cd59589a-d30c-4d65-989c-90b108594b41'
2025-01-02 09:57:01,336 - src.agent.evaluation.eval_util - WARNING - Error processing sample 252: 
2025-01-02 09:57:01,376 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 09:57:01,380 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 09:57:01,380 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 09:57:01,753 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 09:57:05,012 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 09:57:05,984 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:57:07,932 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:57:11,107 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:57:14,859 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:57:25,114 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 09:57:25,688 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 09:57:28,839 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 09:57:28,840 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 09:57:28,840 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 09:57:29,441 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 09:57:30,666 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 09:57:31,589 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:12:53,500 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:12:53,974 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 10:12:54,856 - asyncio - ERROR - Exception in callback Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-9b15526cb12d', bound_args=<BoundArgumen...expensive?"})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x34a53df80>)(<WorkflowHand...nthesize': ")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273
handle: <Handle Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-9b15526cb12d', bound_args=<BoundArgumen...expensive?"})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x34a53df80>)(<WorkflowHand...nthesize': ")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 271, in __aiter__
    async for part in self._httpcore_stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 407, in __aiter__
    raise exc from None
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 403, in __aiter__
    async for part in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 342, in __aiter__
    raise exc
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 334, in __aiter__
    async for chunk in self._connection._receive_response_body(**kwargs):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 203, in _receive_response_body
    event = await self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 217, in _receive_event
    data = await self._network_stream.read(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_backends/anyio.py", line 32, in read
    with map_exceptions(exc_map):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 247, in _task
    new_ev = await instrumented_step(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/Documents/GitHub/AITA-Judge-Agent/src/agent/AITA_Agent.py", line 126, in synthesize
    response = await response_synthesizer.asynthesize(query, nodes=ev.nodes)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/base.py", line 306, in asynthesize
    response_str = await self.aget_response(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 370, in aget_response
    response = await self._arefine_response_single(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 396, in _arefine_response_single
    response = await aget_response_text(response)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response/utils.py", line 17, in aget_response_text
    async for response in response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/llm.py", line 151, in gen
    async for response in chat_response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/callbacks.py", line 88, in wrapped_gen
    async for x in f_return_val:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/llms/openai/base.py", line 724, in gen
    async for response in await aclient.chat.completions.create(
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 147, in __aiter__
    async for item in self._iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 160, in __stream__
    async for sse in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 151, in _iter_events
    async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 302, in aiter_bytes
    async for chunk in self._aiter_chunks(iterator):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 313, in _aiter_chunks
    async for chunk in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 997, in aiter_bytes
    async for raw_bytes in self.aiter_raw():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 1055, in aiter_raw
    async for raw_stream_bytes in self.stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_client.py", line 176, in __aiter__
    async for chunk in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 270, in __aiter__
    with map_httpcore_exceptions():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/asyncio/events.py", line 84, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 285, in handle_future_result
    raise exception
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 440, in _run_workflow
    raise exception_raised
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 254, in _task
    raise WorkflowRuntimeError(
llama_index.core.workflow.errors.WorkflowRuntimeError: Error in step 'synthesize': 
2025-01-02 10:12:54,865 - src.agent.evaluation.eval_util - WARNING - Error processing sample 254: Error in step 'synthesize': 
2025-01-02 10:12:54,882 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:12:54,884 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:12:54,884 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:12:55,520 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:12:57,551 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:12:58,325 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:13:00,007 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:13:03,081 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:13:05,632 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:13:07,571 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:13:08,302 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:13:10,802 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:13:10,804 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:13:10,804 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:13:11,275 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:13:12,478 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:13:13,760 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:13:18,385 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:13:21,920 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:13:26,324 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:13:31,355 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:13:32,059 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:13:35,709 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:13:35,710 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:13:35,711 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:13:36,028 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:13:37,108 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:13:38,002 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:13:40,047 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:13:49,157 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:13:54,487 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:13:56,429 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:13:57,070 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:14:03,475 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:14:03,476 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:14:03,477 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:14:03,831 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:14:04,985 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:14:06,036 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:14:09,524 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:14:13,738 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:14:17,020 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:14:21,653 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:14:22,339 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:14:26,622 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:14:26,623 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:14:26,623 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:14:27,149 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:14:28,337 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:14:29,304 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:14:31,322 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:14:33,911 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:14:36,879 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:14:40,022 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:14:40,669 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:14:43,802 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:14:43,804 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:14:43,804 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:14:44,134 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:14:45,327 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:14:46,203 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:14:48,247 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:14:51,118 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:15:00,041 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:15:03,090 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:15:03,814 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:15:06,880 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:15:06,881 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:15:06,881 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:15:07,398 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:15:08,452 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:15:09,253 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:15:11,903 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:15:14,359 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:15:18,047 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:15:21,067 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:15:21,730 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:15:24,587 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:15:24,589 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:15:24,590 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:15:25,218 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:15:26,516 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:15:27,468 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:15:30,951 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:15:33,508 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:15:37,043 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:15:39,686 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:15:40,475 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:15:42,976 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:15:42,977 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:15:42,977 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:15:43,256 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:15:44,347 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:15:45,288 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:15:47,472 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:16:05,047 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:16:07,917 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:16:11,980 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:16:12,833 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:16:15,641 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:16:15,644 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:16:15,644 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:16:16,160 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:16:17,746 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:16:18,673 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:16:21,325 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:16:25,543 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:16:31,168 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:16:33,824 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:16:34,642 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:16:40,778 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:16:40,779 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:16:40,779 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:16:41,336 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:16:42,438 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:16:43,249 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:16:46,109 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:16:49,490 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:16:53,078 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:16:56,693 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:16:57,317 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:17:02,470 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:17:02,472 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:17:02,472 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:17:03,017 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:17:04,114 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:17:04,856 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:17:07,275 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:17:10,485 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:17:18,881 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:17:21,462 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:17:22,134 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:17:24,763 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:17:24,764 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:17:24,764 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:17:25,337 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:17:26,441 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:17:27,279 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:17:30,350 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:17:33,864 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:17:37,007 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:17:39,811 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:17:40,588 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:17:43,338 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:17:43,340 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:17:43,340 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:17:43,618 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:17:44,724 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:17:46,021 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:17:48,376 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:17:51,261 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:17:54,722 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:17:58,458 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:17:59,334 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:18:05,175 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:18:05,176 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:18:05,176 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:18:05,680 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:18:06,752 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:18:07,627 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:18:09,775 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:18:14,998 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:18:18,174 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:18:21,966 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:18:22,676 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:18:38,036 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:18:38,038 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:18:38,039 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:18:38,654 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:18:40,184 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:18:41,012 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:18:43,777 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:18:47,255 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:18:50,738 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:18:54,079 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:18:54,732 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:23:35,473 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 286, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/socket.py", line 706, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/ssl.py", line 1314, in recv_into
    return self.read(nbytes, buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/ssl.py", line 1166, in read
    return self._sslobj.read(len, buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TimeoutError: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 39, in reraise
    raise value
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 713, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)
2025-01-02 10:23:35,522 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:23:35,523 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:23:35,523 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:23:36,234 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:23:38,162 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:23:39,203 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:23:41,689 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:23:44,632 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:23:48,566 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:23:52,838 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:23:53,948 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:23:57,253 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:23:57,256 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:23:57,256 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:23:57,843 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:23:58,964 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:23:59,892 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:24:04,360 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:24:06,480 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:24:09,106 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:24:11,723 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:24:12,380 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:24:15,091 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:24:15,092 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:24:15,093 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:24:15,664 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:24:16,781 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:24:17,707 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:24:21,910 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:24:25,798 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:24:28,462 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:24:31,661 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:24:32,350 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:24:36,832 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:24:36,835 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:24:36,835 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:24:37,472 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:24:38,624 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:24:39,625 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:24:42,389 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:24:45,561 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:24:48,529 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:24:56,809 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:24:57,646 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:25:01,446 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:25:01,447 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:25:01,448 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:25:02,050 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:25:03,805 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:25:04,712 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:25:07,065 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:25:09,830 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:25:13,212 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:25:16,259 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:25:16,998 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:25:19,631 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:25:19,634 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:25:19,634 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:25:20,272 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:25:21,348 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:25:22,145 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:25:24,662 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:25:29,490 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:25:32,563 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:25:36,214 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:25:36,968 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:25:40,340 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:25:40,342 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:25:40,342 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:25:40,860 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:25:42,030 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:25:42,803 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:25:44,850 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:25:50,178 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:25:54,071 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:41:26,141 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 10:42:25,212 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-cf0b77ab-d74a-48b5-9f7b-98b563b8cf1f', event.id_='27fdf9f0-488c-4b5e-a0e3-034e52118f6e'
2025-01-02 10:42:25,616 - asyncio - ERROR - Exception in callback Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-be55da9b8a6d', bound_args=<BoundArgumen...ic school?'})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x350c31f00>)(<WorkflowHand...nthesize': ")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273
handle: <Handle Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-be55da9b8a6d', bound_args=<BoundArgumen...ic school?'})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x350c31f00>)(<WorkflowHand...nthesize': ")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 271, in __aiter__
    async for part in self._httpcore_stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 407, in __aiter__
    raise exc from None
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 403, in __aiter__
    async for part in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 342, in __aiter__
    raise exc
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 334, in __aiter__
    async for chunk in self._connection._receive_response_body(**kwargs):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 203, in _receive_response_body
    event = await self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 217, in _receive_event
    data = await self._network_stream.read(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_backends/anyio.py", line 32, in read
    with map_exceptions(exc_map):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 247, in _task
    new_ev = await instrumented_step(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/Documents/GitHub/AITA-Judge-Agent/src/agent/AITA_Agent.py", line 126, in synthesize
    response = await response_synthesizer.asynthesize(query, nodes=ev.nodes)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/base.py", line 306, in asynthesize
    response_str = await self.aget_response(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 370, in aget_response
    response = await self._arefine_response_single(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 396, in _arefine_response_single
    response = await aget_response_text(response)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response/utils.py", line 17, in aget_response_text
    async for response in response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/llm.py", line 151, in gen
    async for response in chat_response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/callbacks.py", line 88, in wrapped_gen
    async for x in f_return_val:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/llms/openai/base.py", line 724, in gen
    async for response in await aclient.chat.completions.create(
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 147, in __aiter__
    async for item in self._iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 160, in __stream__
    async for sse in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 151, in _iter_events
    async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 302, in aiter_bytes
    async for chunk in self._aiter_chunks(iterator):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 313, in _aiter_chunks
    async for chunk in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 997, in aiter_bytes
    async for raw_bytes in self.aiter_raw():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 1055, in aiter_raw
    async for raw_stream_bytes in self.stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_client.py", line 176, in __aiter__
    async for chunk in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 270, in __aiter__
    with map_httpcore_exceptions():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/asyncio/events.py", line 84, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 285, in handle_future_result
    raise exception
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 440, in _run_workflow
    raise exception_raised
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 254, in _task
    raise WorkflowRuntimeError(
llama_index.core.workflow.errors.WorkflowRuntimeError: Error in step 'synthesize': 
2025-01-02 10:42:25,623 - src.agent.evaluation.eval_util - WARNING - Error processing sample 277: Error in step 'synthesize': 
2025-01-02 10:42:25,639 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:42:25,641 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:42:25,641 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:42:26,166 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:42:27,949 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:42:28,817 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:42:31,174 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:42:34,819 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:42:39,363 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:42:42,816 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:42:50,426 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:42:53,282 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:42:53,283 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:42:53,283 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:42:53,593 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:42:54,759 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:42:55,649 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:42:57,697 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:43:01,793 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:43:06,194 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:43:09,671 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:43:10,277 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:43:12,744 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:43:12,744 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:43:12,745 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:43:13,109 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:43:14,231 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:43:15,206 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:43:17,765 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:43:20,633 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:43:24,425 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:43:27,011 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:43:27,555 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:43:30,699 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:43:30,701 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:43:30,701 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:43:31,184 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:43:32,359 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:43:33,337 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:43:35,686 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:43:39,170 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:43:43,264 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:43:46,518 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:43:47,606 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:43:50,429 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:43:50,430 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:43:50,430 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:43:50,883 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:43:52,087 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:43:52,846 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:43:55,245 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:43:58,314 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:59:10,470 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 286, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/socket.py", line 706, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/ssl.py", line 1314, in recv_into
    return self.read(nbytes, buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/ssl.py", line 1166, in read
    return self._sslobj.read(len, buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TimeoutError: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 39, in reraise
    raise value
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 713, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)
2025-01-02 10:59:11,318 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:59:14,216 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:59:14,976 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:59:17,826 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:59:17,828 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:59:17,828 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:59:18,259 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:59:20,121 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:59:21,012 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:59:23,417 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:59:26,246 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:59:30,382 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:59:33,515 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:59:34,140 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:59:37,538 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 10:59:37,539 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 10:59:37,539 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 10:59:38,104 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 10:59:39,248 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 10:59:41,893 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:59:46,354 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:59:50,492 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:59:54,076 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 10:59:57,722 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 10:59:58,319 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:00:03,888 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:00:03,891 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:00:03,891 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:00:04,319 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:00:05,436 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:00:06,361 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:00:08,513 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:00:11,916 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:00:15,374 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:00:17,271 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:00:18,058 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:00:20,577 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:00:20,578 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:00:20,579 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:00:21,108 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:00:22,174 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:00:23,053 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:00:24,642 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:00:26,738 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:00:28,996 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:00:31,224 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:00:31,877 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:00:36,057 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:00:36,060 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:00:36,060 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:00:36,463 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:00:37,594 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:00:38,362 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:00:40,052 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:00:43,429 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:00:45,887 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:00:48,448 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:00:49,369 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:00:52,496 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:00:52,497 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:00:52,498 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:00:52,787 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:00:53,929 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:00:54,799 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:00:58,074 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:01:01,350 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:01:04,728 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:01:07,813 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:01:08,726 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:01:12,057 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:01:12,059 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:01:12,060 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:01:12,618 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:01:14,045 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:01:14,869 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:01:17,117 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:01:20,396 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:01:23,674 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:01:26,458 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:01:27,051 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:01:29,954 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:01:29,955 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:01:29,955 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:01:30,435 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:01:31,585 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:01:32,586 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:01:34,529 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:03:31,057 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:03:33,821 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:03:37,320 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:03:38,026 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:03:41,421 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:03:41,424 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:03:41,425 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:03:42,426 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:03:43,653 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:03:44,403 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:03:46,624 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:03:49,488 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:03:52,475 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:03:54,923 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:03:55,517 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:03:59,621 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:03:59,622 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:03:59,622 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:04:00,036 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:04:02,871 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:04:03,826 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:04:05,526 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:04:08,052 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:04:10,864 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:04:14,691 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:04:15,499 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:04:18,759 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:04:18,761 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:04:18,761 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:04:19,139 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:04:20,278 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:04:21,232 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:04:22,969 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:04:26,145 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:04:29,630 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:04:33,366 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:04:34,440 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:04:39,139 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:04:39,140 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:04:39,140 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:04:39,425 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:04:40,534 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:04:41,509 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:04:44,169 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:04:48,000 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:04:51,439 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:04:54,999 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:04:56,044 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:04:58,474 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:04:58,477 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:04:58,477 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:04:59,124 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:05:00,756 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:05:04,650 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:05:07,031 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:05:22,270 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:05:24,925 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:05:27,059 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:05:27,891 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:05:29,974 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:05:29,975 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:05:29,976 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:05:30,240 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:05:31,715 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:05:32,710 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:05:35,166 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:05:38,747 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:05:41,852 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:05:47,481 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:05:48,168 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:05:53,145 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:05:53,148 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:05:53,148 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:05:53,523 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:05:55,028 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:05:55,795 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:05:57,483 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:06:00,352 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:06:03,936 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:06:06,918 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:06:07,900 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:06:11,099 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:06:11,099 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:06:11,100 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:06:11,615 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:06:12,811 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:06:13,613 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:06:15,710 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:06:18,529 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:06:22,878 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:06:28,476 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:06:29,465 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:06:33,509 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:06:33,512 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:06:33,512 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:06:33,940 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:06:35,068 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:06:36,099 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:06:40,481 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:06:42,543 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:06:49,401 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:06:52,961 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:06:53,702 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:06:55,494 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:06:55,495 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:06:55,495 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:06:55,959 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:06:57,123 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:06:58,429 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:07:02,992 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:07:08,303 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:07:12,544 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:07:16,109 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:07:16,821 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:07:19,595 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:07:19,597 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:07:19,598 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:07:20,222 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:07:21,353 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:07:22,276 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:07:24,217 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:07:26,367 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:07:30,055 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:07:32,586 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:07:33,227 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:07:36,142 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:07:36,143 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:07:36,143 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:07:36,541 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:07:37,719 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:07:38,757 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:07:41,933 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:07:43,880 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:07:50,887 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:07:53,820 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:07:54,527 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:07:58,756 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:07:58,758 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:07:58,758 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:07:59,239 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:08:00,370 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:08:04,169 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:08:06,108 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:08:11,420 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:08:14,392 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:08:16,977 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:08:17,668 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:08:21,223 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:08:21,223 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:08:21,224 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:08:21,577 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:08:22,630 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:08:23,399 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:08:26,983 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:08:29,894 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:08:33,027 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:08:36,470 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:08:37,430 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:08:40,730 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:08:40,731 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:08:40,732 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:08:41,078 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:08:42,206 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:08:43,036 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:08:44,905 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:08:46,439 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:08:49,407 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:08:51,955 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:08:52,791 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:08:55,420 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:08:55,421 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:08:55,421 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:08:55,967 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:08:57,029 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:08:58,019 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:08:59,447 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:09:03,132 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:09:05,797 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:09:08,902 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:09:09,584 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:09:12,378 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:09:12,380 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:09:12,380 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:09:13,171 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:09:14,808 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:09:16,144 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:09:17,780 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:09:20,235 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:09:22,690 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:09:30,919 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:09:31,599 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:09:35,518 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:09:35,519 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:09:35,520 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:09:35,752 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:09:36,844 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:09:37,747 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:09:40,322 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:09:44,093 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:09:48,392 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:09:56,929 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:09:57,711 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:10:00,103 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:10:00,104 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:10:00,104 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:10:01,478 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:10:04,735 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:10:05,600 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:10:07,541 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:10:11,256 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:10:14,300 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:10:17,098 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:10:17,756 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:10:21,631 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:10:21,632 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:10:21,632 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:10:22,495 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:10:23,924 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:10:25,011 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:10:26,894 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:10:30,172 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:10:33,034 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:10:39,200 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:10:39,898 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:10:43,081 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:10:43,083 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:10:43,083 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:10:43,589 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:10:46,045 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:10:46,969 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:10:49,114 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:10:52,493 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:10:56,284 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:10:59,896 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:11:00,790 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:11:03,778 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:11:03,779 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:11:03,779 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:11:04,456 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:11:05,642 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:11:06,525 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:11:08,875 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:11:11,025 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:11:14,508 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:11:18,944 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:11:19,562 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:11:24,135 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:11:24,138 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:11:24,138 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:11:24,598 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:11:25,592 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:11:26,691 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:11:29,724 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:11:32,510 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:11:35,297 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:11:38,338 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:11:38,978 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:11:48,086 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:11:48,088 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:11:48,088 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:11:48,608 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:11:49,937 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:11:50,754 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:11:52,418 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:11:54,852 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:11:58,130 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:12:03,558 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:12:04,221 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:12:07,973 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:12:07,976 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:12:07,976 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:12:08,297 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:12:09,408 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:12:10,210 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:12:12,567 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:12:16,055 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:12:18,914 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:12:21,574 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:12:22,296 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:12:25,862 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:12:25,862 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:12:25,862 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:12:26,597 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:12:27,759 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:12:28,539 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:12:31,335 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:12:35,305 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:12:38,400 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:12:41,628 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:12:42,366 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:12:45,247 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:12:45,250 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:12:45,250 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:12:45,751 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:12:46,792 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:12:47,692 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:12:49,330 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:12:51,583 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:12:54,141 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:12:56,476 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:12:57,213 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:12:59,501 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:12:59,501 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:12:59,501 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:12:59,978 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:13:04,020 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:13:04,780 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:13:08,788 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:13:10,836 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:13:14,112 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:13:33,256 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:13:33,975 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:13:37,883 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:13:37,886 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:13:37,886 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:13:38,248 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:13:39,404 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:13:40,225 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:13:41,963 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:13:43,702 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:13:46,279 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:13:50,483 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:13:51,075 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:13:53,453 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:13:53,454 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:13:53,454 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:13:55,376 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:13:56,589 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:13:57,529 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:13:59,270 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:14:03,577 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:14:06,947 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:14:09,764 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:14:10,433 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:14:13,122 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:14:13,124 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:14:13,125 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:14:16,162 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:14:17,241 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:14:18,110 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:14:20,364 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:14:24,968 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:14:36,145 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:14:40,956 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:14:41,869 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:14:47,690 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:14:47,691 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:14:47,691 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:14:48,088 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:14:49,221 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:14:50,174 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:14:52,001 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:14:55,226 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:14:58,044 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:15:03,325 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:15:04,165 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:15:06,639 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:15:06,641 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:15:06,641 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:15:07,060 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:15:08,164 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:15:09,104 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:15:12,996 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:15:15,761 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:15:25,900 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:15:29,273 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:15:30,101 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:15:33,826 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:15:33,827 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:15:33,827 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:15:34,165 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:15:35,803 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:15:36,954 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:15:38,800 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:15:41,466 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:15:45,251 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:15:48,524 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:15:49,244 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:15:53,170 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:15:53,171 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:15:53,172 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:15:53,493 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:15:54,714 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:15:55,595 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:15:57,335 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:16:00,740 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:16:05,321 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:16:07,825 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:16:08,602 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:16:12,803 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:16:12,805 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:16:12,806 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:16:13,313 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:16:14,453 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:16:18,223 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:16:20,065 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:16:24,061 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:16:27,747 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:16:31,493 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:16:32,356 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:16:35,740 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:16:35,744 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:16:35,744 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:16:36,250 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:16:37,372 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:16:38,297 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:16:40,171 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:16:42,901 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:16:45,871 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:16:50,824 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:16:51,608 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:16:58,862 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:16:58,863 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:16:58,864 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:16:59,287 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:17:01,129 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:17:04,340 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:17:07,876 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:17:11,673 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:17:14,852 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:17:17,507 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:17:18,171 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:17:23,813 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:17:23,816 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:17:23,817 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:17:24,273 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:17:25,907 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:17:26,935 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:17:29,187 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:17:33,178 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:17:36,761 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:17:40,517 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:17:41,269 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:17:44,708 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:17:44,709 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:17:44,709 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:17:45,162 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:17:46,243 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:17:47,101 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:17:49,737 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:17:51,813 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:17:54,476 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:17:57,083 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:17:57,753 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:18:03,708 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:18:03,710 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:18:03,710 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:18:04,208 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:18:05,366 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:18:06,142 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:18:08,404 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:18:11,475 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:18:14,547 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:18:17,015 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:18:17,721 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:18:21,142 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:18:21,143 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:18:21,143 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:18:21,618 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:18:22,850 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:18:23,765 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:18:25,811 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:18:28,945 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:18:32,675 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:18:37,386 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:18:38,098 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:18:43,842 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:18:43,843 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:18:43,844 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:18:44,162 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:18:45,247 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:18:46,087 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:18:48,031 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:18:51,346 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:18:54,482 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:18:56,750 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:18:57,764 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:19:02,598 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:19:02,599 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:19:02,599 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:19:03,093 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:19:04,228 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:19:05,100 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:19:07,281 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:19:11,789 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:19:15,474 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:19:20,432 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:19:21,307 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:19:24,406 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:19:24,409 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:19:24,409 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:19:25,000 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:19:26,157 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:19:27,044 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:19:29,501 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:19:32,882 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:19:36,465 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:19:40,901 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:19:41,892 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:19:46,030 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:19:46,031 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:19:46,031 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:19:46,336 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:19:47,730 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:19:48,964 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:19:51,746 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:19:54,284 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:19:57,663 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:20:03,727 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:20:04,534 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:20:07,663 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:20:07,667 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:20:07,667 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:20:08,197 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:20:09,386 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:20:10,260 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:20:18,862 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:20:21,639 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:20:24,700 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:20:28,035 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:20:28,797 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:20:33,677 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:20:33,678 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:20:33,678 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:20:34,120 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:20:35,353 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:20:36,166 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:20:38,828 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:20:42,615 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:20:46,300 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:20:49,701 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:20:50,383 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:20:55,194 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:20:55,196 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:20:55,196 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:20:56,034 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:20:57,187 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:21:00,384 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:21:03,300 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:21:06,275 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:21:08,728 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:21:18,106 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:21:18,867 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:21:21,220 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:21:21,221 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:21:21,221 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:21:21,567 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:21:22,693 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:21:23,783 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:21:25,932 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:21:28,080 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:21:31,766 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:21:34,853 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:21:35,660 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:21:40,458 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:21:40,459 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:21:40,460 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:21:40,750 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:21:41,911 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:21:42,829 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:21:45,079 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:21:48,561 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:21:51,939 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:21:54,926 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:21:55,629 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:21:59,280 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:21:59,280 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:21:59,281 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:21:59,824 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:22:01,879 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:22:04,475 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:22:07,596 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:22:10,883 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:22:14,775 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:22:17,949 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:22:18,662 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:22:22,035 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:22:22,035 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:22:22,036 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:22:22,557 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:22:23,639 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:22:24,505 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:22:26,239 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:22:30,337 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:22:32,591 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:22:35,032 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:22:35,692 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:22:37,647 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:22:37,648 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:22:37,648 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:22:38,123 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:22:39,194 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:22:39,954 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:22:42,116 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:22:51,842 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:22:54,915 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:22:58,392 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:22:59,112 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:23:03,822 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:23:03,824 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:23:03,825 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:23:05,260 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:23:06,329 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:23:07,203 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:23:09,659 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:23:13,141 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:23:17,543 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:23:21,073 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:23:21,740 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:23:26,293 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:23:26,294 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:23:26,294 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:23:26,864 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:23:27,988 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:23:28,812 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:23:30,548 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:23:33,109 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:23:35,362 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:23:37,066 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:23:38,228 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:23:40,842 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:23:40,842 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:23:40,843 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:23:41,160 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:23:42,256 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:23:43,147 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:23:44,781 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:23:47,155 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:23:49,803 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:23:52,168 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:23:52,871 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:23:55,883 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:23:55,884 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:23:55,885 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:23:56,269 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:23:57,430 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:23:58,199 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:23:59,937 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:24:03,019 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:24:06,124 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:24:09,175 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:24:09,870 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:24:13,995 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:24:13,996 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:24:13,996 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:24:14,690 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:24:15,919 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:24:16,730 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:24:19,304 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:24:21,647 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:24:24,000 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:24:26,525 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:24:27,277 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:24:30,136 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:24:30,137 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:24:30,137 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:24:30,454 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:24:31,614 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:24:32,811 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:24:35,778 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:24:38,442 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:24:42,329 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:24:47,581 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:24:48,269 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:24:52,597 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:24:52,598 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:24:52,598 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:24:53,080 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:24:54,422 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:24:55,339 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:24:56,666 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:24:59,523 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:25:04,139 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:25:07,136 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:25:07,912 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:25:10,898 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:25:10,904 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:25:10,905 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:25:11,262 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:25:12,379 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:25:13,343 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:25:14,978 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:25:18,267 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:25:21,838 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:25:27,631 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:25:28,317 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:25:30,890 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:25:30,893 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:25:30,893 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:25:31,467 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:25:32,570 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:25:33,415 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:25:35,971 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:25:38,941 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:25:42,627 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:25:46,108 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:25:46,829 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:25:51,399 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:25:51,400 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:25:51,400 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:25:51,709 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:25:52,794 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:25:53,686 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:25:56,965 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:25:59,658 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:26:03,107 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:26:06,367 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:26:07,206 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:26:11,573 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:26:11,574 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:26:11,574 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:26:12,121 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:26:13,277 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:26:18,160 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:26:21,440 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:26:25,123 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:26:27,280 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:26:32,803 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:26:33,622 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:26:36,309 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:26:36,309 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:26:36,310 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:26:36,638 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:26:37,762 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:26:38,744 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:26:40,381 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:26:42,636 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:26:45,093 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:26:47,427 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:26:48,299 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:26:58,594 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:26:58,596 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:26:58,596 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:26:59,225 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:27:00,360 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:27:02,092 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:27:04,547 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:27:08,235 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:27:23,900 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:27:37,647 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:27:38,647 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:27:44,109 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:27:44,110 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:27:44,110 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:27:44,428 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:27:45,544 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:27:46,433 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:27:47,865 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:27:50,832 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:27:54,521 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:27:58,346 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:27:59,026 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:28:04,076 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:28:04,077 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:28:04,078 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:28:04,660 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:28:05,737 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:28:06,578 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:28:08,245 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:28:12,029 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:28:16,231 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:28:18,614 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:28:19,241 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:28:21,660 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:28:21,661 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:28:21,661 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:28:22,033 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:28:23,107 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:28:23,910 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:28:26,364 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:28:29,236 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:28:31,547 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:28:34,039 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:28:34,762 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:28:36,576 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:28:36,577 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:28:36,577 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:28:37,121 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:28:38,261 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:28:39,476 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:28:41,726 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:28:45,210 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:28:47,665 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:28:50,347 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:28:51,045 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:28:53,647 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:28:53,649 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:28:53,649 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:28:54,224 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:28:55,342 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:28:56,242 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:28:58,107 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:29:03,128 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:29:05,440 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:29:09,414 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:29:10,297 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:29:12,241 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:29:12,242 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:29:12,242 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:29:12,962 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:29:14,074 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:29:14,907 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:29:16,233 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:29:18,896 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:29:21,256 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:29:24,118 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:29:24,708 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:29:28,300 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:29:28,302 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:29:28,302 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:29:28,727 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:29:29,824 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:29:30,773 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:29:33,114 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:29:36,327 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:29:38,968 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:29:41,782 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:29:42,541 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:29:45,132 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:29:45,133 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:29:45,133 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:29:45,627 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:29:46,790 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:29:47,674 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:29:49,717 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:29:52,483 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:29:54,840 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:29:58,632 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:29:59,347 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:30:04,270 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:30:04,273 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:30:04,273 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:30:04,777 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:30:05,907 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:30:06,719 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:30:09,999 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:30:14,100 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:30:18,187 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:30:21,658 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:30:22,385 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:30:25,537 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:30:25,539 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:30:25,539 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:30:25,974 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:30:27,235 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:30:28,124 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:30:30,272 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:30:32,420 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:30:35,185 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:30:38,646 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:30:39,282 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:30:43,440 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:30:43,443 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:30:43,443 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:30:43,902 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:30:45,229 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:30:46,350 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:30:48,089 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:30:53,312 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:30:55,871 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:30:59,758 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:31:00,582 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:31:03,459 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:31:03,459 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:31:03,459 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:31:03,959 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:31:05,071 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:31:05,878 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:31:08,773 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:31:11,231 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:31:14,607 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:31:17,945 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:31:18,704 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:31:25,019 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:31:25,021 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:31:25,021 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:31:25,369 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:31:26,720 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:31:28,423 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:31:30,586 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:31:32,328 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:31:34,658 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:31:37,009 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:31:37,753 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:31:40,922 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:31:40,923 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:31:40,923 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:31:41,340 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:31:42,974 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:31:43,793 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:31:46,457 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:31:49,326 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:31:51,781 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:31:55,352 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:31:55,978 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:31:59,469 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:31:59,472 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:31:59,473 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:31:59,877 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:32:01,305 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:32:04,559 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:32:06,668 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:32:08,884 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:32:11,238 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:32:14,999 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:32:15,742 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:32:19,072 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:32:19,073 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:32:19,073 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:32:19,519 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:32:20,555 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:32:21,375 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:32:23,219 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:32:29,873 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:32:32,742 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:32:34,953 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:32:36,025 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:32:38,073 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:32:38,075 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:32:38,075 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:32:38,364 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:32:39,618 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:32:40,628 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:32:43,596 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:32:46,671 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:32:49,637 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:32:51,854 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:32:54,451 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:32:56,766 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:32:56,767 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:32:56,767 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:32:57,423 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:32:58,579 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:32:59,677 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:33:04,488 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:33:07,150 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:33:10,630 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:33:13,456 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:33:14,213 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:33:17,236 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:33:17,237 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:33:17,238 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:33:17,802 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:33:18,865 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:33:19,744 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:33:21,587 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:33:24,329 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:33:27,117 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:33:29,290 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:33:30,088 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:33:36,958 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:33:36,959 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:33:36,959 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:33:47,295 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:33:48,445 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:33:49,340 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:33:51,491 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:33:56,815 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:33:59,167 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:34:02,585 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:34:03,240 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:34:07,289 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:34:07,292 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:34:07,292 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:34:07,774 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:34:08,898 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:34:10,129 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:34:12,686 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:34:15,356 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:34:18,434 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:34:22,210 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:34:22,924 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:34:24,958 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:34:24,959 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:34:24,959 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:34:25,385 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:34:26,712 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:34:27,532 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:34:29,547 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:34:33,781 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:34:36,750 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:34:38,897 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:34:39,754 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:34:41,932 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:34:41,934 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:34:41,934 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:34:42,382 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:34:43,500 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:34:44,264 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:34:46,579 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:34:48,831 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:34:51,084 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:34:57,122 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:34:57,744 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:35:04,073 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:35:04,074 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:35:04,075 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:35:04,425 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:35:05,544 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:35:06,446 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:35:11,974 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:35:15,968 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:35:18,351 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:35:20,602 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:35:21,191 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:35:25,060 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:35:25,062 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:35:25,062 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:35:25,905 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:35:27,068 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:35:27,950 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:35:29,310 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:35:32,047 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:35:34,913 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:35:38,207 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:35:38,907 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:35:43,446 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:35:43,447 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:35:43,447 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:35:43,835 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:35:44,998 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:35:45,872 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:35:48,122 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:35:51,503 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:35:54,675 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:35:58,664 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:35:59,386 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:36:03,192 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:36:03,194 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:36:03,194 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:36:03,894 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:36:05,061 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:36:06,049 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:36:07,374 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:36:09,317 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:36:12,803 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:36:16,057 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:36:17,360 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:36:20,665 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:36:20,666 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:36:20,666 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:36:21,507 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:36:22,610 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:36:23,451 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:36:25,909 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:36:32,974 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:36:35,842 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:36:38,957 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:36:39,526 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:36:42,283 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:36:42,285 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:36:42,286 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:36:42,702 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:36:44,441 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:36:45,469 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:36:48,026 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:36:51,101 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:36:55,088 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:36:58,017 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:36:58,675 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:37:04,005 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:37:04,005 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:37:04,006 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:37:04,512 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:37:05,619 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:37:06,658 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:37:08,914 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:37:12,915 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:37:15,573 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:37:19,257 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:37:20,075 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:37:23,982 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:37:23,986 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:37:23,986 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:37:24,511 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:37:25,583 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:37:26,428 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:37:28,803 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:37:32,060 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:37:35,233 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:37:40,231 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:37:40,969 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:37:44,420 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:37:44,421 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:37:44,421 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:37:44,859 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:37:46,142 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:37:47,010 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:37:49,262 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:37:51,618 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:37:54,077 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:37:56,086 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:37:56,840 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:37:59,465 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:37:59,466 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:37:59,467 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:38:00,219 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:38:03,246 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:38:04,109 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:38:06,528 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:38:09,024 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:38:13,428 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:38:15,576 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:38:16,232 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:38:21,154 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:38:21,155 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:38:21,156 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:38:21,501 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:38:23,345 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:38:24,284 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:38:26,856 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:38:30,528 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:38:35,765 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:38:40,532 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:38:41,491 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:38:44,781 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:38:44,782 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:38:44,783 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:38:45,275 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:38:46,444 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:38:47,220 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:38:50,086 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:38:53,057 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:38:55,515 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:38:58,173 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:38:58,806 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:39:03,894 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:39:03,895 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:39:03,895 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:39:04,529 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:39:05,675 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:39:06,816 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:39:08,827 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:39:11,385 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:39:14,252 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:39:16,684 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:39:17,431 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:39:20,377 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:39:20,378 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:39:20,378 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:39:20,810 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:39:21,946 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:39:22,857 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:39:24,499 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:39:27,363 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:39:29,936 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:39:31,747 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:39:32,586 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:39:34,465 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:39:34,465 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:39:34,466 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:39:34,791 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:39:35,929 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:39:37,093 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:39:39,342 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:39:41,905 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:39:44,053 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:39:48,573 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:39:49,274 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:39:52,187 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:39:52,188 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:39:52,188 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:39:52,859 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:39:53,934 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:39:54,704 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:39:56,752 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:39:58,699 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:40:00,994 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:40:03,802 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:40:04,530 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:40:07,049 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:40:07,050 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:40:07,050 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:40:07,341 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:40:09,343 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:40:10,166 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:40:16,156 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:40:24,092 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:40:27,368 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:40:32,443 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:40:33,310 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:40:37,553 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:40:37,555 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:40:37,555 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:40:37,918 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:40:39,108 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:40:39,967 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:40:43,036 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:40:46,110 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:40:49,285 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:40:54,417 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:40:55,118 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:40:59,462 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:40:59,463 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:40:59,463 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:40:59,937 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:41:03,059 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:41:03,927 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:41:05,565 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:41:08,082 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:41:11,914 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:41:14,855 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:41:15,600 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:41:21,098 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:41:21,100 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:41:21,100 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:41:21,643 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:41:22,755 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:41:23,692 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:41:25,327 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:41:27,683 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:41:30,654 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:41:35,113 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:41:36,081 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:41:38,488 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:41:38,489 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:41:38,489 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:41:39,870 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:41:40,929 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:41:42,230 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:41:44,987 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:41:48,263 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:41:55,229 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:41:57,728 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:41:58,607 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:42:03,791 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:42:03,793 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:42:03,793 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:42:04,082 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:42:05,272 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:42:06,285 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:42:08,642 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:42:12,127 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:42:15,237 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:42:18,605 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:42:19,397 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:42:22,694 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:42:22,694 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:42:22,695 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:42:23,189 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:42:24,277 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:42:25,133 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:42:27,693 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:42:32,230 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:42:36,289 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:42:40,815 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:42:41,616 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:42:44,230 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:42:44,231 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:42:44,231 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:42:44,691 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:42:45,755 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:42:46,634 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:42:48,065 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:42:50,626 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:42:53,187 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:42:56,601 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:42:57,388 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:43:00,163 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:43:00,164 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:43:00,164 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:43:00,768 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:43:03,737 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:43:04,496 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:43:06,088 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:43:09,776 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:43:12,544 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:43:15,859 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:43:16,637 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:43:19,216 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:43:19,219 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:43:19,219 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:43:19,713 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:43:20,868 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:43:21,764 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:43:23,807 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:43:26,774 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:43:33,334 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:43:38,118 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:43:38,857 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:43:43,322 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:43:43,323 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:43:43,323 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:43:43,980 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:43:45,133 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:43:46,030 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:43:47,281 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:43:50,735 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:43:54,322 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:43:57,732 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:43:58,743 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:44:03,868 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:44:03,870 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:44:03,870 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:44:04,457 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:44:05,887 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:44:06,663 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:44:09,783 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:44:13,366 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:44:17,768 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:44:22,201 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:44:22,890 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:44:27,322 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:44:27,322 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:44:27,322 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:44:28,014 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:44:29,123 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:44:29,943 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:44:31,802 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:44:34,474 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:44:37,431 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:44:40,758 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:44:41,424 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:44:44,602 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:44:44,603 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:44:44,604 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:44:45,114 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:44:46,199 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:44:47,058 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:44:49,514 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:44:53,712 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:44:57,400 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:45:00,047 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:45:00,849 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:45:03,656 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:45:03,656 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:45:03,656 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:45:04,056 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:45:05,159 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:45:06,004 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:45:07,843 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:45:10,918 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:45:13,285 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:45:15,894 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:45:16,549 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:45:20,019 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:45:20,021 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:45:20,021 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:45:20,542 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:45:22,178 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:45:23,103 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:45:25,198 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:45:28,807 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:45:35,185 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:45:39,594 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:45:40,305 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:45:44,376 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:45:44,377 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:45:44,377 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:45:44,650 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:45:46,349 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:45:47,373 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:45:50,229 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:45:55,050 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:45:59,350 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:46:02,940 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:46:03,696 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:46:06,167 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:46:06,170 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:46:06,170 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:46:06,521 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:46:07,691 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:46:08,672 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:46:11,127 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:46:13,996 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:46:16,865 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:46:20,807 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:46:21,908 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:46:25,101 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:46:25,102 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:46:25,102 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:46:25,421 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:46:26,555 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:46:27,410 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:46:29,663 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:46:33,654 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:46:36,423 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:46:40,069 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:46:40,825 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:46:43,885 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:46:43,887 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:46:43,887 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:46:44,306 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:46:45,651 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:46:46,762 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:46:51,064 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:46:52,910 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:46:55,573 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:46:58,700 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:46:59,563 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:47:03,848 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:47:03,849 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:47:03,850 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:47:04,240 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:47:05,409 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:47:06,324 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:47:07,142 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:47:08,957 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:47:12,054 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:47:14,452 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:47:15,225 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:47:18,858 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:47:18,860 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:47:18,860 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:47:19,327 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:47:20,449 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:47:21,274 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:47:23,410 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:47:26,290 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:47:28,846 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:47:32,176 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:47:32,843 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:47:35,770 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:47:35,771 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:47:35,771 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:47:36,222 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:47:37,288 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:47:38,171 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:47:40,626 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:47:44,826 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:47:48,715 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:47:53,061 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:47:54,039 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:48:02,789 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:48:02,790 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:48:02,791 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:48:03,328 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:48:04,952 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:48:05,886 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:48:07,986 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:48:11,139 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:48:14,417 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:48:16,973 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:48:17,609 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:48:20,064 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:48:20,065 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:48:20,066 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:48:20,564 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:48:21,756 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:48:22,715 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:48:25,837 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:48:29,471 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:48:35,103 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:48:37,812 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:48:38,447 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:48:41,521 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:48:41,523 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:48:41,523 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:48:42,069 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:48:43,198 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:48:44,009 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:48:46,060 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:48:49,236 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:48:54,969 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:48:57,613 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:48:58,451 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:49:00,253 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:49:00,254 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:49:00,254 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:49:00,912 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:49:04,978 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:49:05,740 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:49:08,283 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:49:12,070 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:49:15,247 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:49:18,013 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:49:18,615 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:49:29,404 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:49:29,406 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:49:29,406 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:49:29,905 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:49:31,215 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:49:32,040 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:49:33,879 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:49:38,182 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:49:41,605 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:49:44,329 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:49:45,054 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:49:48,035 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:49:48,036 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:49:48,037 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:49:48,303 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:49:50,309 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:49:51,189 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:49:52,930 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:49:55,370 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:49:57,982 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:50:00,677 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:50:04,622 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:50:06,388 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:50:06,391 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:50:06,391 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:50:07,060 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:50:08,466 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:50:09,619 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:50:12,178 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:50:15,552 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:50:19,451 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:50:22,812 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:50:23,549 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:50:26,452 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:50:26,454 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:50:26,454 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:50:27,436 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:50:28,839 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:50:29,793 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:50:32,145 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:50:35,014 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:50:37,470 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:50:42,320 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:50:42,952 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:50:47,876 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:50:47,878 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:50:47,878 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:50:48,411 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:50:49,518 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:50:50,376 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:50:52,460 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:50:55,393 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:50:57,477 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:51:00,544 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:51:03,072 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:51:05,176 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:51:05,176 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:51:05,177 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:51:05,526 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:51:06,961 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:51:07,782 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:51:10,035 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:51:13,927 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:51:17,100 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:51:19,989 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:51:20,788 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:51:23,970 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:51:23,972 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:51:23,972 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:51:24,470 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:51:25,596 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:51:26,729 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:51:28,774 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:51:30,827 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:51:33,894 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:51:37,096 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:51:37,788 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:51:40,326 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:51:40,327 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:51:40,327 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:51:40,760 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:51:42,802 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:51:43,728 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:51:45,479 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:51:48,024 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:51:50,584 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:51:53,496 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:51:54,277 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:51:57,485 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:51:57,487 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:51:57,487 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:51:57,864 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:51:59,394 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:52:00,421 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:52:04,720 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:52:07,642 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:52:09,945 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:52:17,434 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:52:18,133 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:52:20,618 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:52:20,619 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:52:20,620 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:52:22,998 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:52:24,183 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:52:25,101 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:52:27,567 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:52:31,040 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:52:35,349 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:52:38,808 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:52:39,539 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:52:42,747 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:52:42,749 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:52:42,749 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:52:43,226 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:52:44,320 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:52:45,172 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:52:46,808 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:52:48,752 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:52:52,190 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:52:54,352 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:52:55,001 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:52:58,099 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:52:58,100 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:52:58,101 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:52:58,402 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:52:59,578 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:53:00,429 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:53:03,296 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:53:05,653 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:53:08,619 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:53:11,301 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:53:11,998 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:53:14,321 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:53:14,322 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:53:14,322 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:53:14,866 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:53:15,948 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:53:16,813 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:53:19,271 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:53:21,625 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:53:25,411 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:53:31,552 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:53:32,275 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:53:35,267 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:53:35,268 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:53:35,269 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:53:35,859 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:53:38,315 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:53:39,136 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:53:41,496 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:53:46,508 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:53:49,273 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:53:52,071 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:53:52,754 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:53:55,547 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:53:55,548 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:53:55,548 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:53:55,931 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:53:57,053 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:53:57,874 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:53:59,820 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:54:04,426 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:54:07,702 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:54:13,910 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:54:14,566 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:54:19,269 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:54:19,270 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:54:19,271 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:54:19,790 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:54:20,919 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:54:21,736 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:54:24,705 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:54:27,161 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:54:29,137 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:54:32,686 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:54:33,510 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:54:41,523 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:54:41,524 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:54:41,524 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:54:42,011 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:54:43,145 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:54:44,162 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:54:46,001 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:54:48,767 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:54:57,284 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:55:04,571 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:55:07,508 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:55:11,202 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:55:11,204 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:55:11,204 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:55:11,641 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:55:12,699 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:55:13,551 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:55:15,898 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:55:18,772 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:55:21,610 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:55:24,737 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:55:25,530 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:55:27,570 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:55:27,570 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:55:27,571 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:55:28,196 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:55:29,288 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:55:30,138 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:55:32,083 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:55:33,928 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:55:37,103 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:55:40,939 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:55:41,811 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:55:44,094 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:55:44,096 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:55:44,096 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:55:44,887 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:55:46,039 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:55:46,829 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:55:49,999 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:55:52,239 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:55:54,818 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:55:57,330 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:55:58,094 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:56:04,145 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:56:04,145 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:56:04,146 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:56:04,754 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:56:06,069 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:56:06,901 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:56:08,640 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:56:11,714 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:56:17,036 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:56:19,189 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:56:20,016 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:56:21,881 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:56:21,883 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:56:21,883 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:56:22,364 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:56:23,999 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:56:24,820 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:56:26,972 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:56:29,120 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:56:32,521 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:56:35,622 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:56:36,392 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:56:38,697 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:56:38,697 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:56:38,698 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:56:39,364 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:56:40,440 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:56:41,307 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:56:44,993 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:56:47,964 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:56:51,646 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:56:53,909 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:56:54,527 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:56:57,281 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:56:57,283 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:56:57,283 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:56:58,001 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:56:59,260 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:57:00,151 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:57:04,448 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:57:07,519 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:57:10,087 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:57:12,188 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:57:12,962 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:57:16,042 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:57:16,045 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:57:16,045 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:57:16,558 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:57:17,643 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:57:18,454 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:57:20,627 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:57:25,336 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:57:29,637 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:57:34,081 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:57:34,866 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:57:38,121 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:57:38,123 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:57:38,124 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:57:38,654 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:57:39,840 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:57:40,700 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:57:42,383 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:57:44,691 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:57:46,397 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:57:49,058 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:57:49,811 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:57:52,887 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:57:52,888 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:57:52,889 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:57:53,297 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:57:54,426 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:57:55,223 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:57:57,145 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:58:00,485 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:58:04,594 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:58:08,132 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:58:09,061 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:58:11,401 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:58:11,403 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:58:11,403 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:58:11,778 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:58:12,932 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:58:13,802 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:58:15,516 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:58:17,460 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:58:19,849 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:58:23,269 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:58:24,117 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:58:26,172 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:58:26,173 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:58:26,173 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:58:26,577 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:58:27,713 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:58:28,625 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:58:30,873 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:58:33,026 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:58:39,272 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:58:43,738 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:58:44,496 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:58:54,203 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:58:54,204 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:58:54,204 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:58:55,046 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:58:56,217 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:58:57,092 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:58:59,752 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:59:04,238 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:59:06,743 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:59:14,059 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:59:14,908 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:59:18,099 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:59:18,100 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:59:18,100 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:59:18,504 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:59:19,620 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:59:20,649 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:59:23,097 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:59:25,046 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:59:28,117 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:59:33,354 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:59:34,157 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:59:39,376 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:59:39,378 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:59:39,378 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:59:39,657 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:59:40,753 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:59:41,635 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:59:43,379 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:59:46,241 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:59:48,803 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:59:50,858 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 11:59:51,669 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:59:53,680 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 11:59:53,680 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 11:59:53,681 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 11:59:54,233 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 11:59:55,378 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 11:59:56,281 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 11:59:58,430 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:00:00,767 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:00:03,035 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:00:05,457 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:00:06,116 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:00:08,024 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:00:08,025 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:00:08,025 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:00:08,434 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:00:09,585 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:00:10,509 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:00:12,761 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:00:16,081 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:00:20,441 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:00:22,805 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:00:23,467 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:00:26,162 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:00:26,164 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:00:26,164 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:00:26,692 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:00:27,814 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:00:28,741 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:00:31,811 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:00:34,984 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:00:37,650 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:00:39,828 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:00:40,720 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:00:43,126 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:00:43,127 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:00:43,127 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:00:43,509 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:00:44,605 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:00:45,429 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:00:48,710 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:00:51,314 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:00:54,545 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:00:57,305 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:00:58,026 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:01:01,755 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:01:01,756 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:01:01,757 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:01:02,330 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:01:04,957 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:01:05,810 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:01:07,754 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:01:09,903 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:01:14,818 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:01:16,671 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:01:17,584 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:01:25,493 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:01:25,494 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:01:25,494 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:01:25,983 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:01:27,312 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:01:28,221 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:01:30,179 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:01:33,252 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:01:37,248 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:01:39,960 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:01:43,490 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:01:48,448 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:01:48,450 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:01:48,450 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:01:49,331 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:01:50,368 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:01:51,172 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:01:53,432 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:01:59,055 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:02:04,482 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:02:08,974 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:02:09,641 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:02:13,294 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:02:13,295 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:02:13,295 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:02:13,904 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:02:15,438 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:02:16,307 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:02:18,922 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:02:23,017 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:02:28,135 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:02:31,117 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:02:31,822 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:02:36,247 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:02:36,249 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:02:36,250 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:02:36,591 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:02:37,769 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:02:38,584 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:02:40,490 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:02:44,728 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:02:48,617 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:02:51,121 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:02:51,794 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:02:54,694 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:02:54,694 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:02:54,695 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:02:55,174 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:02:56,285 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:02:57,117 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:02:59,065 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:03:03,466 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:03:06,027 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:03:09,320 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:03:10,019 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:03:13,304 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:03:13,306 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:03:13,306 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:03:13,811 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:03:15,142 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:03:16,063 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:03:18,221 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:03:21,288 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:03:24,867 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:03:30,430 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:03:31,113 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:03:33,419 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:03:33,420 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:03:33,420 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:03:33,985 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:03:35,291 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:03:36,303 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:03:39,103 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:03:42,073 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:03:45,347 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:03:49,199 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:03:50,062 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:03:53,395 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:03:53,396 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:03:53,397 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:03:54,055 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:03:55,484 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:03:56,307 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:03:58,456 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:04:04,189 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:04:09,206 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:04:12,071 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:04:12,690 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:04:18,825 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:04:18,827 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:04:18,827 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:04:22,217 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:04:23,300 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:04:24,223 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:04:25,746 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:04:29,176 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:04:31,940 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:04:34,501 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:04:35,116 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:04:43,084 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:04:43,086 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:04:43,086 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:04:43,925 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:04:45,076 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:04:45,970 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:04:48,227 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:04:50,582 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:04:58,259 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:05:00,240 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:05:01,044 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:05:05,755 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:05:05,756 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:05:05,757 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:05:06,257 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:05:07,289 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:05:08,190 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:05:09,730 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:05:12,410 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:05:14,642 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:05:18,543 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:05:20,069 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:05:25,382 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:05:25,384 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:05:25,384 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:05:25,749 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:05:28,055 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:05:28,982 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:05:31,333 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:05:33,685 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:05:36,658 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:05:40,361 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:05:41,061 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:05:43,821 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:05:43,822 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:05:43,822 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:05:44,223 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:05:45,316 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:05:46,389 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:05:48,535 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:05:52,452 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:05:55,704 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:05:59,839 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:06:00,616 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:06:03,653 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:06:03,656 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:06:03,656 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:06:04,103 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:06:05,944 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:06:06,764 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:06:09,526 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:06:12,497 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:06:15,671 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:06:21,398 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:06:22,228 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:06:26,179 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:06:26,181 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:06:26,181 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:06:26,629 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:06:27,862 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:06:28,676 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:06:30,603 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:06:33,494 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:06:35,765 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:06:39,700 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:06:40,851 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:06:43,396 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:06:43,398 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:06:43,398 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:06:43,836 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:06:45,161 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:06:46,086 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:06:50,900 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:06:53,046 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:06:56,426 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:06:59,639 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:07:00,421 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:07:04,500 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:07:04,501 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:07:04,501 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:07:04,926 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:07:06,581 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:07:07,318 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:07:09,310 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:07:13,018 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:07:18,658 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:07:22,442 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:07:23,127 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:07:27,260 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:07:27,262 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:07:27,262 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:07:27,760 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:07:28,907 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:07:30,369 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:07:32,220 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:07:38,633 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:07:43,235 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:07:48,426 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:07:49,220 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:07:54,405 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:07:54,406 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:07:54,407 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:07:55,003 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:07:56,176 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:08:01,492 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:08:06,389 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:08:10,030 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:08:15,511 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:08:20,182 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:08:20,806 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:08:24,710 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:08:24,712 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:08:24,712 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:08:25,181 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:08:26,948 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:08:27,876 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:08:31,046 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:08:35,041 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:08:50,231 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:08:55,721 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:08:56,476 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:09:02,569 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:09:02,571 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:09:02,571 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:09:03,203 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:09:04,944 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:09:05,763 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:09:07,759 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:09:11,060 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:09:14,146 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:09:18,843 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:09:19,517 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:09:22,834 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:09:22,836 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:09:22,836 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:09:23,312 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:09:24,516 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:09:25,382 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:09:26,979 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:09:31,054 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:09:34,332 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:09:38,123 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:09:38,764 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:09:42,450 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:09:42,451 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:09:42,451 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:09:42,804 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:09:43,953 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:09:45,018 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:09:46,550 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:09:48,903 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:09:51,905 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:09:54,741 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:09:55,576 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:10:04,003 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:10:04,004 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:10:04,004 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:10:04,539 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:10:05,687 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:10:06,446 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:10:08,238 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:10:11,604 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:10:14,878 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:10:16,629 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:10:17,338 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:10:19,780 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:10:19,782 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:10:19,782 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:10:20,358 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:10:23,789 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:10:24,709 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:10:26,186 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:10:30,649 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:10:35,358 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:10:38,273 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:10:38,881 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:10:42,422 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:10:42,423 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:10:42,424 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:10:42,940 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:10:44,022 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:10:44,985 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:10:47,608 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:10:50,057 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:10:52,126 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:10:57,969 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:10:58,641 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:11:03,765 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:11:03,767 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:11:03,767 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:11:04,162 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:11:05,271 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:11:06,192 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:11:08,025 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:11:10,600 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:11:14,530 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:11:19,840 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:11:20,557 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:11:22,678 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:11:22,678 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:11:22,679 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:11:23,389 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:11:24,560 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:11:25,433 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:11:28,094 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:11:31,841 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:11:38,098 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:11:43,481 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:11:44,279 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:11:48,181 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:11:48,183 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:11:48,183 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:11:48,555 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:11:49,652 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:11:50,459 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:11:52,980 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:11:55,540 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:11:58,818 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:12:03,684 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:12:04,656 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:12:06,665 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:12:06,665 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:12:06,665 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:12:07,244 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:12:08,344 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:12:09,263 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:12:11,051 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:12:14,689 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:12:19,046 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:12:25,492 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:12:26,365 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:12:32,353 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:12:32,355 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:12:32,356 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:12:32,924 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:12:34,473 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:12:35,376 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:12:38,585 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:12:41,929 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:12:45,919 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:12:48,868 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:12:49,587 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:12:52,460 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:12:52,461 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:12:52,461 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:12:52,991 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:12:54,387 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:12:55,243 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:12:58,416 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:13:03,227 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:13:06,744 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:13:14,638 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:13:15,412 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:13:23,314 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:13:23,316 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:13:23,316 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:13:23,910 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:13:25,757 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:13:26,783 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:13:30,779 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:13:33,949 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:13:36,509 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:13:38,971 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:13:40,228 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:13:44,658 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:13:44,659 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:13:44,659 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:13:45,112 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:13:46,439 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:13:47,463 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:13:49,409 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:13:54,699 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:13:57,910 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:14:02,807 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:14:03,504 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:14:06,768 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:14:06,770 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:14:06,770 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:14:07,137 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:14:08,274 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:14:09,276 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:14:11,737 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:14:15,319 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:14:19,292 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:14:23,559 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:14:24,225 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:14:32,135 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:14:32,136 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:14:32,137 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:14:32,416 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:14:33,543 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:14:34,463 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:14:36,208 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:14:38,672 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:14:43,744 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:14:45,475 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:14:46,243 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:14:48,282 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:14:48,284 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:14:48,284 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:14:48,698 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:14:50,968 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:14:51,781 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:14:54,144 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:14:56,585 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:15:00,953 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:15:03,714 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:15:04,576 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:15:06,675 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:15:06,676 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:15:06,676 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:15:07,098 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:15:08,500 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:15:09,484 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:15:11,228 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:15:12,580 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:15:14,812 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:15:17,105 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:15:17,884 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:15:23,757 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:15:23,759 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:15:23,759 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:15:24,241 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:15:26,226 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:15:26,999 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:15:28,927 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:15:32,528 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:15:35,445 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:15:46,468 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:15:47,171 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:15:58,546 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:15:58,548 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:15:58,549 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:15:59,043 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:16:00,250 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:16:01,103 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:16:03,410 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:16:07,771 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:16:10,006 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:16:14,858 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:16:15,532 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:16:23,462 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:16:23,463 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:16:23,464 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:16:23,996 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:16:27,131 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:16:27,872 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:16:29,256 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:16:32,315 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:16:35,112 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:16:38,030 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:16:38,885 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:16:43,895 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:16:43,897 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:16:43,897 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:16:44,517 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:16:46,131 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:16:46,980 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:16:49,063 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:16:52,473 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:16:55,042 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:16:58,754 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:16:59,637 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:17:04,041 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:17:04,043 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:17:04,043 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:17:04,481 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:17:05,723 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:17:06,676 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:17:09,602 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:17:14,292 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:17:21,288 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:17:23,840 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:17:24,460 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:17:27,002 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:17:27,003 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:17:27,003 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:17:27,319 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:17:28,852 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:17:29,755 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:17:31,732 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:17:34,482 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:17:37,868 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:17:39,956 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:17:40,575 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:17:43,607 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:17:43,608 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:17:43,608 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:17:44,039 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:17:45,258 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:17:46,053 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:17:47,589 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:17:49,638 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:17:53,222 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:17:55,086 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:17:55,784 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:17:57,583 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:17:57,586 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:17:57,586 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:17:57,975 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:17:59,144 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:18:00,192 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:18:10,987 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:18:14,526 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:18:16,886 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:18:20,548 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:18:22,916 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:18:25,344 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:18:25,344 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:18:25,344 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:18:25,805 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:18:26,955 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:18:27,958 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:18:30,006 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:18:33,388 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:18:37,382 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:18:39,631 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:18:40,353 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:18:42,967 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:18:42,968 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:18:42,969 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:18:43,738 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:18:45,048 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:18:45,886 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:18:47,420 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:18:52,337 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:18:56,023 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:18:59,260 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:19:00,138 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:19:04,067 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:19:04,070 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:19:04,070 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:19:04,656 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:19:05,861 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:19:06,615 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:19:08,217 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:19:10,768 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:19:14,451 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:19:17,124 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:19:17,843 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:19:22,412 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:19:22,414 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:19:22,414 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:19:22,874 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:19:24,600 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:19:25,414 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:19:27,152 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:19:32,271 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:19:36,575 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:19:39,677 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:19:40,331 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:19:42,472 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:19:42,474 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:19:42,475 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:19:42,887 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:19:43,969 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:19:44,871 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:19:46,916 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:19:49,887 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:19:53,598 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:19:56,224 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:19:56,851 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:20:03,602 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:20:03,605 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:20:03,605 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:20:04,123 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:20:05,288 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:20:06,371 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:20:08,219 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:20:10,880 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:20:14,460 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:20:17,135 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:20:17,952 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:20:23,291 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:20:23,293 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:20:23,293 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:20:24,606 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:20:25,740 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:20:26,651 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:20:29,106 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:20:33,202 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:20:36,172 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:20:39,904 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:20:40,654 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:20:44,348 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:20:44,351 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:20:44,351 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:20:44,881 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:20:45,991 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:20:47,102 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:20:49,385 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:20:51,533 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:20:54,984 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:20:57,790 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:20:58,498 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:21:02,827 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:21:02,828 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:21:02,829 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:21:03,212 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:21:04,338 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:21:05,964 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:21:08,624 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:21:22,481 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:21:26,660 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:21:29,648 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:21:30,341 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:21:33,829 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:21:33,833 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:21:33,833 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:21:34,245 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:21:35,359 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:21:36,179 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:21:38,688 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:21:42,055 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:21:44,885 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:21:46,667 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:21:47,306 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:21:50,978 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:21:50,979 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:21:50,979 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:21:51,446 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:21:52,624 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:21:53,580 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:21:55,021 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:21:56,968 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:22:00,038 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:22:03,783 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:22:04,439 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:22:07,382 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:22:07,384 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:22:07,384 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:22:07,825 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:22:08,958 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:22:09,767 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:22:16,937 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:22:23,592 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:22:26,770 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:22:29,797 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:22:30,657 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:22:33,527 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:22:33,528 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:22:33,529 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:22:33,937 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:22:35,028 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:22:35,888 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:22:37,419 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:22:40,386 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:22:42,409 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:22:45,468 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:22:46,123 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:22:50,309 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:22:50,312 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:22:50,312 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:22:50,728 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:22:52,022 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:22:53,186 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:22:54,928 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:22:56,873 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:22:58,600 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:23:02,531 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:23:03,734 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:23:05,614 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:23:05,614 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:23:05,615 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:23:05,986 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:23:07,193 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:23:08,036 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:23:09,265 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:23:11,620 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:23:14,897 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:23:18,108 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:23:18,781 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:23:23,210 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:23:23,211 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:23:23,212 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:23:23,627 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:23:24,928 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:23:25,725 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:23:27,189 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:23:29,740 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:23:34,657 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:23:38,576 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:23:39,185 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:23:42,043 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:23:42,044 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:23:42,044 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:23:42,418 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:23:43,592 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:23:44,351 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:23:46,915 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:23:49,929 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:23:54,320 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:23:58,159 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:23:58,927 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:24:03,789 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:24:03,791 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:24:03,791 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:24:04,194 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:24:05,320 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:24:06,097 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:24:10,603 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:24:13,984 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:24:17,490 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:24:19,762 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:24:21,320 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:24:23,224 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:24:23,225 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:24:23,225 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:24:23,507 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:24:24,662 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:24:25,532 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:24:27,332 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:24:31,286 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:24:39,581 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:24:41,561 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:24:42,201 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:24:46,694 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:24:46,696 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:24:46,696 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:24:46,992 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:24:48,149 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:24:49,104 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:24:50,966 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:24:54,029 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:24:56,071 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:24:59,561 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:25:00,285 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:25:03,484 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:25:03,485 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:25:03,486 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:25:03,957 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:25:05,061 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:25:05,902 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:25:08,639 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:25:12,047 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:25:15,012 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:25:17,285 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:25:17,870 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:25:23,333 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:25:23,335 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:25:23,335 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:25:23,784 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:25:25,014 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:25:25,872 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:25:28,249 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:25:31,807 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:25:35,394 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:25:41,289 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:25:42,044 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:25:47,380 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:25:47,381 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:25:47,381 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:25:47,691 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:25:49,545 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:25:51,447 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:25:52,901 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:25:54,755 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:25:59,971 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:26:02,685 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:26:03,452 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:26:06,054 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:26:06,056 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:26:06,056 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:26:06,331 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:26:07,539 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:26:08,373 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:26:10,620 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:26:14,308 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:26:16,964 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:26:19,964 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:26:23,066 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:26:26,188 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:26:26,188 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:26:26,189 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:26:26,592 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:26:27,684 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:26:28,433 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:26:29,973 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:26:32,432 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:26:34,377 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:26:36,299 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:26:37,037 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:26:39,213 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:26:39,214 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:26:39,215 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:26:39,698 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:26:41,026 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:26:41,854 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:26:43,285 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:26:46,869 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:26:49,056 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:26:51,543 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:26:52,196 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:26:54,745 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:26:54,746 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:26:54,746 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:26:55,263 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:26:56,320 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:26:57,211 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:26:58,336 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:27:00,587 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:27:04,069 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:27:06,613 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:27:07,349 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:27:13,438 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:27:13,440 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:27:13,440 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:27:14,011 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:27:15,200 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:27:16,055 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:27:17,687 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:27:20,305 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:27:23,320 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:27:26,289 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:27:27,112 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:27:30,400 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:27:30,400 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:27:30,401 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:27:30,867 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:27:31,998 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:27:32,849 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:27:35,714 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:27:40,525 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:27:43,264 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:27:46,414 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:27:47,183 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:27:49,739 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:27:49,741 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:27:49,741 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:27:50,147 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:27:51,659 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:27:52,500 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:27:56,194 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:27:59,366 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:28:03,728 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:28:07,391 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:28:08,173 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:28:09,700 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:28:09,701 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:28:09,701 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:28:10,009 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:28:11,659 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:28:12,415 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:28:14,011 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:28:16,878 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:28:22,285 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:28:23,218 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:28:25,071 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:28:27,087 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:28:27,089 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:28:27,089 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:28:27,472 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:28:28,579 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:28:29,345 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:28:31,506 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:28:33,879 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:28:36,336 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:28:40,166 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:28:40,942 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:28:43,454 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:28:43,455 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:28:43,456 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:28:44,121 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:28:45,687 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:28:46,577 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:28:49,239 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:28:52,897 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:28:55,280 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:28:58,278 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:28:59,066 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:29:03,882 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:29:03,885 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:29:03,885 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:29:04,174 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:29:05,314 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:29:06,052 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:29:07,466 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:29:10,639 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:29:13,325 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:29:20,069 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:29:22,429 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:29:25,728 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:29:25,729 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:29:25,729 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:29:26,117 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:29:27,436 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:29:28,252 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:29:29,913 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:29:32,347 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:29:36,755 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:29:38,926 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:29:40,028 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:29:42,698 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:29:42,700 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:29:42,700 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:29:43,203 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:29:44,269 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:29:45,106 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:29:46,586 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:29:48,573 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:29:52,322 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:29:54,428 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:29:55,183 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:29:58,167 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:29:58,168 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:29:58,168 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:29:58,667 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:29:59,830 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:30:00,754 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:30:04,297 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:30:06,912 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:30:10,250 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:30:12,553 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:30:13,109 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:30:17,341 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:30:17,343 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:30:17,343 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:30:17,920 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:30:19,020 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:30:19,910 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:30:24,475 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:30:27,233 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:30:31,537 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:30:34,450 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:30:35,328 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:30:42,648 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:30:42,649 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:30:42,649 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:30:43,522 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:30:44,700 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:30:45,569 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:30:47,865 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:30:50,949 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:30:54,167 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:30:58,537 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:30:59,184 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:31:03,183 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:31:03,185 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:31:03,185 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:31:03,590 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:31:04,710 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:31:05,639 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:31:07,837 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:31:10,449 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:31:13,520 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:31:16,942 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:31:17,926 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:31:20,610 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:31:20,611 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:31:20,611 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:31:21,074 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:31:24,523 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:31:25,504 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:31:27,448 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:31:29,635 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:31:33,900 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:31:36,704 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:31:37,346 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:31:41,366 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:31:41,367 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:31:41,368 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:31:41,642 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:31:42,719 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:31:43,525 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:31:45,164 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:31:47,107 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:31:52,434 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:31:53,693 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:31:54,486 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:31:57,690 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:31:57,691 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:31:57,692 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:31:58,170 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:31:59,303 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:32:00,324 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:32:04,415 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:32:06,974 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:32:11,687 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:32:16,534 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:32:17,319 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:32:20,284 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:32:20,286 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:32:20,287 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:32:20,741 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:32:24,092 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:32:24,996 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:32:27,865 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:32:30,428 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:32:33,206 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:32:39,002 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:32:39,640 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:32:45,062 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:32:45,063 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:32:45,063 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:32:45,347 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:32:46,705 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:32:47,630 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:32:49,684 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:32:52,950 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:32:56,537 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:32:59,463 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:33:00,160 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:33:03,089 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:33:03,091 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:33:03,091 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:33:03,396 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:33:04,638 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:33:05,597 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:33:07,798 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:33:09,655 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:33:12,206 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:33:15,272 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:33:15,991 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:33:20,384 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:33:20,385 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:33:20,385 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:33:20,783 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:33:24,291 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:33:25,210 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:33:26,748 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:33:30,023 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:33:32,992 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:33:34,559 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:33:35,251 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:33:38,908 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:33:38,909 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:33:38,909 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:33:39,320 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:33:40,488 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:33:41,391 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:33:43,129 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:33:46,076 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:33:48,149 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:33:51,946 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:33:52,757 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:33:56,087 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:33:56,089 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:33:56,089 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:33:56,650 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:33:57,755 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:33:58,595 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:34:00,543 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:34:03,630 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:34:07,344 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:34:09,415 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:34:10,096 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:34:13,465 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:34:13,465 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:34:13,466 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:34:13,857 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:34:14,930 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:34:15,694 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:34:17,209 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:34:18,984 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:34:23,466 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:34:27,417 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:34:28,085 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:34:30,476 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:34:30,478 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:34:30,479 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:34:31,305 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:34:32,589 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:34:33,470 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:34:37,814 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:34:41,295 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:34:44,265 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:34:47,300 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:34:48,408 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:34:51,119 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:34:51,120 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:34:51,120 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:34:51,740 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:34:52,900 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:34:53,692 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:34:55,632 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:34:57,472 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:34:59,852 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:35:03,772 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:35:04,642 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:35:06,948 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:35:06,950 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:35:06,950 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:35:07,407 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:35:08,733 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:35:09,509 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:35:11,718 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:35:13,473 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:35:16,931 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:35:19,464 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:35:20,196 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:35:24,690 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:35:24,691 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:35:24,691 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:35:25,187 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:35:26,344 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:35:27,080 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:35:29,227 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:35:31,680 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:35:34,593 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:35:37,749 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:35:38,435 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:35:40,698 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:35:40,700 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:35:40,700 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:35:41,202 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:35:42,334 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:35:43,151 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:35:44,787 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:35:50,710 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:35:52,871 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:35:55,687 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:35:56,285 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:35:59,574 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:35:59,575 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:35:59,575 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:36:00,149 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:36:04,359 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:36:05,777 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:36:07,321 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:36:09,971 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:36:14,479 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:36:18,119 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:36:18,747 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:36:23,506 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:36:23,508 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:36:23,508 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:36:23,868 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:36:25,228 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:36:26,053 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:36:27,382 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:36:29,841 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:36:32,706 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:36:34,807 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:36:35,473 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:36:38,361 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:36:38,362 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:36:38,362 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:36:38,800 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:36:39,921 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:36:41,004 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:36:43,050 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:36:46,239 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:36:48,255 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:36:51,078 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:36:51,853 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:36:53,360 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:36:53,361 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:36:53,361 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:36:53,691 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:36:54,809 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:36:55,648 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:36:57,079 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:37:03,326 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:37:06,705 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:37:08,996 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:37:10,775 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:37:12,267 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:37:12,268 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:37:12,269 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:37:12,551 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:37:13,708 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:37:14,472 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:37:17,151 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:37:24,244 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:37:27,288 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:37:31,539 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:37:32,306 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:37:34,745 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:37:34,746 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:37:34,746 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:37:35,483 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:37:36,622 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:37:37,472 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:37:39,166 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:37:41,620 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:37:44,187 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:37:47,633 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:37:48,489 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:37:50,969 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:37:50,970 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:37:50,970 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:37:51,262 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:37:52,305 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:37:53,091 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:37:54,732 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:37:56,891 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:37:59,031 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:38:02,713 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:38:03,270 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:38:06,195 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:38:06,196 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:38:06,196 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:38:06,515 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:38:08,352 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:38:09,169 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:38:10,709 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:38:12,057 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:38:13,983 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:38:15,647 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:38:16,338 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:38:19,781 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:38:19,782 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:38:19,782 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:38:20,216 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:38:26,781 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:38:28,014 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:38:30,058 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:38:33,865 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:38:38,152 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:38:42,829 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:38:43,576 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:38:45,397 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:38:45,398 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:38:45,398 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:38:45,834 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:38:46,892 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:38:47,776 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:38:49,517 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:38:53,201 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:38:55,769 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:39:03,614 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:39:04,260 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:39:06,502 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:39:06,503 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:39:06,504 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:39:06,924 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:39:08,402 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:39:09,280 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:39:11,841 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:39:13,851 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:39:16,450 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:39:18,556 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:39:19,260 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:39:22,632 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:39:22,633 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:39:22,633 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:39:23,041 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:39:24,158 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:39:24,950 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:39:27,202 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:39:28,979 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:39:31,299 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:39:34,650 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:39:35,207 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:39:38,493 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:39:38,494 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:39:38,494 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:39:39,078 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:39:40,228 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:39:41,128 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:39:43,483 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:39:46,144 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:39:48,296 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:39:51,145 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:39:51,879 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:39:54,926 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:39:54,928 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:39:54,928 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:39:55,256 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:39:56,656 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:39:57,557 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:39:59,708 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:40:04,476 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:40:07,956 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:40:11,389 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:40:12,053 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:40:15,755 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:40:15,755 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:40:15,756 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:40:16,078 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:40:18,586 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:40:19,818 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:40:24,052 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:40:28,129 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:40:30,690 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:40:33,948 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:40:34,685 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:40:38,682 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:40:38,684 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:40:38,684 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:40:39,089 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:40:40,240 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:40:41,137 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:40:43,679 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:40:46,828 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:40:51,477 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:40:55,045 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:40:55,778 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:41:03,837 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:41:03,838 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:41:03,838 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:41:04,484 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:41:05,578 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:41:06,428 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:41:08,783 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:41:11,958 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:41:14,476 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:41:17,775 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:41:18,550 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:41:22,496 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:41:22,498 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:41:22,498 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:41:22,905 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:41:24,078 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:41:25,171 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:41:27,829 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:41:31,207 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:41:35,102 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:41:38,650 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:41:39,403 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:41:43,532 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:41:43,533 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:41:43,533 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:41:43,980 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:41:45,159 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:41:46,058 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:41:48,624 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:41:51,792 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:41:54,962 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:41:57,961 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:41:58,659 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:42:03,781 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:42:03,782 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:42:03,783 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:42:04,289 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:42:05,923 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:42:06,847 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:42:09,465 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:42:12,068 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:42:14,528 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:42:18,768 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:42:19,495 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:42:23,167 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:42:23,168 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:42:23,168 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:42:23,523 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:42:25,265 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:42:26,094 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:42:27,734 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:42:30,294 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:42:32,751 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:42:38,886 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:42:39,484 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:42:42,741 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:42:42,743 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:42:42,743 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:42:43,297 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:42:44,352 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:42:46,169 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:42:48,729 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:42:52,411 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:42:55,074 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:42:58,110 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:42:58,868 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:43:03,106 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:43:03,107 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:43:03,107 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:43:03,438 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:43:04,531 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:43:05,424 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:43:07,673 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:43:11,563 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:43:15,253 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:43:18,666 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:43:19,646 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:43:24,420 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:43:24,423 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:43:24,424 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:43:24,980 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:43:26,163 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:43:27,131 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:43:29,174 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:43:33,478 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:43:36,757 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:43:40,303 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:43:40,957 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:43:44,754 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:43:44,755 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:43:44,755 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:43:45,367 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:43:46,550 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:43:47,354 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:43:49,766 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:43:52,021 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:43:55,811 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:44:05,647 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:44:06,339 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:44:10,750 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:44:10,752 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:44:10,752 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:44:11,148 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:44:12,294 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:44:13,223 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:44:16,086 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:44:19,862 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:44:23,048 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:44:28,265 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:44:28,991 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:44:32,906 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:44:32,907 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:44:32,907 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:44:33,403 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:44:34,531 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:44:35,931 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:44:37,774 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:44:41,013 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:44:45,700 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:44:48,956 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:44:49,779 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:44:52,971 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:44:52,973 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:44:52,973 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:44:53,309 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:44:54,343 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:44:55,142 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:44:57,535 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:45:00,385 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:45:04,325 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:45:06,756 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:45:07,421 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:45:10,149 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:45:10,150 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:45:10,150 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:45:10,568 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:45:11,999 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:45:12,923 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:45:14,767 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:45:17,941 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:45:20,696 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:45:23,343 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:45:24,084 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:45:26,863 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:45:26,865 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:45:26,865 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:45:27,362 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:45:29,304 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:45:30,639 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:45:32,173 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:45:35,346 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:45:40,981 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:45:42,727 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:45:43,441 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:45:46,078 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:45:46,079 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:45:46,079 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:45:46,513 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:45:47,614 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:45:48,459 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:45:50,303 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:45:52,503 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:45:55,732 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:45:58,414 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:45:59,122 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:46:02,904 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:46:02,905 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:46:02,906 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:46:03,511 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:46:04,601 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:46:05,419 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:46:07,422 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:46:09,730 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:46:13,033 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:46:15,742 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:46:16,438 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:46:18,805 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:46:18,806 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:46:18,806 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:46:19,226 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:46:20,534 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:46:23,987 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:46:25,935 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:46:30,847 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:46:33,717 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:46:38,108 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:46:38,836 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:46:42,261 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:46:42,263 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:46:42,263 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:46:42,832 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:46:43,982 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:46:44,780 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:46:46,925 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:46:50,002 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:46:52,251 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:46:54,761 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:46:55,426 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:46:58,271 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:46:58,272 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:46:58,273 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:46:58,689 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:46:59,886 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:47:00,755 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:47:04,336 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:47:06,696 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:47:08,940 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:47:11,680 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:47:12,321 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:47:14,996 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:47:14,998 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:47:14,998 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:47:15,340 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:47:16,501 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:47:17,339 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:47:19,963 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:47:23,585 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:47:26,455 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:47:29,523 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:47:30,348 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:47:32,562 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:47:32,563 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:47:32,563 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:47:33,336 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:47:35,437 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:47:36,901 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:47:39,052 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:47:42,642 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:47:46,113 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:47:48,583 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:47:49,316 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:47:51,422 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:47:51,425 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:47:51,425 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:47:51,793 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:47:52,959 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:47:53,898 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:47:55,382 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:47:57,482 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:48:01,146 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:48:03,803 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:48:04,441 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:48:08,879 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:48:08,880 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:48:08,880 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:48:09,568 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:48:10,791 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:48:11,820 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:48:15,709 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:48:18,969 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:48:23,561 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:48:25,967 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:48:26,667 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:48:29,575 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:48:29,577 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:48:29,577 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:48:29,880 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:48:31,014 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:48:31,787 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:48:34,141 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:48:37,318 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:48:40,492 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:48:43,852 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:48:44,788 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:48:47,198 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:48:47,199 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:48:47,199 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:48:47,661 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:48:48,887 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:48:49,627 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:48:51,448 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:48:53,919 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:48:56,672 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:48:59,813 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:49:00,665 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:49:04,344 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:49:04,346 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:49:04,346 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:49:04,762 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:49:06,195 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:49:06,994 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:49:08,900 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:49:12,441 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:49:16,945 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:49:20,084 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:49:23,634 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:49:26,046 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:49:26,047 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:49:26,047 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:49:26,690 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:49:28,619 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:49:29,441 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:49:30,870 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:49:33,570 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:49:36,955 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:49:39,612 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:49:40,294 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:49:44,480 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:49:44,481 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:49:44,482 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:49:44,902 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:49:46,642 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:49:47,570 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:49:49,817 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:49:52,480 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:49:54,955 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:49:58,916 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:49:59,751 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:50:02,711 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:50:02,712 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:50:02,712 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:50:03,055 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:50:04,161 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:50:05,074 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:50:06,551 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:50:09,787 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:50:12,348 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:50:14,992 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:50:15,726 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:50:19,214 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:50:19,215 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:50:19,215 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:50:19,673 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:50:23,726 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:50:24,496 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:50:26,681 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:50:29,734 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:50:34,671 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:50:38,751 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:50:39,380 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:50:42,626 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:50:42,627 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:50:42,627 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:50:42,957 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:50:44,445 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:50:45,213 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:50:47,160 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:50:50,650 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:50:54,641 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:50:57,993 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:50:58,735 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:51:05,201 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:51:05,202 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:51:05,203 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:51:05,702 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:51:07,027 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:51:07,824 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:51:10,303 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:51:13,174 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:51:15,942 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:51:19,085 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:51:19,818 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:51:23,587 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:51:23,588 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:51:23,588 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:51:24,339 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:51:25,493 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:51:26,384 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:51:28,531 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:51:33,552 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:51:36,520 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:51:41,078 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:51:41,743 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:51:44,502 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:51:44,503 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:51:44,504 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:51:44,789 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:51:46,556 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:51:47,370 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:51:49,718 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:51:52,700 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:51:57,207 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:52:00,695 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:52:03,860 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:52:09,950 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:52:09,951 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:52:09,951 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:52:13,391 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:52:14,516 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:52:15,451 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:52:17,891 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:52:20,024 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:52:24,140 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:52:26,469 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:52:27,314 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:52:29,380 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:52:29,381 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:52:29,381 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:52:29,643 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:52:30,812 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:52:31,715 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:52:34,582 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:52:37,756 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:52:40,623 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:52:44,733 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:52:45,438 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:52:51,313 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:52:51,314 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:52:51,314 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:52:51,657 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:52:52,899 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:52:53,741 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:52:55,472 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:52:57,780 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:53:01,003 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:53:04,466 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:53:05,201 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:53:08,333 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:53:08,335 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:53:08,335 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:53:08,771 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:53:09,850 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:53:10,734 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:53:13,394 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:53:16,465 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:53:19,794 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:53:23,416 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:53:24,144 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:53:27,655 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:53:27,656 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:53:27,657 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:53:28,141 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:53:29,251 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:53:30,026 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:53:33,464 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:53:36,428 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:53:39,092 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:53:42,454 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:53:43,191 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:53:45,690 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:53:45,692 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:53:45,693 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:53:46,163 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:53:47,390 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:53:48,826 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:53:51,794 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:53:54,663 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:54:00,090 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:54:04,051 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:54:04,900 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:54:07,717 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:54:07,718 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:54:07,718 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:54:08,045 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:54:09,171 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:54:09,962 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:54:12,070 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:54:14,731 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:54:17,909 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:54:23,615 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:54:24,254 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:54:28,559 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:54:28,560 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:54:28,561 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:54:29,070 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:54:30,185 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:54:31,220 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:54:33,264 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:54:36,336 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:54:39,926 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:54:45,049 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:54:45,756 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:54:52,351 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:54:52,352 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:54:52,353 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:54:52,931 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:54:54,008 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:54:54,883 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:54:58,867 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:55:04,808 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:55:07,775 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:55:13,273 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:55:14,158 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:55:16,298 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:55:16,299 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:55:16,300 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:55:16,793 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:55:19,541 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:55:20,377 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:55:24,106 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:55:28,459 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:55:32,659 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:55:41,455 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:55:42,078 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:55:46,466 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:55:46,467 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:55:46,468 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:55:47,006 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:55:48,165 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:55:49,667 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:56:01,638 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:56:06,554 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:56:09,936 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:56:13,981 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:56:14,648 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:56:19,519 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:56:19,522 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:56:19,522 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:56:19,910 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:56:21,098 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:56:22,011 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:56:24,372 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:56:29,287 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:56:31,949 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:56:35,534 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:56:36,106 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:56:40,879 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:56:40,880 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:56:40,880 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:56:41,420 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:56:42,535 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:56:43,317 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:56:48,541 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:56:52,945 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:56:56,427 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:56:59,589 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:57:00,419 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:57:05,739 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:57:05,740 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:57:05,740 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:57:06,208 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:57:07,400 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:57:08,305 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:57:11,068 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:57:14,758 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:57:18,471 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:57:23,286 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:57:24,101 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:57:28,064 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:57:28,064 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:57:28,064 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:57:28,554 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:57:32,229 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:57:32,977 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:57:34,378 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:57:39,618 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:57:44,657 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:57:46,760 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:57:47,525 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:57:51,819 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:57:51,821 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:57:51,821 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:57:52,282 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:57:53,525 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:57:54,272 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:57:57,251 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:58:03,601 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:58:20,654 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:58:24,687 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:58:25,515 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:58:29,332 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:58:29,333 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:58:29,333 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:58:29,820 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:58:30,980 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:58:32,265 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:58:35,142 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:58:37,596 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:58:41,697 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:58:44,189 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:58:46,405 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:58:49,497 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:58:49,499 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:58:49,499 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:58:49,893 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:58:54,117 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:58:54,906 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:58:59,926 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:59:01,662 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:59:04,828 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:59:07,294 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:59:07,954 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:59:11,315 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:59:11,316 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:59:11,316 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:59:11,668 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:59:12,825 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:59:13,750 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:59:17,334 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:59:20,107 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:59:23,575 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:59:28,343 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:59:29,104 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:59:31,406 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 12:59:31,407 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 12:59:31,407 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 12:59:32,078 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 12:59:35,104 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 12:59:35,972 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:59:41,727 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:59:47,745 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:59:52,511 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 12:59:56,218 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 12:59:56,961 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:00:01,624 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:00:01,626 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:00:01,626 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:00:02,027 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:00:03,223 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:00:04,233 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:00:07,095 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:00:11,535 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:00:15,912 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:00:19,449 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:00:20,205 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:00:28,217 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:00:28,218 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:00:28,219 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:00:28,709 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:00:29,926 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:00:30,752 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:00:36,281 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:00:40,789 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:00:47,000 - opentelemetry.exporter.otlp.proto.http.trace_exporter - WARNING - Transient error Service Unavailable encountered while exporting span batch, retrying in 1s.
2025-01-02 13:00:49,085 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:00:53,245 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:00:53,998 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:00:59,563 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:00:59,564 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:00:59,565 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:01:00,146 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:01:01,396 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:01:02,298 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:01:05,979 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:01:10,792 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:01:14,373 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:01:18,290 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:01:18,981 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:01:23,810 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:01:23,811 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:01:23,811 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:01:24,309 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:01:28,348 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:01:29,226 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:01:34,096 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:01:37,006 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:01:39,669 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:01:45,503 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:01:46,224 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:01:50,437 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:01:50,439 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:01:50,440 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:01:50,847 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:01:52,129 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:01:53,083 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:01:57,841 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:02:03,838 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:02:07,622 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:02:22,731 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:02:23,362 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:02:29,416 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:02:29,418 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:02:29,418 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:02:29,703 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:02:30,870 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:02:32,101 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:02:35,070 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:02:38,856 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:02:42,237 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:02:47,224 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:02:47,868 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:02:52,495 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:02:52,497 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:02:52,497 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:02:52,988 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:02:54,424 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:02:55,350 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:03:00,162 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:03:04,665 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:03:12,241 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:03:17,223 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:03:18,284 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:03:27,619 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:03:27,621 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:03:27,622 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:03:28,018 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:03:29,161 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:03:30,430 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:03:34,364 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:03:38,898 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:03:45,672 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:03:48,394 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:03:50,640 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:03:53,205 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:03:53,206 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:03:53,206 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:03:53,718 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:03:57,881 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:03:58,787 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:04:04,205 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:04:07,436 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:04:17,369 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:04:21,490 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:04:22,241 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:04:27,212 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:04:27,214 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:04:27,214 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:04:27,696 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:04:28,798 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:04:29,635 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:04:32,936 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:04:35,904 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:04:40,205 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:04:45,645 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:04:46,350 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:04:51,556 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:04:51,557 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:04:51,557 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:04:52,086 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:04:53,307 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:04:54,237 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:04:58,224 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:05:00,824 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:05:03,862 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:05:09,113 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:05:09,698 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:05:12,208 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:05:12,210 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:05:12,211 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:05:12,681 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:05:15,447 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:05:16,973 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:05:21,589 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:05:25,883 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:05:30,998 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:05:35,841 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:05:36,529 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:05:41,745 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:05:41,746 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:05:41,746 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:05:42,088 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:05:43,193 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:05:43,984 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:05:48,508 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:05:52,954 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:05:55,693 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:05:59,465 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:06:00,182 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:06:04,652 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:06:04,653 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:06:04,654 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:06:05,099 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:06:06,253 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:06:07,147 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:06:11,857 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:06:17,897 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:06:21,078 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:06:27,295 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:06:27,934 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:06:35,261 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:06:35,262 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:06:35,262 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:06:35,713 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:06:36,941 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:06:37,868 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:06:42,064 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:06:44,830 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:06:47,696 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:06:50,297 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:06:53,536 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:06:59,484 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:06:59,486 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:06:59,486 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:06:59,915 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:07:01,215 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:07:02,134 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:07:05,312 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:07:09,405 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:07:12,582 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:07:16,429 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:07:17,192 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:07:23,522 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:07:23,523 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:07:23,524 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:07:24,071 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:07:25,354 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:07:28,181 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:07:30,501 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:07:33,775 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:07:39,611 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:07:41,892 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:07:42,652 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:07:45,803 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:07:45,804 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:07:45,805 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:07:46,221 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:07:47,499 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:07:48,834 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:07:52,216 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:07:57,123 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:08:00,061 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:08:03,453 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:08:04,087 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:08:08,510 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:08:08,511 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:08:08,512 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:08:08,860 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:08:10,602 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:08:11,670 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:08:15,771 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:08:19,133 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:08:27,026 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:08:31,071 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:08:31,788 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:08:37,829 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:08:37,831 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:08:37,831 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:08:38,393 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:08:39,677 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:08:40,647 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:08:44,947 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:08:49,654 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:08:56,418 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:09:00,624 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:09:01,638 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:09:07,729 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:09:07,730 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:09:07,730 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:09:08,067 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:09:09,187 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:09:10,037 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:09:13,210 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:09:16,488 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:09:20,962 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:09:25,193 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:09:28,524 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:09:34,516 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:09:34,518 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:09:34,518 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:09:34,994 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:09:36,161 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:09:36,971 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:09:38,709 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:09:42,293 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:09:45,566 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:09:52,228 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:09:52,941 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:09:57,925 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:09:57,926 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:09:57,926 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:09:58,686 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:09:59,818 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:10:00,711 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:10:02,424 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:10:05,283 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:10:15,265 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:10:20,398 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:10:21,088 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:10:25,228 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:10:25,231 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:10:25,232 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:10:25,622 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:10:26,914 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:10:29,934 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:10:36,295 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:10:42,334 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:10:49,198 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:10:53,439 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:10:54,115 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:10:58,485 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:10:58,487 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:10:58,488 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:10:59,139 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:11:00,248 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:11:01,083 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:11:06,516 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:11:11,014 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:11:20,990 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:11:23,778 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:11:24,428 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:11:29,668 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:11:29,669 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:11:29,669 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:11:30,269 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:11:31,447 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:11:32,419 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:11:35,185 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:11:41,941 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:11:47,266 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:11:53,373 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:11:54,016 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:11:59,559 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:11:59,560 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:11:59,561 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:12:00,173 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:12:02,444 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:12:03,344 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:12:06,827 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:12:10,104 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:12:15,028 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:12:18,769 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:12:19,474 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:12:23,960 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:12:23,960 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:12:23,961 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:12:24,854 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:12:26,025 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:12:28,842 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:12:30,878 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:12:35,976 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:12:40,617 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:12:45,179 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:12:45,901 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:12:51,368 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:12:51,370 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:12:51,371 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:12:51,802 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:12:53,519 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:12:54,755 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:12:57,831 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:13:02,840 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:13:06,016 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:13:09,570 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:13:10,417 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:13:15,509 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:13:15,509 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:13:15,510 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:13:15,947 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:13:17,134 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:13:17,953 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:13:20,959 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:13:26,313 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:13:30,386 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:13:33,838 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:13:34,685 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:13:37,154 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:13:37,156 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:13:37,156 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:13:37,440 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:13:38,583 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:13:39,811 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:13:43,800 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:13:46,567 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:13:49,945 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:13:54,343 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:13:55,067 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:13:59,379 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:13:59,380 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:13:59,380 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:13:59,762 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:14:00,948 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:14:01,821 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:14:05,233 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:14:08,603 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:14:12,064 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:14:17,248 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:14:18,207 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:14:23,556 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:14:23,558 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:14:23,558 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:14:24,058 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:14:25,261 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:14:28,345 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:14:33,467 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:14:36,131 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:14:39,967 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:14:44,412 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:14:45,143 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:14:51,377 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:14:51,378 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:14:51,378 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:14:51,914 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:14:53,113 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:14:54,053 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:14:57,005 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:14:58,994 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:15:01,536 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:15:04,230 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:15:05,010 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:15:09,578 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:15:09,580 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:15:09,580 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:15:10,082 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:15:11,256 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:15:12,279 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:15:16,066 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:15:18,625 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:15:21,902 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:15:33,266 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 13:15:33,930 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:15:39,376 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 13:15:39,378 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 13:15:39,378 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 13:15:39,823 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 13:15:41,591 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 13:15:42,427 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:15:46,034 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 13:30:48,653 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 14:53:48,508 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-5639bb8e-ccab-4535-8b3f-00799a6b97b0', event.id_='b90daf72-1dcf-4250-a9a0-aa338e86440b'
2025-01-02 14:53:48,552 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 271, in __aiter__
    async for part in self._httpcore_stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 407, in __aiter__
    raise exc from None
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 403, in __aiter__
    async for part in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 342, in __aiter__
    raise exc
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 334, in __aiter__
    async for chunk in self._connection._receive_response_body(**kwargs):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 203, in _receive_response_body
    event = await self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 217, in _receive_event
    data = await self._network_stream.read(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_backends/anyio.py", line 32, in read
    with map_exceptions(exc_map):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 370, in aget_response
    response = await self._arefine_response_single(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 396, in _arefine_response_single
    response = await aget_response_text(response)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response/utils.py", line 17, in aget_response_text
    async for response in response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/llm.py", line 151, in gen
    async for response in chat_response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/callbacks.py", line 88, in wrapped_gen
    async for x in f_return_val:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/llms/openai/base.py", line 724, in gen
    async for response in await aclient.chat.completions.create(
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 147, in __aiter__
    async for item in self._iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 160, in __stream__
    async for sse in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 151, in _iter_events
    async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 302, in aiter_bytes
    async for chunk in self._aiter_chunks(iterator):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 313, in _aiter_chunks
    async for chunk in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 997, in aiter_bytes
    async for raw_bytes in self.aiter_raw():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 1055, in aiter_raw
    async for raw_stream_bytes in self.stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_client.py", line 176, in __aiter__
    async for chunk in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 270, in __aiter__
    with map_httpcore_exceptions():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 14:53:49,126 - asyncio - ERROR - Exception in callback Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-02e9b9f3be7d', bound_args=<BoundArgumen...t remarks?'})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x362e9ba00>)(<WorkflowHand...nthesize': ")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273
handle: <Handle Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-02e9b9f3be7d', bound_args=<BoundArgumen...t remarks?'})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x362e9ba00>)(<WorkflowHand...nthesize': ")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 271, in __aiter__
    async for part in self._httpcore_stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 407, in __aiter__
    raise exc from None
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 403, in __aiter__
    async for part in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 342, in __aiter__
    raise exc
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 334, in __aiter__
    async for chunk in self._connection._receive_response_body(**kwargs):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 203, in _receive_response_body
    event = await self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 217, in _receive_event
    data = await self._network_stream.read(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_backends/anyio.py", line 32, in read
    with map_exceptions(exc_map):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 247, in _task
    new_ev = await instrumented_step(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/Documents/GitHub/AITA-Judge-Agent/src/agent/AITA_Agent.py", line 126, in synthesize
    response = await response_synthesizer.asynthesize(query, nodes=ev.nodes)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/base.py", line 306, in asynthesize
    response_str = await self.aget_response(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 370, in aget_response
    response = await self._arefine_response_single(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 396, in _arefine_response_single
    response = await aget_response_text(response)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response/utils.py", line 17, in aget_response_text
    async for response in response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/llm.py", line 151, in gen
    async for response in chat_response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/callbacks.py", line 88, in wrapped_gen
    async for x in f_return_val:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/llms/openai/base.py", line 724, in gen
    async for response in await aclient.chat.completions.create(
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 147, in __aiter__
    async for item in self._iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 160, in __stream__
    async for sse in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 151, in _iter_events
    async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 302, in aiter_bytes
    async for chunk in self._aiter_chunks(iterator):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 313, in _aiter_chunks
    async for chunk in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 997, in aiter_bytes
    async for raw_bytes in self.aiter_raw():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 1055, in aiter_raw
    async for raw_stream_bytes in self.stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_client.py", line 176, in __aiter__
    async for chunk in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 270, in __aiter__
    with map_httpcore_exceptions():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/asyncio/events.py", line 84, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 285, in handle_future_result
    raise exception
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 440, in _run_workflow
    raise exception_raised
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 254, in _task
    raise WorkflowRuntimeError(
llama_index.core.workflow.errors.WorkflowRuntimeError: Error in step 'synthesize': 
2025-01-02 14:53:49,132 - src.agent.evaluation.eval_util - WARNING - Error processing sample 667: Error in step 'synthesize': 
2025-01-02 14:53:49,149 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 14:53:49,151 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 14:53:49,151 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 14:53:49,517 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 15:08:51,801 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 8] nodename nor servname provided, or not known

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 321, in wrapper
    result = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/postprocessor/cohere_rerank/base.py", line 81, in _postprocess_nodes
    results = self._client.rerank(
              ^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/cohere/base_client.py", line 2055, in rerank
    _response = self._client_wrapper.httpx_client.request(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/cohere/core/http_client.py", line 195, in request
    response = self.httpx_client.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_client.py", line 825, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 8] nodename nor servname provided, or not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 15:08:52,437 - asyncio - ERROR - Exception in callback Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-4fc621f081fc', bound_args=<BoundArgumen...e trouble?"})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x362f3b800>)(<WorkflowHand...r not known")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273
handle: <Handle Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-4fc621f081fc', bound_args=<BoundArgumen...e trouble?"})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x362f3b800>)(<WorkflowHand...r not known")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 8] nodename nor servname provided, or not known

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 247, in _task
    new_ev = await instrumented_step(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/Documents/GitHub/AITA-Judge-Agent/src/agent/AITA_Agent.py", line 100, in rerank
    new_nodes = cohere_reranker.postprocess_nodes(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/postprocessor/types.py", line 54, in postprocess_nodes
    return self._postprocess_nodes(nodes, query_bundle)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 321, in wrapper
    result = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/postprocessor/cohere_rerank/base.py", line 81, in _postprocess_nodes
    results = self._client.rerank(
              ^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/cohere/base_client.py", line 2055, in rerank
    _response = self._client_wrapper.httpx_client.request(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/cohere/core/http_client.py", line 195, in request
    response = self.httpx_client.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_client.py", line 825, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 8] nodename nor servname provided, or not known

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/asyncio/events.py", line 84, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 285, in handle_future_result
    raise exception
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 440, in _run_workflow
    raise exception_raised
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 254, in _task
    raise WorkflowRuntimeError(
llama_index.core.workflow.errors.WorkflowRuntimeError: Error in step 'rerank': [Errno 8] nodename nor servname provided, or not known
2025-01-02 15:08:52,440 - src.agent.evaluation.eval_util - WARNING - Error processing sample 668: Error in step 'rerank': [Errno 8] nodename nor servname provided, or not known
2025-01-02 15:08:52,453 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 15:08:52,453 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 15:08:52,453 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 15:08:52,777 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 15:08:54,170 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 15:08:55,004 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 15:08:56,595 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 15:08:58,797 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 15:09:03,828 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 15:09:07,952 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 15:09:08,551 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 15:09:13,357 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 15:09:13,358 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 15:09:13,358 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 15:09:13,966 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 15:09:16,265 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 15:41:14,651 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 286, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/socket.py", line 706, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/ssl.py", line 1314, in recv_into
    return self.read(nbytes, buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/ssl.py", line 1166, in read
    return self._sslobj.read(len, buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TimeoutError: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 39, in reraise
    raise value
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 713, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)
2025-01-02 15:41:15,915 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 15:41:17,996 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 15:41:21,408 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 15:41:26,426 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 15:41:32,508 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 15:41:33,822 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 15:52:29,776 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 16:16:16,276 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-acf597ba-bd99-405b-affb-748c09f82573', event.id_='a1aae237-4282-4f43-8c15-428cd604b1d2'
2025-01-02 16:16:16,279 - src.agent.evaluation.eval_util - WARNING - Error processing sample 670: 
2025-01-02 16:16:16,313 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 16:16:16,314 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 16:16:16,315 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 16:16:16,793 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 16:16:16,837 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 16:16:18,703 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 16:16:19,552 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 16:16:22,723 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 16:16:25,791 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 16:34:10,849 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 17:26:57,012 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-65782286-8642-4061-8292-014b00da3517', event.id_='c55d3146-f0b2-49e2-8e8a-b0e32584453a'
2025-01-02 17:26:57,160 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 271, in __aiter__
    async for part in self._httpcore_stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 407, in __aiter__
    raise exc from None
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 403, in __aiter__
    async for part in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 342, in __aiter__
    raise exc
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 334, in __aiter__
    async for chunk in self._connection._receive_response_body(**kwargs):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 203, in _receive_response_body
    event = await self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 217, in _receive_event
    data = await self._network_stream.read(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_backends/anyio.py", line 32, in read
    with map_exceptions(exc_map):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 370, in aget_response
    response = await self._arefine_response_single(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 396, in _arefine_response_single
    response = await aget_response_text(response)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response/utils.py", line 17, in aget_response_text
    async for response in response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/llm.py", line 151, in gen
    async for response in chat_response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/callbacks.py", line 88, in wrapped_gen
    async for x in f_return_val:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/llms/openai/base.py", line 724, in gen
    async for response in await aclient.chat.completions.create(
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 147, in __aiter__
    async for item in self._iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 160, in __stream__
    async for sse in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 151, in _iter_events
    async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 302, in aiter_bytes
    async for chunk in self._aiter_chunks(iterator):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 313, in _aiter_chunks
    async for chunk in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 997, in aiter_bytes
    async for raw_bytes in self.aiter_raw():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 1055, in aiter_raw
    async for raw_stream_bytes in self.stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_client.py", line 176, in __aiter__
    async for chunk in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 270, in __aiter__
    with map_httpcore_exceptions():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 17:34:22,063 - asyncio - ERROR - Exception in callback Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-d950180501cb', bound_args=<BoundArgumen...on my car?"})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x363289540>)(<WorkflowHand...nthesize': ")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273
handle: <Handle Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-d950180501cb', bound_args=<BoundArgumen...on my car?"})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x363289540>)(<WorkflowHand...nthesize': ")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 271, in __aiter__
    async for part in self._httpcore_stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 407, in __aiter__
    raise exc from None
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 403, in __aiter__
    async for part in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 342, in __aiter__
    raise exc
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 334, in __aiter__
    async for chunk in self._connection._receive_response_body(**kwargs):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 203, in _receive_response_body
    event = await self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 217, in _receive_event
    data = await self._network_stream.read(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_backends/anyio.py", line 32, in read
    with map_exceptions(exc_map):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 247, in _task
    new_ev = await instrumented_step(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/Documents/GitHub/AITA-Judge-Agent/src/agent/AITA_Agent.py", line 126, in synthesize
    response = await response_synthesizer.asynthesize(query, nodes=ev.nodes)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/base.py", line 306, in asynthesize
    response_str = await self.aget_response(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 370, in aget_response
    response = await self._arefine_response_single(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 396, in _arefine_response_single
    response = await aget_response_text(response)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response/utils.py", line 17, in aget_response_text
    async for response in response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/llm.py", line 151, in gen
    async for response in chat_response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/callbacks.py", line 88, in wrapped_gen
    async for x in f_return_val:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/llms/openai/base.py", line 724, in gen
    async for response in await aclient.chat.completions.create(
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 147, in __aiter__
    async for item in self._iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 160, in __stream__
    async for sse in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 151, in _iter_events
    async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 302, in aiter_bytes
    async for chunk in self._aiter_chunks(iterator):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 313, in _aiter_chunks
    async for chunk in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 997, in aiter_bytes
    async for raw_bytes in self.aiter_raw():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 1055, in aiter_raw
    async for raw_stream_bytes in self.stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_client.py", line 176, in __aiter__
    async for chunk in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 270, in __aiter__
    with map_httpcore_exceptions():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/asyncio/events.py", line 84, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 285, in handle_future_result
    raise exception
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 440, in _run_workflow
    raise exception_raised
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 254, in _task
    raise WorkflowRuntimeError(
llama_index.core.workflow.errors.WorkflowRuntimeError: Error in step 'synthesize': 
2025-01-02 17:34:22,065 - src.agent.evaluation.eval_util - WARNING - Error processing sample 671: Error in step 'synthesize': 
2025-01-02 17:34:22,079 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:34:22,081 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:34:22,081 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:34:22,479 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:34:25,236 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:34:27,908 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:34:29,437 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:36:01,972 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 286, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/socket.py", line 706, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/ssl.py", line 1314, in recv_into
    return self.read(nbytes, buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/ssl.py", line 1166, in read
    return self._sslobj.read(len, buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TimeoutError: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 39, in reraise
    raise value
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 713, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)
2025-01-02 17:36:02,623 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:36:06,041 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:39:10,747 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-91b1b5af-e6ef-4353-8391-9acb93843b1f', event.id_='0f9e9719-fad4-4bb6-8732-ae5580fe0d21'
2025-01-02 17:39:11,637 - asyncio - ERROR - Exception in callback Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-19c7859b4b8f', bound_args=<BoundArgumen...ick me out'})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x363283a40>)(<WorkflowHand...nthesize': ")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273
handle: <Handle Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-19c7859b4b8f', bound_args=<BoundArgumen...ick me out'})>, instance=<src.agent.AI...t 0x308d81bd0>, context=<_contextvars...t 0x363283a40>)(<WorkflowHand...nthesize': ")>) at /Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 271, in __aiter__
    async for part in self._httpcore_stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 407, in __aiter__
    raise exc from None
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 403, in __aiter__
    async for part in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 342, in __aiter__
    raise exc
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 334, in __aiter__
    async for chunk in self._connection._receive_response_body(**kwargs):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 203, in _receive_response_body
    event = await self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_async/http11.py", line 217, in _receive_event
    data = await self._network_stream.read(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_backends/anyio.py", line 32, in read
    with map_exceptions(exc_map):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 247, in _task
    new_ev = await instrumented_step(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/Documents/GitHub/AITA-Judge-Agent/src/agent/AITA_Agent.py", line 126, in synthesize
    response = await response_synthesizer.asynthesize(query, nodes=ev.nodes)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/base.py", line 306, in asynthesize
    response_str = await self.aget_response(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 370, in aget_response
    response = await self._arefine_response_single(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py", line 396, in _arefine_response_single
    response = await aget_response_text(response)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/response/utils.py", line 17, in aget_response_text
    async for response in response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/llm.py", line 151, in gen
    async for response in chat_response_gen:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/llms/callbacks.py", line 88, in wrapped_gen
    async for x in f_return_val:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/llms/openai/base.py", line 724, in gen
    async for response in await aclient.chat.completions.create(
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 147, in __aiter__
    async for item in self._iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 160, in __stream__
    async for sse in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 151, in _iter_events
    async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 302, in aiter_bytes
    async for chunk in self._aiter_chunks(iterator):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openai/_streaming.py", line 313, in _aiter_chunks
    async for chunk in iterator:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 997, in aiter_bytes
    async for raw_bytes in self.aiter_raw():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_models.py", line 1055, in aiter_raw
    async for raw_stream_bytes in self.stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_client.py", line 176, in __aiter__
    async for chunk in self._stream:
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 270, in __aiter__
    with map_httpcore_exceptions():
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/asyncio/events.py", line 84, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py", line 285, in handle_future_result
    raise exception
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 440, in _run_workflow
    raise exception_raised
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py", line 254, in _task
    raise WorkflowRuntimeError(
llama_index.core.workflow.errors.WorkflowRuntimeError: Error in step 'synthesize': 
2025-01-02 17:39:11,644 - src.agent.evaluation.eval_util - WARNING - Error processing sample 672: Error in step 'synthesize': 
2025-01-02 17:39:11,668 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:39:11,670 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:39:11,670 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:39:12,164 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:39:13,865 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:39:17,309 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:39:19,021 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:39:22,503 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:39:27,273 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:39:29,669 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:39:31,815 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:39:34,298 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:39:34,299 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:39:34,299 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:39:34,588 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:39:38,236 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:39:40,118 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:39:42,397 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:39:44,929 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:39:47,362 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:39:51,876 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:39:53,637 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:39:56,509 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:39:56,510 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:39:56,511 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:39:57,010 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:39:59,038 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:40:01,010 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:40:03,822 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:40:06,029 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:40:10,118 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:40:13,968 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:40:15,621 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:40:18,085 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:40:18,086 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:40:18,086 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:40:18,440 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:40:22,358 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:40:24,358 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:40:26,606 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:40:31,627 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:40:34,288 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:40:37,131 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:40:38,791 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:40:42,883 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:40:42,884 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:40:42,885 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:40:43,196 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:40:45,554 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:40:48,421 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:40:50,632 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:40:54,969 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:40:57,635 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:41:00,345 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:41:02,142 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:41:05,019 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:41:05,020 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:41:05,020 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:41:05,324 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:41:07,071 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:41:08,599 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:41:10,245 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:41:15,859 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:41:20,167 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:41:22,171 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:41:24,845 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:41:27,277 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:41:27,279 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:41:27,279 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:41:27,664 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:41:30,362 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:41:31,228 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:41:33,039 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:41:37,267 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:41:39,829 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:41:46,781 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:41:47,918 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:41:52,474 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:41:52,474 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:41:52,475 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:41:52,805 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:41:53,932 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:41:54,778 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:41:56,720 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:42:00,000 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:42:04,198 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:42:07,879 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:42:08,600 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:42:12,881 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:42:12,882 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:42:12,882 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:42:13,212 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:42:14,333 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:42:15,938 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:42:20,723 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:42:23,044 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:42:27,199 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:42:31,683 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:42:32,898 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:42:35,496 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:42:35,497 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:42:35,498 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:42:35,809 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:42:37,958 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:42:38,733 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:42:40,110 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:42:42,497 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:42:44,562 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:42:47,491 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:42:48,124 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:42:52,803 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:42:52,805 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:42:52,805 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:42:53,065 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:42:54,374 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:42:55,196 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:42:58,678 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:43:00,726 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:43:04,002 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:43:06,070 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:43:06,870 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:43:08,582 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:43:08,583 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:43:08,583 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:43:08,912 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:43:10,039 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:43:10,864 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:43:12,096 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:43:13,933 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:43:15,574 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:43:17,270 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:43:18,028 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:43:20,603 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:43:20,604 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:43:20,604 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:43:23,463 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:43:26,116 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:43:27,250 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:43:29,182 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:43:32,689 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:43:35,127 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:43:37,877 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:43:39,220 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:43:43,239 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:43:43,240 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:43:43,241 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:43:43,747 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:43:45,270 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:43:46,193 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:43:48,545 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:43:50,020 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:43:52,337 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:43:54,793 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:43:55,511 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:43:57,284 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:43:57,285 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:43:57,285 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:43:57,585 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:44:00,077 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:44:00,804 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:44:02,370 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:44:04,317 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:44:07,390 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:44:09,572 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:44:10,358 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:44:12,977 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:44:12,978 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:44:12,978 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:44:13,418 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:44:16,914 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:44:17,838 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:44:20,396 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:44:22,341 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:44:24,387 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:44:27,468 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:44:28,174 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:44:30,788 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:44:30,790 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:44:30,790 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:44:31,060 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:44:32,169 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:44:32,987 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:44:34,730 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:44:37,401 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:44:41,897 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:44:44,571 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:44:45,217 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:44:49,686 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:44:49,687 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:44:49,687 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:44:50,194 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:44:53,568 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:44:54,498 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:44:55,919 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:44:58,177 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:45:01,356 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:45:03,474 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:45:04,377 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:45:06,795 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:45:06,796 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:45:06,797 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:45:07,194 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:45:08,286 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:45:09,137 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:45:12,314 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:45:14,295 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:45:16,612 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:45:20,082 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:45:20,718 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:45:22,368 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:45:22,368 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:45:22,369 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:45:22,967 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:45:24,175 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:45:25,115 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:45:26,788 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:45:28,470 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:45:33,099 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:45:36,077 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:45:38,020 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:45:39,386 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:45:39,388 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:45:39,388 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:45:39,656 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:45:44,058 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:45:44,983 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:45:46,824 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:45:48,868 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:45:51,024 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:45:54,301 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:45:55,018 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:45:57,995 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:45:57,997 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:45:57,997 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:45:58,431 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:45:59,870 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:46:00,751 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:46:04,022 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:46:06,533 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:46:09,311 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:46:11,781 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:46:12,451 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:46:13,987 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:46:13,988 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:46:13,988 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:46:14,476 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:46:18,915 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:46:19,734 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:46:24,981 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:46:27,478 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:46:30,037 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:46:32,449 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:46:33,930 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:46:37,095 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:46:37,097 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:46:37,097 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:46:37,617 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:46:38,756 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:46:39,609 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:46:42,634 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:46:44,474 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:46:48,263 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:46:50,873 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:46:51,541 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:47:02,911 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:47:02,913 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:47:02,913 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:47:03,424 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:47:04,790 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:47:05,779 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:47:09,155 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:47:11,603 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:47:14,068 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:47:15,976 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:47:19,004 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:47:21,288 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:47:21,291 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:47:21,291 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:47:21,753 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:47:24,238 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:47:25,030 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:47:27,282 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:47:31,291 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:47:33,678 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:47:36,584 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:47:37,419 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:47:41,055 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:47:41,056 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:47:41,056 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:47:41,518 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:47:42,743 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:47:43,616 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:47:46,830 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:47:48,588 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:47:53,244 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:47:56,284 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:47:58,205 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:47:59,888 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:47:59,891 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:47:59,891 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:48:00,404 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:48:03,992 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:48:04,807 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:48:06,060 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:48:08,959 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:48:10,805 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:48:13,677 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:48:14,388 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:48:16,193 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:48:16,194 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:48:16,194 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:48:16,744 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:48:19,507 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:48:20,327 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:48:21,765 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:48:24,731 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:48:29,132 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:48:31,281 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:48:31,998 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:48:34,392 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:48:34,394 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:48:34,395 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:48:34,868 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:48:36,607 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:48:37,635 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:48:40,716 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:48:43,980 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:48:46,336 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:48:51,178 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:48:51,863 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:48:57,370 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:48:57,371 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:48:57,371 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:48:57,909 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:48:59,082 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:49:00,267 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:49:03,437 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:49:05,261 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:49:08,971 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:49:13,958 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:49:14,703 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:49:18,207 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:49:18,209 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:49:18,210 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:49:18,700 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:49:20,742 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:49:23,021 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:49:24,578 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:49:27,500 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:49:29,490 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:49:34,003 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:49:34,671 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:49:39,111 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:49:39,112 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:49:39,113 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:49:39,480 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:49:40,620 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:49:41,431 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:49:44,526 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:49:46,507 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:49:50,133 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:49:54,189 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:49:54,843 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:49:59,309 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:49:59,312 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:49:59,312 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:49:59,629 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:50:00,805 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:50:01,706 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:50:03,056 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:50:05,630 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:50:08,772 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:50:11,313 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:50:11,948 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:50:15,951 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:50:15,952 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:50:15,952 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:50:16,455 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:50:19,317 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:50:21,781 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:50:23,171 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:50:27,441 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:50:29,247 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:50:32,081 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:50:33,247 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:50:36,196 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:50:36,199 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:50:36,199 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:50:36,523 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:50:37,671 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:50:38,674 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:50:40,828 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:50:44,285 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:50:48,286 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:50:53,416 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:50:54,135 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:50:58,004 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:50:58,005 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:50:58,005 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:50:58,278 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:50:59,509 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:51:00,279 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:51:03,150 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:51:06,106 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:51:10,316 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:51:15,541 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:51:16,256 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:51:17,695 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:51:17,697 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:51:17,698 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:51:18,032 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:51:19,735 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:51:21,375 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:51:22,810 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:51:26,907 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:51:29,672 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:51:32,450 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:51:33,254 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:51:35,190 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:51:35,191 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:51:35,191 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:51:35,816 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:51:40,100 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:51:41,140 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:51:44,526 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:51:46,382 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:51:48,510 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:51:50,783 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:51:51,791 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:51:56,187 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:51:56,189 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:51:56,189 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:51:56,564 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:51:57,931 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:51:59,678 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:52:02,028 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:52:06,811 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:52:08,492 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:52:10,084 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:52:12,372 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:52:13,788 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:52:13,789 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:52:13,790 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:52:14,729 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:52:15,924 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:52:16,898 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:52:20,099 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:52:24,765 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:52:26,574 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:52:31,524 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:52:32,238 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:52:38,009 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:52:38,011 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:52:38,012 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:52:38,487 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:52:39,648 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:52:40,638 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:52:44,119 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:52:46,587 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:52:48,842 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:52:51,285 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:52:52,003 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:52:55,611 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:52:55,612 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:52:55,613 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:52:56,512 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:52:57,707 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:52:58,558 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:53:00,945 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:53:02,754 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:53:07,600 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:53:12,211 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:53:12,897 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:53:15,505 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:53:15,508 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:53:15,508 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:53:15,968 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:53:20,230 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:53:21,049 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:53:22,928 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:53:25,377 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:53:31,604 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:53:36,249 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:53:36,956 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:53:43,311 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:53:43,313 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:53:43,314 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:53:43,832 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:53:45,167 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:53:46,278 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:53:49,046 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:53:55,798 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:54:00,716 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:54:07,178 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:54:07,789 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:54:13,319 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:54:13,321 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:54:13,321 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:54:13,822 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:54:14,916 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:54:15,770 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:54:17,301 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:54:21,920 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:54:28,872 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:54:33,685 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:54:34,408 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:54:39,003 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:54:39,004 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:54:39,005 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:54:39,527 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:54:40,612 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:54:44,240 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:54:45,571 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:54:48,945 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:54:52,018 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:54:55,708 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:54:56,278 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:55:00,550 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:55:00,551 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:55:00,551 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:55:03,602 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:55:07,685 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:55:08,515 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:55:09,895 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:55:16,490 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:55:20,283 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:55:24,032 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:55:24,787 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:55:27,635 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:55:27,635 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:55:27,636 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:55:27,988 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:55:30,603 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:55:31,341 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:55:32,147 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:55:34,040 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:55:38,203 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:55:40,588 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:55:41,282 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:55:43,114 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:55:43,116 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:55:43,116 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:55:43,630 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:55:44,696 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:55:45,579 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:55:50,184 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:55:52,048 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:55:55,076 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:55:56,588 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:55:59,399 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:56:02,709 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:56:02,710 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:56:02,710 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:56:03,191 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:56:04,284 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:56:05,180 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:56:08,924 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:56:11,374 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:56:15,995 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:56:20,384 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:56:21,111 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:56:27,432 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:56:27,435 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:56:27,436 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:56:27,840 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:56:28,978 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:56:29,907 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:56:34,126 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:56:36,255 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:56:39,277 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:56:45,538 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:56:46,183 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:56:50,823 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:56:50,824 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:56:50,824 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:56:51,315 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:56:52,615 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:56:53,402 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:56:57,958 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:57:01,444 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:57:03,799 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:57:05,675 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:57:06,454 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:57:09,098 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:57:09,101 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:57:09,101 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:57:09,533 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:57:12,498 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:57:18,747 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:57:20,966 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:57:22,643 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:57:27,572 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:57:30,773 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:57:34,023 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:57:35,692 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:57:35,693 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:57:35,693 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:57:35,950 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:57:39,224 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:57:39,987 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:57:41,480 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:57:46,009 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:57:57,763 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:58:02,305 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:58:03,089 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:58:05,007 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:58:05,010 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:58:05,011 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:58:05,362 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:58:06,569 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:58:07,405 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:58:10,765 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:58:13,938 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:58:17,425 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:58:22,316 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:58:23,160 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:58:25,582 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:58:25,583 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:58:25,584 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:58:25,875 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:58:27,083 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:58:30,532 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:58:32,480 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:58:36,667 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:58:40,154 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:58:44,012 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:58:44,763 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:58:49,613 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:58:49,615 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:58:49,616 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:58:49,987 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:58:51,318 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:58:52,138 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:58:56,130 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:58:58,779 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:59:02,275 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:59:13,075 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:59:13,743 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:59:18,698 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:59:18,699 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:59:18,699 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:59:19,042 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:59:20,399 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:59:21,223 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:59:25,929 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:59:28,699 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:59:32,241 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:59:34,169 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:59:36,478 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:59:40,039 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 17:59:40,041 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 17:59:40,041 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 17:59:40,334 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 17:59:41,499 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 17:59:42,418 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:59:46,107 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:59:52,348 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:59:54,191 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 17:59:58,507 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 17:59:59,207 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:00:00,781 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:00:00,783 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:00:00,784 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:00:01,186 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:00:02,521 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:00:06,415 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:00:08,530 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:00:14,060 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:00:18,973 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:00:25,227 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:00:25,936 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:00:32,279 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:00:32,282 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:00:32,282 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:00:32,804 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:00:33,883 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:00:35,155 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:00:38,844 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:00:42,187 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:00:45,699 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:00:51,046 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:00:51,745 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:00:56,395 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:00:56,397 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:00:56,397 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:00:56,761 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:00:57,842 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:00:58,726 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:01:03,932 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:01:07,003 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:01:10,670 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:01:15,115 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:01:15,808 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:01:21,396 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:01:21,397 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:01:21,398 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:01:22,058 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:01:23,488 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:01:24,303 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:01:27,893 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:01:33,365 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:01:36,503 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:01:39,323 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:01:39,974 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:01:45,487 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:01:45,488 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:01:45,489 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:01:46,122 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:01:47,858 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:01:48,682 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:01:51,239 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:02:01,275 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:02:05,343 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:02:09,476 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:02:12,671 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:02:16,817 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:02:16,820 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:02:16,820 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:02:17,571 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:02:18,637 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:02:19,464 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:02:23,601 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:02:26,022 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:02:29,844 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:02:34,326 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:02:34,967 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:02:37,887 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:02:37,887 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:02:37,887 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:02:39,269 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:02:42,574 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:02:43,377 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:02:44,704 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:02:47,142 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:02:49,099 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:02:53,477 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:02:54,169 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:02:59,347 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:02:59,349 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:02:59,349 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:03:00,054 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:03:01,155 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:03:02,102 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:03:05,181 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:03:07,016 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:03:11,733 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:03:17,409 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:03:18,080 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:03:19,989 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:03:19,992 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:03:19,992 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:03:20,373 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:03:23,707 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:03:24,535 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:03:26,170 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:03:29,549 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:03:33,560 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:03:36,122 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:03:36,737 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:03:40,885 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:03:40,888 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:03:40,888 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:03:41,327 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:03:42,437 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:03:43,273 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:03:44,981 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:03:48,189 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:03:49,925 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:03:53,609 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:03:54,264 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:03:58,504 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:03:58,505 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:03:58,505 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:03:59,100 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:04:00,673 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:04:01,703 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:04:05,917 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:04:08,259 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:04:12,116 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:04:14,176 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:04:15,013 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:04:17,262 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:04:17,264 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:04:17,265 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:04:17,885 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:04:19,091 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:04:19,935 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:04:24,131 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:04:26,993 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:04:29,358 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:04:31,799 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:04:32,521 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:04:38,091 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:04:38,093 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:04:38,094 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:04:38,670 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:04:43,886 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:04:44,814 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:04:47,064 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:04:48,807 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:04:53,826 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:04:58,350 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:04:58,977 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:05:02,186 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:05:02,188 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:05:02,189 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:05:02,453 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:05:07,137 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:05:08,061 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:05:12,052 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:05:14,520 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:05:18,766 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:05:21,980 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:05:22,624 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:05:25,792 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:05:25,793 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:05:25,793 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:05:26,287 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:05:27,477 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:05:28,335 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:05:31,918 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:05:34,992 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:05:37,140 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:05:38,880 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:05:39,699 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:05:43,291 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:05:43,292 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:05:43,292 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:05:43,898 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:05:45,130 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:05:46,052 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:05:49,123 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:05:51,988 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:05:56,186 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:05:58,781 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:06:01,209 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:06:05,590 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:06:05,592 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:06:05,592 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:06:06,026 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:06:09,184 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:06:10,012 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:06:15,853 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:06:20,971 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:06:23,599 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:06:28,079 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:06:28,956 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:06:33,803 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:06:33,804 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:06:33,804 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:06:34,275 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:06:35,716 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:06:36,539 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:06:37,974 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:06:40,835 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:06:43,395 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:06:47,579 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:06:48,413 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:06:50,390 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:06:50,393 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:06:50,393 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:06:50,686 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:06:54,482 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:06:55,377 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:06:59,272 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:07:02,371 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:07:05,740 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:07:08,790 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:07:09,509 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:07:12,988 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:07:12,989 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:07:12,989 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:07:13,505 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:07:14,631 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:07:15,446 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:07:19,032 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:07:21,595 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:07:26,613 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:07:28,581 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:07:29,380 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:07:32,592 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:07:32,595 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:07:32,595 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:07:33,061 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:07:34,190 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:07:35,015 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:07:36,226 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:07:40,434 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:07:46,170 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:07:48,181 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:07:48,915 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:07:51,398 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:07:51,399 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:07:51,399 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:07:51,803 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:07:52,963 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:07:53,857 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:07:55,797 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:07:58,865 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:08:01,836 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:08:05,294 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:08:05,931 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:08:11,437 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:08:11,439 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:08:11,439 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:08:11,878 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:08:13,001 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:08:13,942 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:08:15,763 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:08:19,452 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:08:21,205 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:08:24,381 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:08:25,186 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:08:30,209 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:08:30,210 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:08:30,210 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:08:33,789 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:08:37,948 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:08:38,804 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:08:40,135 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:08:42,492 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:08:45,053 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:08:47,582 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:08:48,329 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:08:51,221 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:08:51,224 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:08:51,224 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:08:51,711 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:08:52,767 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:08:53,564 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:08:57,135 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:08:59,387 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:09:03,689 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:09:06,197 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:09:06,965 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:09:09,702 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:09:09,703 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:09:09,703 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:09:09,996 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:09:11,144 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:09:12,294 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:09:15,569 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:09:17,078 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:15:44,841 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 286, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/socket.py", line 706, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/ssl.py", line 1314, in recv_into
    return self.read(nbytes, buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/ssl.py", line 1166, in read
    return self._sslobj.read(len, buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TimeoutError: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 39, in reraise
    raise value
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 713, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)
2025-01-02 18:15:45,496 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:15:51,232 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:15:51,921 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:15:56,402 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:15:56,404 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:15:56,405 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:15:56,680 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:15:58,439 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:16:00,458 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:16:04,129 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:16:06,280 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:16:10,103 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:16:12,560 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:16:14,977 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:16:18,064 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:16:18,065 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:16:18,065 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:16:18,464 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:16:22,387 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:16:23,277 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:16:27,063 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:16:33,925 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:16:39,864 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:16:44,441 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:16:45,083 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:16:47,578 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:16:47,580 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:16:47,581 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:16:47,881 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:16:51,833 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:16:52,662 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:16:53,915 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:16:57,273 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:17:00,137 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:17:03,410 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:17:03,988 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:17:08,471 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:17:08,471 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:17:08,471 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:17:08,946 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:17:10,112 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:17:12,006 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:17:16,007 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:17:18,674 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:17:22,357 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:17:24,457 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:17:25,225 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:17:27,443 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:17:27,445 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:17:27,445 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:17:27,752 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:17:29,044 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:17:29,938 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:17:33,994 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:17:36,801 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:17:40,422 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:17:43,528 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:17:44,139 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:17:48,477 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:17:48,478 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:17:48,478 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:17:48,984 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:17:50,113 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:17:50,937 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:17:53,183 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:17:56,123 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:18:01,380 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:18:04,857 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:18:05,675 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:18:08,050 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:18:08,051 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:18:08,051 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:18:08,312 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:18:09,496 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:18:10,388 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:18:14,610 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:18:16,633 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:18:20,497 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:18:24,058 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:18:27,312 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:18:32,296 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:18:32,297 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:18:32,297 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:18:32,816 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:18:33,958 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:18:34,784 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:18:39,670 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:18:45,922 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:18:50,937 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:18:54,268 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:18:57,695 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:19:02,495 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:19:02,497 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:19:02,498 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:19:02,869 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:19:04,089 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:19:06,821 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:19:10,396 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:19:12,750 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:19:17,594 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:19:22,580 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:19:23,192 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:19:29,497 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:19:29,498 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:19:29,498 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:19:29,900 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:19:30,987 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:19:31,899 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:19:36,199 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:19:37,571 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:19:41,731 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:19:46,233 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:19:47,051 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:19:48,763 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:19:48,766 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:19:48,766 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:19:49,292 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:19:50,435 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:19:54,127 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:19:56,581 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:19:59,976 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:20:04,725 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:20:06,563 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:20:07,210 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:20:11,485 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:20:11,486 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:20:11,486 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:20:11,852 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:20:13,088 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:20:14,192 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:20:17,453 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:20:19,731 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:20:24,534 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:20:28,014 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:20:28,730 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:20:31,464 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:20:31,466 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:20:31,467 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:20:31,912 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:20:35,869 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:20:36,720 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:20:39,147 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:20:41,787 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:20:43,785 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:20:47,652 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:20:48,288 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:20:53,976 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:20:53,978 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:20:53,978 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:20:54,318 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:20:55,527 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:20:56,382 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:20:57,714 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:21:00,889 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:21:03,448 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:21:07,561 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:21:08,363 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:21:12,384 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:21:12,387 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:21:12,387 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:21:12,971 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:21:14,096 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:21:17,075 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:21:19,971 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:21:23,396 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:21:26,075 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:21:30,667 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:21:31,401 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:21:33,877 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:21:33,878 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:21:33,879 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:21:34,269 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:21:39,081 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:21:39,831 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:21:41,437 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:21:43,073 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:21:44,919 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:21:47,257 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:21:48,121 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:21:51,219 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:21:51,220 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:21:51,221 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:21:51,547 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:21:52,702 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:21:53,442 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:21:55,776 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:21:58,595 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:22:01,102 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:22:04,219 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:22:04,986 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:22:09,592 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:22:09,593 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:22:09,593 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:22:10,111 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:22:11,438 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:22:12,469 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:22:16,462 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:22:18,591 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:22:23,721 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:22:26,064 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:22:26,801 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:22:29,415 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:22:29,418 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:22:29,418 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:22:30,089 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:22:32,103 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:22:33,293 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:22:36,096 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:22:37,970 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:22:42,125 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:22:44,462 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:22:46,702 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:22:48,365 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:22:48,365 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:22:48,366 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:22:48,837 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:22:50,104 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:22:50,969 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:22:54,441 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:22:59,346 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:23:01,896 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:23:05,510 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:23:06,100 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:23:10,509 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:23:10,511 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:23:10,511 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:23:10,901 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:23:12,084 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:23:12,883 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:23:18,206 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:23:20,874 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:23:24,323 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:23:28,311 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:23:28,958 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:23:31,475 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:23:31,476 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:23:31,476 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:23:31,931 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:23:36,294 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:23:37,153 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:23:38,892 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:23:41,060 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:23:43,908 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:23:47,575 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:23:48,209 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:23:50,277 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:23:50,279 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:23:50,280 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:23:50,666 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:23:53,592 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:23:54,457 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:23:57,322 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:24:00,087 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:24:02,752 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:24:05,835 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:24:06,539 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:24:10,597 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:24:10,598 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:24:10,599 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:24:11,001 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:24:12,094 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:24:12,815 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:24:14,835 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:24:18,040 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:24:20,521 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:24:23,394 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:24:23,974 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:24:29,507 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:24:29,509 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:24:29,509 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:24:29,779 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:24:30,878 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:24:31,735 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:24:36,237 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:24:39,001 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:24:42,033 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:24:47,558 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:24:48,132 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:24:53,011 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:24:53,013 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:24:53,013 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:24:53,543 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:24:54,683 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:24:55,591 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:25:00,013 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:25:05,273 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:25:11,973 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:25:16,469 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:25:17,047 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:25:20,372 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:25:20,374 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:25:20,375 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:25:20,679 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:25:24,601 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:25:25,365 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:25:27,026 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:25:29,719 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:25:33,486 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:25:35,670 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:25:36,549 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:25:39,123 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:25:39,124 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:25:39,124 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:25:39,625 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:25:42,671 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:25:43,448 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:25:46,997 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:25:49,045 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:25:54,166 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:25:57,061 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:25:59,387 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:26:01,470 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:26:01,473 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:26:01,473 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:26:01,785 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:26:06,098 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:26:06,859 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:26:08,315 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:26:11,266 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:26:13,317 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:26:18,169 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:26:18,844 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:26:25,724 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:26:25,724 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:26:25,725 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:26:26,242 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:26:28,012 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:26:28,842 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:26:31,541 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:26:33,076 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:26:34,919 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:26:38,801 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:26:39,529 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:26:41,472 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:26:41,475 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:26:41,475 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:26:41,989 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:26:45,199 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:26:46,290 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:26:47,689 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:26:49,420 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:26:52,327 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:26:54,462 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:26:55,105 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:26:57,973 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:26:57,974 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:26:57,974 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:26:58,475 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:26:59,626 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:27:00,524 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:27:03,642 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:27:05,233 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:27:10,862 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:27:14,619 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:27:15,254 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:27:16,685 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:27:16,688 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:27:16,688 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:27:17,111 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:27:18,268 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:27:19,159 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:27:23,049 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:27:24,483 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:27:27,147 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:27:28,819 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:27:29,454 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:27:31,365 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:27:31,366 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:27:31,366 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:27:31,795 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:27:36,191 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:27:37,083 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:27:38,714 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:27:41,106 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:27:43,602 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:27:47,527 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:27:48,139 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:27:49,578 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:27:49,580 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:27:49,580 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:27:50,035 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:27:52,892 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:27:53,769 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:27:56,103 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:27:59,828 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:28:01,862 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:28:05,785 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:28:08,003 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:28:10,595 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:28:10,597 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:28:10,597 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:28:11,182 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:28:12,315 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:28:13,222 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:28:14,405 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:28:18,219 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:28:20,189 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:28:23,062 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:28:23,701 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:28:25,474 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:28:25,475 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:28:25,475 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:28:26,029 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:28:29,946 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:28:30,731 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:28:32,275 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:28:35,858 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:28:37,909 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:28:41,826 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:28:42,385 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:28:43,977 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:28:43,977 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:28:43,977 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:28:44,463 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:28:48,385 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:28:49,275 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:28:51,070 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:28:54,699 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:28:58,080 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:29:01,899 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:29:02,687 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:29:04,773 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:29:04,775 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:29:04,775 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:29:05,247 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:29:08,521 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:29:09,452 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:29:10,903 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:29:14,823 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:29:17,025 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:29:20,463 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:29:21,089 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:29:23,193 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:29:23,195 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:29:23,195 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:29:23,526 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:29:27,980 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:29:28,801 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:29:30,338 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:29:32,895 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:29:34,944 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:29:36,664 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:29:40,239 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:29:42,276 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:29:42,279 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:29:42,279 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:29:43,036 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:29:47,445 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:29:48,354 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:29:51,328 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:29:55,325 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:29:57,783 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:29:59,164 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:29:59,929 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:30:03,316 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:30:03,316 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:30:03,317 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:30:03,628 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:30:04,787 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:30:05,564 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:30:09,045 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:30:10,700 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:30:15,472 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:30:19,077 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:30:21,498 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:30:23,978 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:30:23,981 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:30:23,981 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:30:24,414 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:30:28,395 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:30:29,122 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:30:30,656 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:30:35,363 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:30:38,449 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:30:42,271 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:30:44,987 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:30:46,973 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:30:46,974 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:30:46,974 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:30:47,255 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:30:48,424 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:30:52,055 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:30:53,076 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:30:56,537 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:30:59,770 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:31:02,563 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:31:03,421 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:31:05,573 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:31:05,575 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:31:05,575 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:31:06,086 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:31:10,015 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:31:11,006 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:31:12,672 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:31:17,547 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:31:19,595 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:31:22,765 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:31:23,462 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:31:25,480 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:31:25,481 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:31:25,481 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:31:25,752 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:31:29,783 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:31:30,663 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:31:33,117 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:31:36,189 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:31:39,156 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:31:41,567 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:31:42,333 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:31:44,174 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:31:44,176 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:31:44,176 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:31:44,689 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:31:48,397 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:31:49,163 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:31:53,084 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:31:56,284 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:31:59,776 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:32:02,271 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:32:02,921 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:32:05,475 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:32:05,476 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:32:05,476 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:32:05,828 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:32:06,960 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:32:07,831 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:32:12,442 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:32:15,005 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:32:17,148 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:32:19,785 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:32:20,489 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:32:23,575 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:32:23,576 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:32:23,577 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:32:24,013 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:32:25,183 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:32:25,985 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:32:29,235 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:32:31,384 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:32:35,476 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:32:37,064 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:32:37,938 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:32:41,090 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:32:41,092 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:32:41,092 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:32:41,727 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:32:42,883 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:32:43,775 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:32:46,950 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:32:48,792 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:32:53,912 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:32:55,965 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:32:56,634 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:32:59,758 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:32:59,760 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:32:59,761 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:33:00,123 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:33:01,247 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:33:02,206 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:33:04,931 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:33:08,351 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:33:12,444 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:33:17,183 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:33:17,776 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:33:22,493 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:33:22,494 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:33:22,494 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:33:22,762 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:33:23,899 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:33:24,838 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:33:26,680 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:33:29,813 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:33:33,338 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:33:36,402 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:33:37,040 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:33:42,502 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:33:42,504 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:33:42,504 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:33:42,890 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:33:43,966 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:33:44,721 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:33:46,445 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:33:49,821 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:33:52,080 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:33:54,843 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:33:55,678 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:33:57,381 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:33:57,382 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:33:57,382 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:33:57,779 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:34:01,905 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:34:02,757 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:34:04,630 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:34:07,946 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:34:12,866 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:34:19,208 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:34:19,869 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:34:21,476 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:34:21,478 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:34:21,478 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:34:21,987 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:34:26,585 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:34:27,393 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:34:31,085 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:34:33,749 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:34:37,439 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:34:43,236 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:34:43,916 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:34:48,395 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:34:48,396 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:34:48,396 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:34:48,740 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:34:49,886 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:34:50,618 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:34:52,082 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:34:55,773 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:34:58,125 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:35:01,318 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:35:02,012 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:35:04,175 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:35:04,177 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:35:04,177 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:35:04,668 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:35:07,238 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:35:07,991 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:35:10,411 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:35:13,794 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:35:22,496 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:35:26,165 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:35:26,900 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:35:29,370 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:35:29,371 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:35:29,371 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:35:29,743 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:35:33,535 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:35:34,372 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:35:36,117 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:35:39,802 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:35:42,128 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:35:44,167 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:35:46,870 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:35:51,379 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:35:51,381 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:35:51,381 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:35:51,889 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:35:53,523 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:35:54,343 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:35:58,237 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:36:00,079 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:36:02,863 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:36:05,367 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:36:06,119 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:36:09,354 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:36:09,355 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:36:09,356 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:36:09,708 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:36:10,836 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:36:11,856 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:36:15,827 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:36:17,487 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:36:20,354 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:36:23,820 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:36:24,400 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:36:29,420 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:36:29,421 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:36:29,421 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:36:29,868 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:36:31,086 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:36:31,915 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:36:35,906 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:36:38,056 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:36:40,528 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:36:42,359 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:36:43,001 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:36:47,189 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:36:47,190 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:36:47,190 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:36:47,674 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:36:48,841 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:36:49,722 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:36:53,104 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:36:55,051 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:36:58,836 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:37:01,944 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:37:02,727 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:37:05,249 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:37:05,251 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:37:05,252 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:37:05,588 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:37:06,694 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:37:07,540 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:37:08,663 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:37:11,331 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:37:13,888 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:37:18,117 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:37:18,714 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:37:21,556 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:37:21,557 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:37:21,557 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:37:21,980 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:37:25,988 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:37:27,301 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:37:28,837 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:37:31,226 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:37:33,753 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:37:37,504 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:37:38,158 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:37:43,590 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:37:43,591 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:37:43,591 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:37:44,100 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:37:45,258 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:37:46,107 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:37:49,218 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:37:51,060 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:37:55,669 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:38:00,290 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:38:00,893 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:38:04,458 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:38:04,459 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:38:04,459 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:38:04,782 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:38:08,377 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:38:09,184 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:38:10,718 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:38:14,203 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:38:16,149 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:38:19,004 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:38:19,628 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:38:21,387 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:38:21,388 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:38:21,389 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:38:21,850 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:38:25,801 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:38:26,595 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:38:28,333 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:38:32,124 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:38:33,866 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:38:38,378 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:38:39,049 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:38:41,360 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:38:41,360 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:38:41,360 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:38:41,690 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:38:44,938 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:38:45,744 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:38:47,750 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:38:52,298 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:38:54,138 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:38:58,249 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:38:58,857 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:39:01,576 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:39:01,580 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:39:01,581 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:39:02,436 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:39:06,157 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:39:06,996 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:39:08,679 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:39:12,470 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:39:14,411 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:39:16,047 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:39:16,771 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:39:18,354 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:39:18,355 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:39:18,355 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:39:18,820 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:39:19,973 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:39:20,868 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:39:25,368 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:39:27,818 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:39:31,211 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:39:35,648 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:39:36,421 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:39:39,924 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:39:39,925 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:39:39,926 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:39:40,434 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:39:41,740 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:39:42,549 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:39:46,013 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:39:48,715 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:39:52,816 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:39:56,645 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:39:59,785 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:40:02,263 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:40:02,264 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:40:02,264 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:40:02,751 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:40:06,773 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:40:07,544 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:40:09,366 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:40:12,987 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:40:16,163 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:40:19,552 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:40:20,360 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:40:24,711 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:40:24,713 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:40:24,713 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:40:25,280 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:40:26,368 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:40:27,109 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:40:29,119 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:40:32,196 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:40:34,882 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:40:37,950 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:40:38,532 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:40:42,882 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:40:42,882 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:40:42,883 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:40:43,506 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:40:44,667 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:40:45,556 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:40:46,986 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:40:50,005 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:40:52,622 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:41:01,718 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:41:02,388 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:41:05,016 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:41:05,018 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:41:05,019 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:41:05,437 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:41:08,841 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:41:12,086 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:41:13,517 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:41:15,865 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:41:19,703 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:41:22,253 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:41:25,694 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:41:28,268 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:41:28,269 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:41:28,269 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:41:28,768 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:41:31,252 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:41:32,147 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:41:34,706 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:41:37,874 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:41:40,597 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:41:43,658 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:41:44,330 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:41:49,475 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:41:49,477 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:41:49,477 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:41:49,832 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:41:51,144 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:41:52,012 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:41:56,016 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:41:58,155 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:42:01,023 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:42:03,043 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:42:06,389 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:42:08,271 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:42:08,272 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:42:08,272 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:42:08,702 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:42:10,032 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:42:12,798 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:42:14,743 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:42:19,662 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:42:22,423 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:42:24,585 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:42:25,187 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:42:31,273 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:42:31,275 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:42:31,275 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:42:31,659 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:42:33,239 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:42:34,099 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:42:38,472 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:42:40,034 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:42:43,517 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:42:45,344 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:42:46,182 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:42:49,356 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:42:49,357 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:42:49,357 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:42:49,886 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:42:51,037 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:42:51,856 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:42:54,990 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:42:58,056 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:42:59,802 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:43:01,945 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:43:02,514 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:43:07,575 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:43:07,577 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:43:07,577 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:43:08,097 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:43:09,343 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:43:10,130 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:43:14,111 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:43:16,287 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:43:19,370 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:43:21,150 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:43:21,895 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:43:25,303 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:43:25,303 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:43:25,304 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:43:25,607 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:43:26,693 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:43:27,554 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:43:30,931 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:43:32,425 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:43:34,002 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:43:37,545 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:43:38,406 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:43:39,756 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:43:39,757 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:43:39,757 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:43:40,119 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:43:42,914 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:43:43,732 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:43:45,163 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:43:50,182 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:43:52,886 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:43:55,794 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:43:56,389 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:43:59,460 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:43:59,462 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:43:59,462 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:44:00,117 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:44:02,607 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:44:03,395 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:44:04,904 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:44:08,204 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:44:10,968 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:44:13,103 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:44:14,052 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:44:19,561 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:44:19,562 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:44:19,563 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:44:19,985 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:44:21,142 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:44:22,032 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:44:25,989 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:44:27,674 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:44:31,015 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:44:34,045 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:44:34,789 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:44:37,280 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:44:37,282 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:44:37,283 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:44:37,707 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:44:39,162 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:44:40,057 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:44:44,252 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:44:45,992 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:44:50,600 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:44:52,618 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:44:53,262 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:44:55,653 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:44:55,654 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:44:55,654 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:44:55,972 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:45:00,131 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:45:01,352 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:45:03,400 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:45:07,087 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:45:09,337 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:45:13,543 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:45:14,456 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:45:15,964 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:45:15,966 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:45:15,967 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:45:16,406 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:45:20,248 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:45:21,122 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:45:22,548 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:45:23,983 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:45:26,439 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:45:28,346 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:45:29,100 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:45:31,965 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:45:31,966 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:45:31,966 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:45:32,380 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 18:45:33,465 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 18:45:34,328 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:45:35,757 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:45:38,316 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:45:40,981 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:45:45,444 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 18:45:46,204 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 18:45:51,506 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 18:45:51,508 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 18:45:51,508 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 18:45:53,775 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 19:02:15,786 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 286, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/socket.py", line 706, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/ssl.py", line 1314, in recv_into
    return self.read(nbytes, buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/ssl.py", line 1166, in read
    return self._sslobj.read(len, buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TimeoutError: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 39, in reraise
    raise value
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 713, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)
2025-01-02 19:02:17,325 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 19:02:18,307 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 19:02:20,249 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 19:02:22,845 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 19:02:25,694 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 19:02:29,372 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 19:02:29,953 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 19:02:34,560 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 19:02:34,562 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 19:02:34,562 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 19:02:35,039 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 19:02:36,926 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 19:02:38,454 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 19:03:08,681 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 19:03:16,822 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 19:26:28,303 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 286, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/socket.py", line 706, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/ssl.py", line 1314, in recv_into
    return self.read(nbytes, buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/ssl.py", line 1166, in read
    return self._sslobj.read(len, buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TimeoutError: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 39, in reraise
    raise value
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 713, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)
2025-01-02 19:26:29,792 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 19:26:32,056 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 19:26:32,774 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 19:41:34,039 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 20:56:51,313 - openinference.instrumentation.llama_index._handler - WARNING - Open span is missing for event.span_id='OpenAI.astream_chat-4ce8174d-06af-4c09-a12e-de2d764b8005', event.id_='227662e2-486c-4139-a863-d7a39c1f3ca8'
2025-01-02 20:56:51,316 - src.agent.evaluation.eval_util - WARNING - Error processing sample 849: 
2025-01-02 20:56:51,347 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 20:56:51,349 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 20:56:51,349 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 20:56:51,929 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 20:56:51,980 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-02 20:56:54,260 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 20:56:55,460 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 20:57:00,435 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 20:57:02,115 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 20:57:04,466 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 20:57:06,474 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 20:57:07,144 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 20:57:08,770 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 20:57:08,771 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 20:57:08,771 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 20:57:09,124 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 20:57:10,412 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:01:48,879 - opentelemetry.sdk.trace.export - ERROR - Exception while exporting Span.
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/http/client.py", line 286, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/socket.py", line 706, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/ssl.py", line 1314, in recv_into
    return self.read(nbytes, buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/ssl.py", line 1166, in read
    return self._sslobj.read(len, buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TimeoutError: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/util/util.py", line 39, in reraise
    raise value
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/urllib3/connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py", line 113, in on_end
    self.span_exporter.export((span,))
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/requests/adapters.py", line 713, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)
2025-01-02 21:01:49,897 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:01:51,793 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:01:54,668 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:01:57,351 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:02:01,356 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:02:02,103 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:02:04,361 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:02:04,364 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:02:04,364 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:02:04,875 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:02:08,527 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:02:11,035 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:02:12,795 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:02:16,312 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:02:18,834 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:02:21,597 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:02:22,181 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:02:26,892 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:02:26,895 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:02:26,895 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:02:27,254 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:02:28,486 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:02:29,294 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:02:30,069 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:02:32,144 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:02:34,753 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:02:37,654 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:02:38,507 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:02:41,475 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:02:41,477 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:02:41,477 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:02:42,041 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:02:43,825 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:02:44,865 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:02:46,882 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:02:49,000 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:02:51,038 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:02:53,858 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:02:58,569 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:03:02,768 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:03:02,770 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:03:02,770 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:03:03,999 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:03:05,167 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:03:06,270 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:03:09,936 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:03:14,519 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:03:16,999 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:03:19,178 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:03:21,099 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:03:23,270 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:03:23,274 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:03:23,274 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:03:23,826 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:03:27,864 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:03:28,681 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:03:30,318 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:03:32,162 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:03:34,517 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:03:36,132 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:03:36,869 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:03:41,394 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:03:41,396 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:03:41,396 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:03:42,049 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:03:43,159 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:03:44,055 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:03:45,644 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:03:48,252 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:03:51,022 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:03:54,899 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:03:55,504 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:03:57,772 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:03:57,773 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:03:57,773 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:03:58,304 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:04:02,815 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:04:03,696 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:04:05,440 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:04:08,462 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:04:11,897 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:04:15,359 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:04:16,173 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:04:18,318 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:04:18,319 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:04:18,320 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:04:18,949 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:04:20,022 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:04:20,902 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:04:22,537 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:04:25,307 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:04:26,677 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:04:31,354 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:04:32,060 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:04:34,283 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:04:34,283 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:04:34,284 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:04:35,031 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:04:36,086 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:04:36,877 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:04:38,102 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:04:40,867 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:04:43,495 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:04:47,456 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:04:48,139 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:04:49,266 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:04:49,267 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:04:49,267 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:04:49,880 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:04:54,137 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:04:55,516 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:04:57,461 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:05:05,236 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:05:07,497 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:05:11,355 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:05:11,951 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:05:13,172 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:05:13,173 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:05:13,173 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:05:13,734 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:05:14,758 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:05:15,561 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:05:19,066 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:05:21,182 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:05:26,542 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:05:28,958 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:05:29,728 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:05:32,574 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:05:32,577 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:05:32,577 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:05:33,098 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:05:34,199 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:05:35,371 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:05:39,954 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:05:42,710 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:05:45,906 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:05:49,157 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:05:50,415 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:05:52,301 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:05:52,302 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:05:52,302 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:05:53,025 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:05:54,273 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:05:55,037 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:05:58,296 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:06:00,698 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:06:03,943 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:06:06,311 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:06:07,410 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:06:11,384 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:06:11,386 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:06:11,386 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:06:11,851 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:06:13,954 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:06:14,774 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:06:16,515 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:06:18,868 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:06:21,102 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:06:25,357 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:06:26,068 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:06:27,767 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:06:27,768 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:06:27,768 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:06:28,677 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:06:32,381 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:06:33,222 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:06:35,476 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:06:39,244 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:06:41,699 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:06:45,612 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:06:46,234 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:06:49,460 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:06:49,463 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:06:49,463 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:06:50,413 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:06:51,536 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:06:52,457 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:06:54,838 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:06:58,213 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:07:01,879 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:07:04,610 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:07:05,181 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:07:07,589 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:07:07,590 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:07:07,591 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:07:08,433 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:07:11,318 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:07:12,224 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:07:17,854 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:07:19,800 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:07:21,899 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:07:24,216 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:07:24,834 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:07:28,166 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:07:28,168 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:07:28,168 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:07:29,221 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:07:32,537 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:07:33,486 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:07:34,646 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:07:36,200 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:07:39,871 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:07:45,599 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:07:49,245 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:07:51,984 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:07:51,985 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:07:51,985 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:07:52,297 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:07:53,418 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:07:54,167 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:07:55,636 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:07:58,708 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:08:00,862 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:08:05,533 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:08:06,185 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:08:08,167 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:08:08,168 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:08:08,169 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:08:09,158 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:08:11,870 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:08:12,743 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:08:14,071 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:08:18,061 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:08:23,695 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:08:26,156 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:08:29,638 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:08:31,371 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:08:31,373 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:08:31,373 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:08:32,058 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:08:35,038 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:08:36,135 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:08:38,544 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:08:42,026 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:08:43,867 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:08:46,570 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:08:47,353 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:08:50,175 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:08:50,177 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:08:50,177 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:08:51,039 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:08:54,500 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:08:55,443 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:08:56,670 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:08:59,310 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:09:01,684 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:09:06,492 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:09:07,213 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:09:09,372 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:09:09,373 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:09:09,373 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:09:09,984 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:09:13,969 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:09:15,042 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:09:16,332 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:09:19,248 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:09:21,389 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:09:26,155 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:09:26,938 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:09:29,033 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:09:29,035 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:09:29,036 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:09:29,839 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:09:31,073 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:09:33,105 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:09:34,970 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:09:37,117 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:09:40,541 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:09:43,359 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:09:44,254 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:09:46,279 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:09:46,280 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:09:46,281 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:09:47,015 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:09:48,130 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:09:49,121 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:09:50,484 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:09:54,221 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:09:56,166 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:09:59,027 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:09:59,780 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:10:02,166 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:10:02,169 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:10:02,169 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:10:02,505 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:10:06,397 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:10:07,131 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:10:08,466 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:10:11,526 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:10:13,310 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:10:17,860 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:10:18,589 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:10:19,771 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:10:19,772 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:10:19,772 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:10:20,131 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:10:23,148 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:10:23,972 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:10:25,357 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:10:29,754 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:10:31,901 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:10:34,566 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:10:35,282 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:10:37,070 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:10:37,073 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:10:37,073 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:10:37,534 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:10:41,719 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:10:42,803 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:10:44,477 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:10:48,121 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:10:50,491 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:10:53,776 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:10:54,636 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:10:56,179 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:10:56,180 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:10:56,181 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:10:59,453 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:11:00,571 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:11:01,801 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:11:03,638 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:11:07,028 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:11:09,090 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:11:12,556 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:11:13,478 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:11:15,469 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:11:15,472 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:11:15,472 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:11:16,039 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:11:19,726 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:11:20,956 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:11:23,104 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:11:26,041 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:11:28,412 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:11:31,913 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:11:32,557 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:11:37,075 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:11:37,075 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:11:37,076 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:11:37,648 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:11:39,084 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:11:40,412 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:11:41,941 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:11:44,400 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:11:46,657 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:11:48,558 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:11:49,364 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:11:53,176 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:11:53,178 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:11:53,179 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:11:53,622 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:11:55,586 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:11:56,690 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:11:58,286 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:12:03,643 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:12:05,740 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:12:08,556 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:12:09,216 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:12:11,573 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:12:11,574 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:12:11,574 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:12:12,265 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:12:16,757 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:12:17,610 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:12:19,525 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:12:23,414 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:12:25,084 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:12:27,892 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:12:28,536 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:12:30,373 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:12:30,376 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:12:30,376 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:12:34,477 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:12:35,580 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:12:36,425 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:12:40,933 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:12:43,182 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:12:45,950 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:12:47,761 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:12:48,608 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:12:51,676 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:12:51,677 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:12:51,677 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:12:52,356 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:12:53,457 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:12:54,552 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:12:58,829 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:13:00,842 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:13:03,176 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:13:05,343 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:13:06,117 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:13:11,804 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:13:11,806 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:13:11,806 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:13:12,651 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:13:13,784 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:13:14,619 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:13:19,121 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:13:21,173 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:13:22,997 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:13:25,481 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:13:26,192 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:13:28,677 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:13:28,678 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:13:28,678 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:13:29,008 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:13:32,988 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:13:34,104 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:13:36,328 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:13:42,179 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:13:44,722 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:13:46,331 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:13:47,182 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:13:52,686 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:13:52,688 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:13:52,689 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:13:53,349 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:13:54,654 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:13:55,761 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:13:57,526 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:14:01,522 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:14:03,465 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:14:07,056 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:14:07,867 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:14:09,768 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:14:09,769 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:14:09,769 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:14:10,739 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:14:14,724 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:14:15,959 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:14:17,436 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:14:21,077 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:14:23,534 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:14:25,860 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:14:26,710 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:14:30,178 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:14:30,181 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:14:30,181 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:14:30,501 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:14:33,139 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:14:34,288 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:14:36,212 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:14:39,033 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:14:41,456 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:14:43,956 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:14:44,837 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:14:48,879 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:14:48,880 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:14:48,880 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:14:49,435 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:14:51,301 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:14:52,374 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:14:53,835 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:14:56,917 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:14:59,482 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:15:02,557 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:15:03,471 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:15:05,168 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:15:05,171 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:15:05,171 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:15:06,136 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:15:08,619 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:15:09,819 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:15:14,522 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:15:17,076 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:15:20,984 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:15:22,857 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:15:23,750 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:15:26,361 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:15:26,362 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:15:26,362 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:15:26,924 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:15:28,059 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:15:29,226 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:15:32,908 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:15:35,524 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:15:38,595 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:15:43,521 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:15:44,282 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:15:46,278 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:15:46,281 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:15:46,281 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:15:47,098 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:15:50,563 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:15:51,399 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:15:52,635 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:15:56,004 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:15:58,869 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:16:02,441 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:16:03,059 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:16:08,391 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:16:08,392 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:16:08,393 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:16:08,908 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:16:10,334 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:16:11,772 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:16:14,383 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:16:16,697 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:16:20,682 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:16:25,073 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:16:25,800 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:16:28,270 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:16:28,271 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:16:28,272 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:16:29,182 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:16:33,274 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:16:34,136 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:16:38,867 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:16:44,232 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:16:47,375 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:16:50,401 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:16:51,055 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:16:56,279 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:16:56,280 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:16:56,281 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:16:56,998 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:16:59,082 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:16:59,816 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:17:02,055 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:17:03,695 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:17:05,537 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:17:08,817 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:17:09,396 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:17:11,667 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:17:11,670 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:17:11,670 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:17:12,088 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:17:16,064 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:17:16,878 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:17:19,202 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:17:24,787 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:17:28,062 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:17:30,568 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:17:31,352 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:17:34,083 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:17:34,083 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:17:34,084 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:17:34,821 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:17:36,766 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:17:38,202 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:17:40,247 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:17:42,298 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:17:46,689 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:17:52,269 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:17:52,914 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:17:57,783 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:17:57,785 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:17:57,785 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:17:58,479 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:17:59,599 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:18:00,935 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:18:04,722 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:18:06,914 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:18:10,999 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:18:12,699 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:18:13,532 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:18:15,279 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:18:15,281 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:18:15,281 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:18:16,447 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:18:18,572 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:18:19,678 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:18:21,617 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:18:24,997 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:18:26,840 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:18:31,186 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:18:31,961 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:18:34,369 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:18:34,370 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:18:34,371 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:18:34,933 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:18:38,704 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:18:39,833 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:18:41,694 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:18:43,431 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:18:47,526 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:18:49,557 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:18:50,291 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:18:53,791 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:18:53,792 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:18:53,792 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:18:54,493 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:18:55,918 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:18:56,719 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:19:01,045 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:19:02,885 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:19:07,391 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:19:10,260 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:19:11,067 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:19:14,023 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:19:14,026 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:19:14,026 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:19:14,461 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:19:15,711 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:19:16,521 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:19:17,936 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:19:20,090 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:19:22,385 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:19:29,275 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:19:29,963 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:19:31,629 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:19:31,630 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:19:31,630 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:19:32,381 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:19:34,263 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:19:35,450 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:19:39,443 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:19:41,900 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:19:44,302 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:19:47,989 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:19:48,844 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:19:51,583 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:19:51,585 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:19:51,585 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:19:52,042 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:19:53,150 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:19:53,928 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:19:55,825 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:19:57,494 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:19:59,977 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:20:02,994 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:20:03,715 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:20:05,656 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:20:05,656 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:20:05,657 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:20:06,382 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:20:07,474 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:20:08,760 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:20:10,472 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:20:12,417 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:20:14,670 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:20:17,973 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:20:18,684 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:20:21,655 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:20:21,656 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:20:21,656 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:20:22,348 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:20:23,484 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:20:24,512 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:20:26,343 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:20:28,596 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:20:31,054 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:20:33,429 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:20:34,121 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:20:36,150 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:20:36,152 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:20:36,152 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:20:36,586 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:20:37,914 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:20:39,043 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:20:40,573 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:20:42,830 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:20:44,878 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:20:46,699 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:20:47,539 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:20:49,316 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:20:49,317 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:20:49,317 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:20:50,414 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:20:52,656 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:20:53,375 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:20:55,016 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:20:56,755 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:21:00,736 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:21:03,888 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:21:04,550 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:21:05,988 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:21:05,989 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:21:05,989 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:21:06,785 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:21:07,941 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:21:09,017 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:21:10,483 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:21:12,242 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:21:14,679 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:21:17,008 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:21:18,159 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:21:20,964 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:21:20,967 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:21:20,967 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:21:21,657 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:21:22,837 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:21:23,690 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:21:25,636 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:21:27,954 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:21:29,779 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:21:32,296 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:21:32,937 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:21:35,410 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:21:35,411 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:21:35,411 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:21:35,880 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:21:37,037 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:21:38,129 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:21:39,766 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:21:42,020 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:21:43,859 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:21:46,019 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:21:46,711 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:21:49,129 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:21:49,130 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:21:49,130 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:21:49,807 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:21:51,153 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:21:51,953 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:21:53,452 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:21:56,575 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:21:58,710 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:22:03,359 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:22:04,034 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:22:05,902 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:22:05,904 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:22:05,904 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:22:06,394 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:22:08,641 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:22:09,462 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:22:10,896 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:22:12,554 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:22:14,886 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:22:16,625 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:22:17,246 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:22:19,221 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:22:19,222 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:22:19,222 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:22:20,018 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:22:21,063 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:22:21,841 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:22:23,801 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:22:25,539 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:22:27,658 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:22:29,376 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:22:30,046 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:22:31,650 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:22:31,651 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:22:31,651 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:22:32,445 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:22:33,932 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:22:35,064 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:22:36,620 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:22:39,053 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:22:41,348 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:22:43,241 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:22:44,042 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:22:46,643 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:22:46,645 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:22:46,646 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:22:47,390 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:22:48,504 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:22:49,586 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:22:51,039 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:22:52,775 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:22:54,826 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:22:56,446 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:22:57,181 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:22:58,465 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:22:58,466 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:22:58,466 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:22:58,926 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:23:00,085 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:23:00,878 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:23:04,660 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:23:06,591 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:23:08,365 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:23:10,109 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:23:10,828 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:23:13,210 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:23:13,211 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:23:13,211 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:23:13,922 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:23:15,018 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:23:15,851 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:23:17,487 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:23:19,374 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:23:22,201 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:23:26,690 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:23:27,284 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:23:29,489 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:23:29,491 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:23:29,491 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:23:30,401 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:23:31,540 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:23:32,451 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:23:34,188 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:23:36,478 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:23:38,591 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:23:40,692 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:23:41,281 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:23:42,871 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:23:42,872 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:23:42,872 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:23:43,591 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:23:44,808 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:23:45,663 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:23:47,193 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:23:49,551 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:23:52,010 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:23:54,283 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:23:54,977 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:23:57,134 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:23:57,135 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:23:57,135 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:23:57,846 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:23:59,585 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:24:00,685 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:24:04,289 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:24:06,549 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:24:08,906 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:24:10,684 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:24:11,465 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:24:17,497 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:24:17,499 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:24:17,499 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:24:18,021 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:24:19,963 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:24:20,695 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:24:21,781 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:24:23,229 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:24:24,879 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:24:26,793 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:24:27,339 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:24:29,355 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:24:29,356 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:24:29,356 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:24:30,084 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:24:31,269 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:24:32,768 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:24:34,121 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:24:36,044 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:24:37,890 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:24:40,455 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:24:41,108 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:24:43,953 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:24:43,954 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:24:43,954 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:24:44,852 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:24:46,076 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:24:47,005 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:24:48,028 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:24:49,463 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:24:50,892 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:24:52,892 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:24:53,493 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:24:55,105 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:24:55,107 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:24:55,108 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:24:56,115 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:24:57,543 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:24:58,673 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:24:59,945 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:25:03,385 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:25:06,048 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:25:09,003 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:25:09,711 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:25:11,894 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:25:11,895 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:25:11,896 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:25:12,501 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:25:13,723 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:25:14,857 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:25:16,186 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:25:17,696 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:25:20,177 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:25:21,903 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:25:22,861 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:25:24,405 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:25:24,406 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:25:24,406 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:25:25,096 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:25:26,188 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:25:27,353 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:25:28,577 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:25:30,108 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:25:32,156 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:25:33,804 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:25:34,719 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:25:37,335 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:25:37,338 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:25:37,338 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:25:37,794 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:25:38,888 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:25:42,181 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:25:43,658 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:25:46,289 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:25:48,645 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:25:50,102 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:25:50,893 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:25:52,593 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:25:52,593 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:25:52,594 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:25:53,358 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:25:54,455 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:25:55,613 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:25:57,663 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:25:59,632 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:26:02,371 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:26:04,595 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:26:05,339 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:26:07,375 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:26:07,376 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:26:07,376 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:26:08,312 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:26:09,392 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:26:10,255 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:26:11,688 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:26:13,328 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:26:14,761 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:26:16,210 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:26:16,912 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:26:18,141 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:26:18,143 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:26:18,144 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:26:18,652 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:26:19,689 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:26:20,802 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:26:22,238 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:26:24,189 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:26:25,921 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:26:27,329 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:26:28,178 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:26:29,380 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:26:29,381 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:26:29,381 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:26:30,125 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:26:31,198 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:26:32,445 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:26:34,014 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:26:36,162 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:26:38,108 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:26:39,559 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:26:40,301 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:26:42,718 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:26:42,719 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:26:42,719 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:26:43,539 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:26:44,656 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:26:45,416 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:26:46,626 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:26:48,451 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:26:50,292 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:26:51,866 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:26:52,420 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:26:54,346 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:26:54,348 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:26:54,348 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:26:55,446 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:26:56,642 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:26:57,770 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:26:59,309 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:27:01,251 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:27:04,530 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:27:06,809 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:27:07,463 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:27:09,278 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:27:09,278 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:27:09,278 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:27:10,265 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:27:11,339 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:27:12,518 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:27:13,948 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:27:15,687 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:27:17,625 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:27:19,296 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:27:20,092 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:27:22,514 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:27:22,515 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:27:22,515 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:27:23,166 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:27:24,416 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:27:25,317 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:27:26,943 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:27:29,618 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:27:32,279 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:27:34,937 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:27:35,660 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:27:39,057 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:27:39,060 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:27:39,060 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:27:39,553 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:27:40,687 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:27:41,805 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:27:43,747 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:27:50,096 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:27:51,881 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:27:53,626 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:27:54,370 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:27:55,836 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:27:55,838 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:27:55,838 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:27:57,222 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:27:58,662 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:27:59,929 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:28:01,263 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:28:04,330 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:28:06,274 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:28:08,893 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:28:09,762 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:28:13,669 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:28:13,671 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:28:13,671 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:28:14,165 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:28:15,250 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:28:16,313 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:28:17,849 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:28:20,203 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:28:21,942 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:28:24,374 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:28:25,049 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:28:27,094 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:28:27,096 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:28:27,096 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:28:27,408 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:28:29,086 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:28:30,346 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:28:32,186 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:28:34,851 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:28:36,692 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:28:38,200 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:28:39,249 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:28:40,732 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:28:40,733 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:28:40,733 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:28:41,708 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:28:44,129 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:28:45,705 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:28:46,694 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:28:48,759 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:28:51,230 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:28:54,040 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:28:54,819 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:28:57,261 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:28:57,263 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:28:57,264 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:28:58,097 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:28:59,523 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:29:00,756 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:29:05,771 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:29:11,204 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:29:13,044 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:29:14,798 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:29:15,498 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:29:18,373 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:29:18,374 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:29:18,374 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:29:18,882 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:29:19,917 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:29:20,930 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:29:22,670 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:29:25,332 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:29:27,683 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:29:29,285 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:29:29,989 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:29:33,175 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:29:33,176 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:29:33,177 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:29:34,423 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:29:35,516 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:29:36,696 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:29:38,413 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:29:41,408 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:29:43,589 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:29:46,539 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:29:47,319 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:29:49,637 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:29:49,640 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:29:49,640 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:29:49,966 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:29:51,084 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:29:51,960 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:29:53,223 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:29:55,663 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:29:58,512 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:30:00,605 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:30:01,378 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:30:03,837 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:30:03,838 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:30:03,838 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:30:04,964 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:30:06,396 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:30:07,418 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:30:09,053 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:30:10,607 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:30:13,050 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:30:15,913 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:30:16,668 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:30:19,325 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:30:19,326 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:30:19,326 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:30:20,116 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:30:21,226 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:30:22,269 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:30:23,703 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:30:25,349 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:30:31,589 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:30:33,441 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:30:34,249 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:30:35,841 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:30:35,844 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:30:35,844 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:30:36,400 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:30:37,490 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:30:38,241 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:30:40,083 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:30:41,927 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:30:44,013 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:30:46,739 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:30:47,466 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:30:49,663 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:30:49,663 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:30:49,664 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:30:50,068 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:30:51,320 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:30:52,479 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:30:53,757 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:30:56,066 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:30:58,109 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:31:00,409 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:31:01,182 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:31:03,302 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:31:03,303 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:31:03,303 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:31:03,638 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:31:04,755 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:31:06,302 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:31:07,945 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:31:10,845 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:31:14,141 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:31:16,445 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:31:17,258 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:31:19,097 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:31:19,099 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:31:19,099 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:31:19,818 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:31:20,927 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:31:22,382 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:31:24,322 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:31:26,166 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:31:28,627 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:31:30,411 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:31:31,163 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:31:33,632 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:31:33,633 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:31:33,633 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:31:34,052 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:31:35,111 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:31:36,306 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:31:37,313 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:31:39,168 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:31:41,115 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:31:42,902 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:31:44,130 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:31:45,658 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:31:45,659 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:31:45,659 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:31:46,548 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:31:47,597 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:31:48,799 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:31:50,344 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:31:51,923 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:32:03,950 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:32:05,639 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:32:06,411 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:32:08,382 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:32:08,384 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:32:08,385 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:32:08,973 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:32:10,813 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:32:11,624 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:32:12,858 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:32:14,502 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:32:16,551 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:32:18,688 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:32:19,414 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:32:20,801 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:32:20,802 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:32:20,802 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:32:30,759 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:32:31,867 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:32:32,937 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:32:34,366 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:32:36,107 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:32:37,848 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:32:39,878 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:32:40,613 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:32:43,190 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:32:43,194 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:32:43,195 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:32:43,993 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:32:45,146 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:32:45,939 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:32:47,272 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:32:49,010 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:32:51,053 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:32:52,548 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:32:53,207 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:32:55,620 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:32:55,622 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:32:55,622 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:32:56,644 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:32:57,778 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:32:58,540 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:32:59,868 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:33:04,061 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:33:06,112 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:33:07,717 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:33:08,290 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:33:09,887 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:33:09,887 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:33:09,887 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:33:10,718 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:33:11,861 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:33:12,667 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:33:14,408 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:33:16,043 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:33:17,469 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:33:19,515 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:33:20,241 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:33:21,729 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:33:21,732 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:33:21,732 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:33:22,373 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:33:23,428 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:33:24,196 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:33:25,670 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:33:28,347 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:33:31,712 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:33:34,289 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:33:36,322 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:33:39,195 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:33:39,195 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:33:39,196 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:33:39,596 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:33:41,029 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:33:41,852 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:33:43,284 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:33:45,030 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:33:46,869 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:33:48,246 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:33:48,914 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:33:50,627 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:33:50,628 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:33:50,628 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:33:51,891 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:33:53,008 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:33:53,835 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:33:55,450 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:33:57,106 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:33:59,055 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:34:02,677 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:34:03,265 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:34:05,893 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:34:05,895 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:34:05,896 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:34:06,326 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:34:07,480 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:34:08,375 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:34:09,806 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:34:11,291 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:34:13,697 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:34:16,957 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:34:17,693 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:34:21,241 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:34:21,246 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:34:21,247 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:34:21,989 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:34:23,834 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:34:24,658 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:34:25,780 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:34:27,421 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:34:28,956 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:34:30,867 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:34:31,516 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:34:33,472 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:34:33,474 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:34:33,474 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:34:34,350 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:34:35,849 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:34:36,640 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:34:38,279 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:34:40,018 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:34:41,553 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:34:43,197 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:34:43,907 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:34:45,053 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:34:45,056 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:34:45,056 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:34:46,266 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:34:47,348 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:34:48,721 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:34:50,130 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:34:52,096 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:34:54,147 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:34:56,081 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:34:56,807 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:34:59,025 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:34:59,026 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:34:59,027 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:34:59,882 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:35:01,313 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:35:04,941 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:35:06,844 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:35:09,097 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:35:11,455 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:35:13,981 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:35:14,935 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:35:16,742 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:35:16,743 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:35:16,743 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:35:18,419 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:35:19,534 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:35:20,465 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:35:22,099 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:35:24,461 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:35:27,315 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:35:29,416 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:35:30,002 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:35:34,413 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:35:34,416 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:35:34,416 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:35:35,127 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:35:36,238 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:35:37,277 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:35:38,433 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:35:40,355 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:35:42,482 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:35:44,286 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:35:45,143 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:35:47,452 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:35:47,453 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:35:47,453 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:35:48,321 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:35:50,468 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:35:51,633 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:35:52,929 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:35:54,567 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:35:56,614 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:35:58,619 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:35:59,481 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:36:04,124 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:36:04,125 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:36:04,125 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:36:05,017 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:36:06,063 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:36:06,960 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:36:08,492 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:36:10,028 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:36:12,145 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:36:14,331 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:36:15,048 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:36:16,955 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:36:16,958 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:36:16,958 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:36:17,381 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:36:18,489 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:36:19,251 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:36:20,714 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:36:22,727 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:36:24,979 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:36:27,623 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:36:28,358 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:36:30,579 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:36:30,582 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:36:30,583 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:36:31,127 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:36:32,230 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:36:33,375 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:36:34,912 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:36:37,065 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:36:41,571 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:36:44,093 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:36:44,778 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:36:47,045 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:36:47,047 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:36:47,048 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:36:51,197 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:36:52,304 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:36:53,090 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:36:54,409 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:36:55,835 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:36:57,646 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:36:59,415 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:37:00,069 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:37:05,928 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:37:05,930 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:37:05,930 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:37:06,572 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:37:08,088 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:37:09,139 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:37:10,753 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:37:13,986 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:37:20,995 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:37:23,695 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:37:24,357 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:37:26,467 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:37:26,469 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:37:26,469 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:37:26,924 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:37:28,067 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:37:29,186 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:37:30,624 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:37:33,589 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:37:36,251 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:37:38,228 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:37:38,891 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:37:41,287 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:37:41,288 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:37:41,288 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:37:44,446 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:37:45,565 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:37:46,596 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:37:48,229 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:37:50,691 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:37:52,531 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:37:54,438 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:37:55,300 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:37:57,352 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:37:57,353 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:37:57,353 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:37:58,373 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:38:01,138 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:38:04,723 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:38:06,494 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:38:08,429 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:38:10,144 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:38:11,939 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:38:12,594 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:38:14,163 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:38:14,164 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:38:14,165 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:38:14,961 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:38:17,654 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:38:18,696 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:38:19,879 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:38:21,512 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:38:23,112 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:38:25,245 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:38:26,360 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:38:29,117 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:38:29,117 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:38:29,118 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:38:30,836 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:38:31,965 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:38:32,775 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:38:34,018 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:38:35,803 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:38:38,291 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:38:40,711 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:38:41,888 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:38:44,117 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:38:44,119 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:38:44,119 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:38:44,675 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:38:45,746 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:38:46,808 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:38:48,204 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:38:50,294 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:38:51,928 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:38:53,559 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:38:54,161 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:38:56,395 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:38:56,396 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:38:56,397 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:38:56,936 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:38:58,047 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:38:58,788 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:39:00,734 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:39:04,625 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:39:06,877 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:39:09,373 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:39:10,051 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:39:11,407 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:39:11,408 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:39:11,408 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:39:11,719 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:39:12,857 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:39:14,049 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:39:15,515 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:39:17,494 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:39:19,166 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:39:20,738 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:39:21,524 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:39:23,226 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:39:23,227 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:39:23,227 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:39:24,289 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:39:25,407 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:39:26,543 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:39:27,735 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:39:29,607 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:39:31,454 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:39:33,253 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:39:33,898 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:39:36,455 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:39:36,457 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:39:36,457 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:39:37,016 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:39:38,543 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:39:39,647 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:39:41,079 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:39:42,382 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:39:44,017 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:39:45,617 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:39:46,505 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:39:48,450 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:39:48,451 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:39:48,451 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:39:48,891 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:39:50,025 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:39:51,118 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:39:52,442 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:39:54,188 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:39:59,294 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:40:02,722 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:40:03,506 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:40:05,065 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:40:05,066 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:40:05,066 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:40:05,842 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:40:07,293 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:40:08,937 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:40:10,365 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:40:12,006 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:40:13,847 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:40:16,050 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:40:16,923 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:40:18,990 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:40:18,992 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:40:18,992 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:40:19,688 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:40:20,793 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:40:22,247 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:40:24,102 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:40:25,522 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:40:27,060 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:40:28,571 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:40:29,312 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:40:30,878 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:40:30,879 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:40:30,879 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:40:31,538 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:40:32,694 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:40:33,919 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:40:35,225 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:40:36,988 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:40:38,836 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:40:40,885 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:40:41,600 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:40:43,982 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:40:43,983 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:40:43,984 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:40:44,879 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:40:46,170 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:40:47,335 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:40:49,180 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:40:50,921 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:40:52,965 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:40:54,991 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:40:56,041 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:40:58,091 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:40:58,092 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:40:58,093 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:40:59,256 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:41:00,387 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:41:02,365 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:41:05,050 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:41:06,997 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:41:09,063 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:41:11,804 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:41:12,833 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:41:15,372 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:41:15,373 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:41:15,373 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:41:15,913 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:41:17,055 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:41:17,849 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:41:18,976 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:41:20,513 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:41:22,664 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:41:24,949 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:41:25,642 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:41:27,562 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:41:27,563 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:41:27,563 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:41:28,399 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:41:29,623 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:41:31,061 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:41:32,698 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:41:35,053 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:41:37,511 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:41:40,313 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:41:41,097 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:41:43,186 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:41:43,187 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:41:43,188 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:41:43,611 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:41:44,868 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:41:45,707 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:41:47,240 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:41:49,028 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:41:51,238 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:41:54,130 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:41:54,819 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:41:55,979 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:41:55,980 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:41:55,981 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:41:56,558 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:41:57,755 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:41:58,914 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:42:00,553 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:42:04,685 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:42:06,595 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:42:08,368 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:42:09,160 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:42:11,091 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:42:11,092 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:42:11,092 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:42:11,617 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:42:12,710 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:42:13,561 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:42:15,095 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:42:17,259 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:42:18,981 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:42:20,462 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:42:21,133 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:42:22,689 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pinecone_plugins'])
2025-01-02 21:42:22,691 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference
2025-01-02 21:42:22,691 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone
2025-01-02 21:42:23,493 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-01-02 21:42:24,597 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2025-01-02 21:42:25,438 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:42:26,931 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:42:29,183 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:42:31,888 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:42:33,893 - openinference.instrumentation.llama_index._handler - ERROR - Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
Traceback (most recent call last):
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/openinference/instrumentation/llama_index/_handler.py", line 253, in process_output
    self[OUTPUT_VALUE] = result.model_dump_json(exclude_unset=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mattboraske/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pydantic/main.py", line 477, in model_dump_json
    return self.__pydantic_serializer__.to_json(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.PydanticSerializationError: Error serializing to JSON: PydanticSerializationError: Unable to serialize unknown type: <class 'async_generator'>
2025-01-02 21:42:34,544 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-02 21:42:35,973 - src.agent.evaluation.eval_util - INFO - Response collection completed. Successful: 978, Failed: 22
2025-01-02 21:42:36,054 - __main__ - INFO - Collected 978 responses
2025-01-02 21:42:36,054 - __main__ - INFO - Starting evaluation of responses
2025-01-02 21:42:36,054 - src.agent.evaluation.eval_util - INFO - Starting comprehensive evaluation
2025-01-02 21:42:36,054 - src.agent.evaluation.eval_util - INFO - Evaluating classifications...
2025-01-02 21:42:36,055 - src.agent.evaluation.eval_util - INFO - Starting classification evaluation
2025-01-02 21:42:36,075 - src.agent.evaluation.eval_util - INFO - Generating classification report
2025-01-02 21:42:36,096 - src.agent.evaluation.eval_util - INFO - Generating confusion matrix
2025-01-02 21:42:36,747 - src.agent.evaluation.eval_util - INFO - Calculating Matthews Correlation Coefficient
2025-01-02 21:42:37,487 - src.agent.evaluation.eval_util - INFO - Classification evaluation completed successfully
2025-01-02 21:42:37,487 - src.agent.evaluation.eval_util - INFO - Evaluating justifications...
2025-01-02 21:42:37,487 - src.agent.evaluation.eval_util - INFO - Starting justification evaluation
2025-01-02 21:42:37,491 - src.agent.evaluation.eval_util - INFO - Calculating ROUGE scores
2025-01-02 21:42:37,875 - absl - INFO - Using default tokenizer.
2025-01-02 21:42:44,276 - src.agent.evaluation.eval_util - INFO - Calculating BLEU scores
2025-01-02 21:42:46,247 - src.agent.evaluation.eval_util - INFO - Starting toxicity analysis
2025-01-02 21:49:36,237 - src.agent.evaluation.eval_util - INFO - Calculating toxicity statistics
2025-01-02 21:49:36,253 - src.agent.evaluation.eval_util - INFO - Generating toxicity visualization
2025-01-02 21:49:36,253 - src.agent.evaluation.eval_util - INFO - Generating toxicity score visualization
2025-01-02 21:49:37,297 - src.agent.evaluation.eval_util - INFO - Toxicity plot saved to eval_results_embedding_3_large_4o_2024_08_06_balanced_250/toxicity_plot.png
2025-01-02 21:49:37,297 - src.agent.evaluation.eval_util - INFO - Justification evaluation completed successfully
2025-01-02 21:49:37,329 - src.agent.evaluation.eval_util - INFO - Evaluating retrieval...
2025-01-02 21:49:37,330 - src.agent.evaluation.eval_util - INFO - Starting retrieval evaluation
2025-01-02 21:49:37,368 - src.agent.evaluation.eval_util - INFO - Calculating retrieval summary metrics
2025-01-02 21:49:37,417 - src.agent.evaluation.eval_util - INFO - Retrieval evaluation completed successfully
2025-01-02 21:49:37,417 - src.agent.evaluation.eval_util - INFO - Top document classification accuracy: 28.53%
2025-01-02 21:49:37,417 - src.agent.evaluation.eval_util - INFO - Average document classification accuracy: 29.28%
2025-01-02 21:49:37,417 - src.agent.evaluation.eval_util - INFO - Comprehensive evaluation completed successfully
2025-01-02 21:49:37,417 - __main__ - INFO - Saving responses to eval_results_embedding_3_large_4o_2024_08_06_balanced_250/responses.json
2025-01-02 21:49:37,552 - __main__ - INFO - Evaluation process completed successfully
2025-01-02 21:49:38,075 - __main__ - INFO - Script execution completed
